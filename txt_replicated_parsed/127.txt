 The mechanisms underlying mental imagery have been investigated for over a century. One important question has been whether imagery uses the same mechanisms nor- mally employed for perception (Ishai & Sagi, 1995; Kosslyn, Thompson, & Alpert, 1997; Perky, 1910; Pylyshyn, 2002). A number of brain areas important for perception can also be engaged by imagery, including retinotopically mapped regions in visual cortex (Kosslyn et al., 1999; Kosslyn, Thompson, Kim, & Alpert, 1995; Slotnick, Thompson, & Kosslyn, 2005) and cortical areas that respond preferen- tially to specific classes of stimuli (e.g., faces, buildings) (O’Craven and Kanwisher, 2000) or visual motion (Goebel, Khorram-Sefat, Muckli, Hacker, & Singer, 1998; Grossman & Blake, 2001). However, standard neuroimaging methods have not answered whether the same subpopulations of neurons are engaged by both perception and imagery. Observations that a particular brain area is active during either viewing or imagery of a particular feature does not * Corresponding author. Tel.: +1 650 704 9702. E-mail address: winawer@stanford.edu (J. Winawer). 0010-0277/$ - see front matter Ó 2009 Elsevier B.V. All rights reserved. doi:10.1016/j.cognition.2009.09.010 necessarily imply that the same individual neurons or fine circuits underlie these activations, nor whether the processing is selective for a particular feature; the activation may be driven by a non-selective mechanism like arousal or attention (Beauchamp, Cox, & DeYoe, 1997; Corbetta, Miezin, Dobmeyer, Shulman, & Petersen, 1991; Huk, Ress, & Heeger, 2001; O’Craven et al., 1997; Saenz, Buracas, & Boynton, 2002). To infer whether imagery of motion relies on direction- selective motion circuitry that is also used for perception of physical motion, we tested for a motion aftereffect following motion imagery. The motion aftereffect is an illusion in which after prolonged viewing of motion in one direction, a stationary or ambiguous dynamic test stimulus appears to drift in the opposite direction (Mather, Verstraten, & Anstis, 1998; Wohlgemuth, 1911). Prolonged viewing of directional motion is thought to adapt direction- selective cortical neurons, such that subpopulations tuned to the adapting direction become less responsive after adaptation. Such direction-selective adaptation leads to an imbalance in neural responses that favors the direction opposite that of adaptation (Barlow & Hill, 1963). The pres- ence of a motion aftereffect is therefore an indicator of the involvement of direction-selective neural mechanisms (Kohn & Movshon, 2003; Petersen, Baker, & Allman, 1985; Van Wezel & Britten, 2002). We reasoned that if visual imagery of motion relies on direction-selective neurons that are also involved in the perception of physical motion, then prolonged imagery of motion in one direction should adapt direction-selective neurons and produce a motion aftereffect. In previous work we have shown that viewing frozen-motion photographs can produce a motion aftereffect (Winawer, Huk, & Boroditsky, 2008). Here we asked whether imagining motion in the absence of visual stimuli can adapt direction-selective neurons and produce a motion aftereffect. Five experiments were conducted. Experiments 1–3 tested for a motion aftereffect resulting from imagined motion. For comparison to the imagery experiments, Experiments 4 and 5 tested for a motion aftereffect resulting from viewing real motion. Each experiment was preceded by a baseline motion sensitivity measurement. In the experimental trials, participants either imagined or viewed motion, and were tested with moving-dot test probes. The test probes were used to assess the degree to which imagining or viewing real motion caused a motion aftereffect. Naïve volunteers from the MIT (n = 64) and Stanford (n = 68) communities received course credit or were paid for participation. In Experiment 1, 33 participants imagined upward or downward motion. In Experiment 2, 31 participants imagined inward or outward motion. In Experiment 3, 30 participants also imagined inward or outward motion, but with a delay of 1, 4, or 13 s inserted in each trial before the appearance of the test probe to assess the decay of the aftereffect. In Experiments 4 and 5, participants passively viewed moving gratings, either upward or downward (n = 31), or inward or outward (n = 7). In all experiments, participants viewed or imagined the two opposing directions of motion in separate blocks; no participants participated in more than one experiment. We assessed adaptation to motion with a standard direction discrimination task ( Newsome & Pare, 1988) used previously to quantify motion aftereffects from adapting to real visual motion (Blake & Hiris, 1993; Hiris & Blake, 1992). The test stimulus consisted of low-contrast dynamic random dots. The percentage of dots moving coherently in a particular direction (‘‘motion coherence”) varied from trial to trial. The direction of coherent motion was either up/down (Experiments 1 and 4), or inward/outward (Experiments 2, 3, and 5). Participants were instructed to indicate the direction of global motion by forced choice (up vs. down or inward vs. outward, depend- ing on the type of motion in the experiment). The range of motion coherence values was adjusted for each participant according to their performance on the baseline motion discrimination task. Participants who failed to demonstrate sensitivity to motion in the baseline task were excluded from analysis (see Appendix A). Experiments 1 and 2 tested for adaptation from motion imagery (Fig. 1). After a baseline task, participants were familiarized with the motion stimuli to imagine. The stimuli were either horizontal gratings that moved up or down (Experiment 1), or two vertical gratings that moved hori- zontally inward or outward (Experiment 2). The gratings were square wave luminance gratings with a spatial frequency of 1 cycle per degree, and a speed of 2.7° per sec- ond. To facilitate imagery, participants were presented with a timing guide: a stationary fixation square which cycled in luminance or a tone which cycled in pitch. The timing guide cycled at the same temporal frequency as the moving gratings. Participants viewed two examples of the moving gratings in each direction for 6 s each, to- gether with the fixation square and tone. Participants were told to ‘‘try to attend to the size, color, and speed of the stripes, so that later you can picture them clearly even when the screen is blank.” At the beginning of each of the 8 imagery blocks, participants were re-familiarized with the gratings by again viewing two examples of gratings in each direction in random order (6 s each). Participants were not told which direction of motion they would need to imagine until after the re-familiarization. This prevented them from being able to selectively attend to the example gratings moving in the direction of imagery for the subsequent block. Each trial consisted of a period of imagery adaptation followed by viewing a real moving-dot test stimulus. The imagery adaptation period was 60 s in the first trial of each block and 6 s in each subsequent trial. After viewing the moving-dot test stimulus participants indicated its direction with a keypress. Within each block of trials, the direction of imagery and whether the eyes were open or closed was the same. For each direction of imagery adaptation, there were two eyes-open blocks and two eyes-closed blocks, in random order. Experiment 3 was conducted to assess whether aftereffects from mental imagery decay over a period of a few seconds, as do aftereffects from visual motion (Keck & Pentz, 1977). This experiment was identical to Experiment 2 except there was a variable delay (1, 4, or 13 s) between when participants were cued to open their eyes following imagery and when the test probe appeared; there was no eyes-open condition; there were 8 dot coherence values tested instead of 12; and there were two blocks of trials instead of 8, with each block consisting of 48 instead of 24 trials (2 directions for the test probe Â 8 coherence values Â 3 delay durations). In Experiments 4 and 5, we tested adaptation to real visual motion. The procedure and stimuli were identical to those in Experiments 1 and 2 (up/down and in/out motion adaptation, respectively) except that rather than being instructed to imagine motion during adaptation, participants were simply instructed to fixate on the actual moving grating; examples of the moving gratings were not shown at the beginning of each block because participants did not need to imagine the grating; there were four blocks of trials instead of eight because there were no eyes-closed blocks; and there was no auditory timing guide. Imagery of motion produced motion aftereffects. Imag- ining motion upward made participants more likely to see the test dots as moving downward, compared to imagining motion downward. Likewise, imagining motion outward made participants more likely to see the test dots as moving inward. These effects were found from imagery both with eyes closed and with eyes open. Moreover, the effects of imagery adaptation weakened when a delay was intro- duced between adaptation and test, as has been found  for perceptual motion adaptation (Keck & Pentz, 1977). We infer that visual motion imagery involves some of the same directional-selective motion processing circuits that are used for perception of motion. Below, the motion aftereffects are quantified and compared to aftereffects from perception of real motion.  Fig. 2 shows the population motion sensitivity curves following opposite directions of imagery adaptation. In each plot, the vertical separation between the curves indicates how differently the same physical stimulus was judged following imagery in opposite directions. The horizontal separation indicates the amount by which two stimuli that were judged by participants as the same (following adaptation in different directions) were in fact physically different. Had there been no effect of imagery the two curves would overlap. If participants had answered based on an association (e.g., with a bias to respond upwards following upwards imagery) then the difference between the curves would have been in the opposite direction than what we observed. The motion aftereffects were quantified as the separation between the paired functions, estimated by logistic fits to the population data (Fig. 2; see Appendix A for model fits). The aftereffects were further quantified on individual participants. A logistic regression was fit to each participant’s data. This provided for each participant an estimate of the separation between the two curves (up vs. down or inward vs. outward) for each eye condition (open and closed). We coded this value as positive if the separation between the curves was in the direction predicted by an aftereffect and negative if it was in the opposite direction. We tested this value against a null hypothesis of no-shift by two-tailed, one-sample t-test (Experiments 3–5), or by analysis of variance using eye condition (open or closed) as a repeated measure (Experiments 1 and 2). A small but highly significant aftereffect from imagery was observed, evident in the population data fits ( Fig. 2), and the individual data fits (Fig. 3). The individual data from up/down imagery (Experiment 1) showed a separation between the motion response functions of 0.15 ± 0.05 (mean ± sem) units of normalized coherence (F(1,28) = 9.3; P = 0.005). There was no significant difference between the size of the effect from imagery with the eyes closed (0.19 ± 0.06) vs. eyes open (0.11 ± 0.05) (F(1,28) = 2.5, P = 0.12). In/out imagery (Experiment 2) also yielded significant motion aftereffects, with a separation between the functions for inward vs. outward imagery of 0.08 ± 0.03 units of normalized coherence (F(1,27) = 6.8; P = 0.015). As with the up/down imagery experiment, the motion aftereffect from imagery with the eyes closed (0.10 ± 0.04) was not significantly different from the effect with the eyes open (0.06 ± 0.03) (F(1,27) = 2.3; P = 0.145). Note that if the data for individual participants are replotted with the actual coherence values of the test stimuli instead of normalized units, then the shape of the curves for each is exactly the same; only the scale of the x-axis changes. Reanalysis with these actual coherence values yields the same pattern of results. The size of the aftereffects in terms of actual coherence was 4.7 ± 1.4% (F(1,28) = 10.9; P = 0.003) for the up/down imagery experiment and 2.9 ± 1.4% (F(1,27) = 4.3; P = 0.049) for the inward/outward imagery experiment. Experiment 3 showed that a brief delay between imagery and test probe weakened the adaptation effect (Fig. 3, right). A 1-s delay, identical to that in the first two experiments, produced a reliable motion aftereffect (0.11 ± 0.5 units of normalized coherence), about equal in magnitude to the aftereffect in the corresponding condition in the previous imagery experiment (in-out, eyes closed, 0.10 ± 0.04). The effect declined with longer delays, (4 s, 0.06 ± 0.06; 13 s, 0.01 ± 0.06), with a significant difference between the shortest and longest delay (T(26) = 1.73; P = 0.047, one-tailed, paired t-test). As expected, viewing real visual motion led to a robust motion aftereffect ( Fig. 4). For upward and downward motion, the separation between the two functions following opposite directions of adaptation, based on fits to individual participants, was 0.73 ± 0.25 units of normalized coherence (t(23) = 2.92, P = 0.008, two-tailed one-sample t-test), or 21 ± 6.4% in terms of the un-normalized coherence (t(23) = 3.44, P = 0.002). Adaptation to inward or outward motion also led to a large motion aftereffect: a separation between curves of 0.37 ± 0.04 units of normalized coherence (t(6) = 9.02, P = 0.0001). These effects were about 3– 4Â bigger than those found from imagery. In these studies participants imagined motion in a particular direction and were then asked to judge the direction of motion of a moving-dots stimulus. We found that imagining motion produced a motion aftereffect. For example, after imagining motion down, participants were more likely to perceive a set of moving dots as moving up (opposite the direction of imagery). These results dem-  onstrate for the first time that imagery of motion recruits direction-selective neural mechanisms that are also used for perceiving real motion. The motion aftereffects we observed from imagery were smaller than those from real motion, consistent with reports showing less activation of sensory cortical areas from motion imagery than from perception of the same stimuli (Goebel et al., 1998; Grossman & Blake, 2001). Our results show that visual imagery of motion can affect the perception of subsequent physical motion stimuli, and that perception and imagery of motion rely on shared direction-selective neural mechanisms. Two important alternative explanations can be ruled out based on the pattern of results. First, the motion aftereffect obtained from in/out imagery discounts the possibil- ity that the effects we report are due to eye movements and not imagery, such as the motion aftereffects caused by pursuit eye movements in the absence of motion perception (Chaudhuri, 1990, 1991; Freeman, Sumnall, & Snowden, 2003). Second, the motion aftereffect from imagery with the eyes closed argues against visual attention as the source of the effects, such as the motion aftereffects observed from attentional amplification of real motion sig- nals (Alais & Blake, 1999) or attentional tracking of moving stimuli (Culham, Verstraten, Ashida, & Cavanagh, 2000). Although one might posit that participants attended to an internal stimulus, this explanation still requires that imagery recruits direction-selective motion mechanisms in the absence of sensory input, in accord with our inter- pretation. Attentional mechanisms for a stimulus or feature, by contrast, presumably operate on representations that are delivered by feed-forward inputs. Moreover, two results suggest that the aftereffects were not due to a simple cognitive bias. First, a brief delay after imagery adaptation weakened the effect, as has been found for adaptation to real motion (Keck & Pentz, 1977). Because the direction of imagery was always the same within a block of 48 trials, it is unlikely that participants relying on an explicit response bias strategy would simply forget which way to respond after such a brief delay. A knowl- edge-based bias might be expected to be present throughout the block. Secondly, debriefing following Experiment 1 suggests that participants were not significantly influenced by their knowledge of motion aftereffects or expectations of the experiment. The participants were asked two questions at the end of the experiment: Have you ever heard of the ‘Mo- tion Aftereffect’ before, and After viewing upward motion, would you expect a static image to appear to move up or down. The answers to these questions were not predictive of the observed MAEs: participants who reported having heard (n = 7) vs. not having heard (n = 17) of the MAE showed shifts of 0.13 ± 0.03 vs. 0.10 ± 0.01 in the motion response curves following opposite directions of imagery (t(22) = .631; P = 0.53, two-tailed, unpaired t-test), pooling across eyes-open and eyes-closed conditions. The 17 participants who had not heard of the motion aftereffect were evenly divided in their responses as to whether a static image would appear to move in the opposite (n = 8) vs. the same (n = 8) direction of prior viewing of motion; one participant responded that it would not appear to move at all. Our results are consistent with prior psychophysical studies on spatial imagery (Ishai & Sagi, 1995) and the imagery and inference of motion. Gilden and colleagues (1995) demonstrated that adaptation to real visual motion affected imagery of motion, the converse of our experiments. Importantly, however, the authors attributed their results to an effect of motion adaptation on the imagined location of a stimulus, not an effect of motion adaptation on motion imagery. This explanation would not apply to our experimental paradigm, since the imagined stimuli occupied the same location regardless of the direction of motion. Our results are also consistent with a prior finding that imagining motion can lead to the illusion of roll vec- tion, whereby spatial judgments are altered by imagery of rotation (Mast, Berthoz, & Kosslyn, 2001). Previously we observed that passive viewing of photographs that de- pict motion can lead to a motion aftereffect (Winawer et al., 2008). Our current studies add to these by showing for the first time that motion imagery, in the absence of motion perception and even in the absence of any visual input, can recruit and adapt directional motion mechanisms. More generally, our results indicate that top-down signals in the brain can selectively exert specific effects on appropriate subpopulations of sensory neurons. We thank Gordon Bower, Nancy Kanwisher, Josh Wall- man, and Nathan Witthoft for reading an earlier version of this manuscript. We thank Jesse Carton and Taraz Lee for assistance in running experiments. Participants sat in a quiet, dark room, approximately 40 cm from an iMac CRT monitor (resolution: 1024 Â 768 pixels (26 Â 19.5 cm), refresh rate: 75 Hz). The test stimulus for the up/down imagery and real motion adaptation experiments consisted of 100 dots in a rectangular window whose length and width were 33% of the entire display (approximately 12 by 9 degrees of visual  angle). On each frame a subset of the dots were selected to move coherently up or down. All other dots disappeared and randomly reappeared at any location within the test window. A new set of dots was re-selected for coherent movement on each frame. This ‘‘limited lifetime” procedure was used so that the trajectory of single dots could not be followed throughout a trial. Each test trial consisted of 25 frames displayed for 40 ms each (1 s total). Dot dis- placement for coherent motion was $0.11° per frame. For the inward/outward experiments, the test stimulus consisted of 200 dots, 100 on each side of fixation. On a given trial the coherent component of the dots motion was horizontal either inward or outward (towards or away from the vertical midline). The stimulus was otherwise identical to the test stimulus used for the up/down experiments. To determine an appropriate range of motion coherences for each participant, all participants first completed a baseline motion discrimination task. Moving-dot displays were presented in 1-s trials with up to 65% of dots moving coherently preceding up/down experiments and up to 100% preceding in/out experiments. The coherence values producing 99% correct responses in each direction based on logistic fits to the responses were used to determine the maximum test coherence for the adaptation phase of the experiments. As this value depended on the participant’s performance on the baseline task, it differed across participants (36 ± 17% and 35 ± 12%, mean ± SD, for the up/down and in-out imagery experiments, respectively). We defined this value as 1 unit of normalized coherence in order to make comparisons across participants. For the up-down experiments, coherence values of one-half and one-quarter of this value were used as test stimuli, giving 6 test stimuli for each participant (±1, ±0.5, and ± 0.25 ‘‘normalized” coherence.) For the in-out experiments, the normalized coherence values were sampled more finely: ±1, ±0.67, ±0.44, ±0.29, ±0.19, ±0.13, ±0.08, ±0.05, ±0.03, ±0.02, ±0.01, and 0. A.3.1. Population fits The responses to moving-dot test stimuli were modeled as a logistic regression. The model fit to the aggregate data (all participants in the population) for a given pair of opposing adapting conditions used the following equation, fit with a maximum likelihood algorithm, PðxÞ 1⁄4 @=2 þ ð1 À @Þ Ã 1=ð1 þ YÞ; ð1Þ where Y 1⁄4 exp1⁄2Àð a þ b Ã x þ c Ã AÞ In this equation, x is the motion signal in normalized units of coherence (with positive values assigned to either upward or inward motion and negative values assigned to downward or outward motion). P(x) is the probability that the participant indicates upward (or inward) motion. A is the direction of motion imagery or real motion preceding the dot trial (+1 or À1), and a , ß, c , and @ are free parame- ters. The free parameters correspond to (i) o, the deviation from 0% and 100% with which responses asymptoted, (ii), a , an overall bias to respond in a particular direction, (iii) ß, the motion sensitivity or steepness of the function, and (iv) c the effect of adaptation. Dividing À2 Ã c by ß yields the separation between the paired curves in units of coherence. Thus this value indicates how much motion must be added to a stimulus in one adaptation condition to make it perceptually equivalent to the same stimulus in the opposite adaptation condition. The 95% confidence interval for each parameter estimate was determined by bootstrap- ping: 1000 simulated data sets were generated for each pair of adaptation conditions based on the actual population mean responses, each data set was fitted by Eq. (1), the 1000 parameter estimates were rank ordered, and the 975th and 25th values were taken as the confidence intervals. A.3.2. Individual fits The model fits for individual participants used a similar equation, but because there was less data for individual participants than for the whole population, fewer free parameters were used: PðxÞ 1⁄4 1=ð1 þ YÞ; where Y 1⁄4 exp1⁄2Àð a þ b Ã x þ c 1 Ã A 1 þ . . . þ c n Ã A n Þ ð2Þ This model differs from the population model in that there was no parameter @ to model the asymptote and, for the imagery experiments, the effects of adaptation were modeled in a single equation for all conditions. Thus for Experiments 1 and 2, there were two adaptation terms, one for the eyes-closed condition ( c 1 ) and one for the eyes-open condition ( c 2 ). For Experiment 3, there were three adaptation terms for the three delay conditions ( c 1 , c 2 , c 3 ). For the real motion adaptation experiments, only one adaptation parameter was modeled ( c 1 ). In all experiments, the motion sensitivity (ß) and global bias ( a ) were estimated only once per participant, whereas for the group data in the imagery experiments these parameters were fit separately for each pair of adapting conditions (eyes open and eyes closed). As with the population fits, dividing À2 Ã c by ß yields the separation between the paired curves in units of coherence. The mean of this value across participants was taken as the effect of adaptation for each pair of adaptation conditions. Fifteen participants were excluded from analysis for failing to perform well on the motion discrimination task. Nine participants (2 of 33 doing up/down imagery, 2 of 31 doing in/out imagery, 2 of 30 in the imagery-delay experiment, and 3 of 31 viewing up/down real motion) did not show a significant effect of motion coherence. For these participants, the probability of an ‘‘up” or ‘‘in” response did not significantly increase with increased coherence in that direction in the test stimulus. Specifically, the parameter estimated for motion coherence in a logistic regression fit was less than the standard error of the same parameter estimate. Six other participants, (1 of 33 doing up/down imagery, 1 of 31 doing in/out imagery, 1 of 30 in the imagery-delay experiment, and 3 of 31 doing up/ down real motion), performed poorly in the baseline motion discrimination task such that curve fits yielded a unit of normalized coherence as values >100% actual coherence. These participants were excluded from analysis.
