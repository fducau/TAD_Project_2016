<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>4def74190efb8695b47260041871a780cd14c400fac6d47730705778210f2305</job>
    <base_name>5z</base_name>
    <doi>10.1016/j.tics.2006.03.006</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="1">Review</outsider>
      <outsider class="DoCO:TextBox" type="header" id="2">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
      <title-group>
        <article-title class="DoCO:Title" id="3">Implicit learning and statistical learning: one phenomenon, two approaches</article-title>
      </title-group>
      <region class="unknown" id="4">Pierre Perruchet and Sebastien Pacton Universite  ́ de Bourgogne, LEAD/CNRS, Po ˆ le AAFE, Esplanade Erasme, 21000 Dijon, France</region>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="5" page="1" column="1">The domain-general learning mechanisms elicited in incidental learning situations are of potential interest in many research fields, including language acquisition, object knowledge formation and motor learning. They have been the focus of studies on implicit learning for nearly 40 years. Stemming from a different research tradition, studies on statistical learning carried out in the past 10 years after the seminal studies by Saffran and collaborators, appear to be closely related, and the similarity between the two approaches is strengthened further by their recent evolution. However, implicit learning and statistical learning research favor different interpretations, focusing on the formation of chunks and statistical computations, respectively. We examine these differing approaches and suggest that this divergence opens up a major theoretical challenge for future studies.</h1>
      </section>
      <section class="deo:Introduction">
        <h1 class="DoCO:SectionTitle" id="6" page="1" column="1">Introduction</h1>
      </section>
      <region class="DoCO:TextChunk" id="24" page="1" column="1">There is no doubt that many of our most fundamental abilities, whether they concern language, perception, motor skill, or social behavior, reflect some kind of adaptation to the regularities of the world that evolves without intention to learn, and without a clear awareness of what we know. This ubiquitous phenomenon was called ‘implicit learning’ (IL) by Reber [ <xref ref-type="bibr" rid="R1" id="7" class="deo:Reference">1</xref>, <xref ref-type="bibr" rid="R2" id="8" class="deo:Reference">2</xref>] 40 years ago. Since then, several studies have explored this form of learning with several experimental paradigms (mainly finite-state grammars and serial reaction time tasks; for reviews, see [<xref ref-type="bibr" rid="R3" id="9" class="deo:Reference">3</xref>, <xref ref-type="bibr" rid="R4" id="10" class="deo:Reference">4</xref>]). Originating from a different research tradition, the term ‘statistical learning’ (SL) was proposed 10 years ago by Saffran and collaborators [<xref ref-type="bibr" rid="R4" id="11" class="deo:Reference">4</xref>] to designate the ability of infants to discover the words embedded in a continuous artificial language, and this field of research is now growing exponentially. There are obvious similarities between SL and IL. As in IL, participants in SL experiments are faced with structured material without being instructed to learn. They learn merely from exposure to positive instances, without engaging in analytical processes or hypothesis-testing strategies. Researchers have pointed out that SL proceeds<marker type="column" number="2"/><marker type="block"/> automatically [<xref ref-type="bibr" rid="R5" id="15" class="deo:Reference">5</xref>, <xref ref-type="bibr" rid="R6" hidden="1" id="16" class="deo:Reference">6</xref>, <xref ref-type="bibr" rid="R7" hidden="1" id="17" class="deo:Reference">7</xref>, <xref ref-type="bibr" rid="R8" id="18" class="deo:Reference">8</xref>], incidentally [<xref ref-type="bibr" rid="R9" id="19" class="deo:Reference">9</xref>], spontaneously [<xref ref-type="bibr" rid="R6" id="20" class="deo:Reference">6</xref>], or by simple observation [<xref ref-type="bibr" rid="R9" id="21" class="deo:Reference">9</xref>], and that participants in SL settings were unaware of the statistical structure of the material [<xref ref-type="bibr" rid="R7" id="22" class="deo:Reference">7</xref>]. This article first describes how recent evolution in IL and SL research fields has made them closer to one another, leading to a growing number of cross-references and to the occasional use of the two expressions as synonymous. Conway and Christiansen [<xref ref-type="bibr" rid="R10" id="23" class="deo:Reference">10</xref>] even now propose the term ‘implicit statistical learning’ to cover the two domains. However, we then go on to show that beyond the similarity of paradigms and results, the two domains emphasize different interpretations of the data. We suggest that this divergence, which has not been highlighted as yet, opens up a deep challenge for future studies.</region>
      <region class="unknown" id="14" page="1" column="1">Corresponding author: Perruchet, P. (<email id="13">pierre.perruchet@u-bourgogne.fr</email>).</region>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="25" page="1" column="2">The recent evolution of IL and SL studies</h1>
      </section>
      <region class="DoCO:TextChunk" id="32" page="1" column="2">Ten years ago, it seemed possible to contrast IL and SL on their main issues of interest, namely syntax acquisition and lexicon formation, respectively. Indeed, the to-be- learned material used in artificial grammar learning research is typically governed by rules, that is by organizing principles which are independent of the specific material used in a given instance. If participants learned the rules, then this form of learning would be out of the scope of SL studies, in which the notion of rules is a priori irrelevant. However, research from the past few years has made it increasingly clear that participants in artificial grammar learning experiments do not need to extract the rules to perform well, even in situations involving transfer across surface forms (Box 1). In addition, the artificial grammar learning paradigms tend to be now supplanted by other paradigms, such as the serial reaction-time tasks, in which a description of the materials in terms of rules appears less appropriate. Another initial difference between the two domains was that IL research used a large variety of situations involving different sensory modalities and response systems, whereas SL originally focused on the early stage of language acquisition. However, more recently research on SL has progressively broadened its scope of investigation. The syllables used in the first studies have been replaced by tones with the same results [<xref ref-type="bibr" rid="R11" id="26" class="deo:Reference">11</xref>, <xref ref-type="bibr" rid="R12" id="27" class="deo:Reference">12</xref>]. A parallel literature has evolved with visual shapes [<xref ref-type="bibr" rid="R6" id="28" class="deo:Reference">6</xref>, <xref ref-type="bibr" rid="R7" hidden="1" id="29" class="deo:Reference">7</xref>, <xref ref-type="bibr" rid="R8" id="30" class="deo:Reference">8</xref>], or even tactile stimuli [<xref ref-type="bibr" rid="R13" id="31" class="deo:Reference">13</xref>]. Perhaps even more importantly,</region>
      <outsider class="DoCO:TextBox" type="footer" id="33" page="1" column="2">www.sciencedirect.com 1364-6613/$ - see front matter Q 2006 Elsevier Ltd. All rights reserved. doi:10.1016/j.tics.2006.03.006</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="34" page="2" column="1">234</outsider>
      <outsider class="DoCO:TextBox" type="header" id="35" page="2" column="1">Review</outsider>
      <outsider class="DoCO:TextBox" type="header" id="36" page="2" column="1">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="37" confidence="possible" page="2" column="1">Box 1. Fading out of the rule vs. no-rule</h1>
        <region class="unknown" id="51" page="2" column="1">Transfer tasks, in which the form of the material presented during the training phase is changed, have been used in studies involving the learning of artificial materials by infants (e.g. [<xref ref-type="bibr" rid="R50" id="38" class="deo:Reference">50</xref>]) and adults (e.g. [<xref ref-type="bibr" rid="R51" id="39" class="deo:Reference">51</xref>]), and the learning of world-sized regularities by children and adults [<xref ref-type="bibr" rid="R52" id="40" class="deo:Reference">52</xref>, <xref ref-type="bibr" rid="R53" id="41" class="deo:Reference">53</xref>]. For instance, in the study by Marcus [<xref ref-type="bibr" rid="R50" id="42" class="deo:Reference">50</xref>], infants previously exposed to exemplars of an ABB grammar (e.g. ga-ti-ti) subsequently listen more to the sentences generated by an ABA grammar (e.g. wo-fe-wo) than to sentences generated by the ABB grammar (e.g. wo-fe-fe), although new syllables were involved in both types of sentences. Although the empirical evidence for the phenomenon is undis- puted, the prevailing idea that positive transfer supports a rule- based interpretation has now been challenged. Some studies suggest that stimuli are not processed at an abstract level during incidental training [<xref ref-type="bibr" rid="R10" id="43" class="deo:Reference">10</xref>]. The above chance performance of participants could be due to analogical processes triggered by the transfer items during the test [<xref ref-type="bibr" rid="R54" id="44" class="deo:Reference">54</xref>], and could be mediated by the participants’ explicit knowledge of the structure [<xref ref-type="bibr" rid="R55" id="45" class="deo:Reference">55</xref>]. It is also possible to acknowledge some form of abstract coding without surmising rule-knowledge. Indeed, as argued by Redington and Chater [<xref ref-type="bibr" rid="R56" id="46" class="deo:Reference">56</xref>], ‘surface independence and rule-based knowledge are orthogonal concepts’. It is worth stressing that the evidence of transfer in implicit training conditions, even in adults, is limited to simple and salient features of the stimuli, and especially to the structure of repetitions (e.g. [<xref ref-type="bibr" rid="R57" id="47" class="deo:Reference">57</xref>, <xref ref-type="bibr" rid="R58" id="48" class="deo:Reference">58</xref>]). In these conditions, transfer might be based on the direct coding of abstract relations at the perceptual level [<xref ref-type="bibr" rid="R12" id="49" class="deo:Reference">12</xref>, <xref ref-type="bibr" rid="R47" id="50" class="deo:Reference">47</xref>].</region>
        <region class="DoCO:TextChunk" id="66" page="2" column="1">recent SL studies are no longer limited to the segmentation of a continuous display into word-like units, but they also explore other, more complex structures [<xref ref-type="bibr" rid="R14" id="52" class="deo:Reference">14</xref>]. For instance, Saffran and Wilson [<xref ref-type="bibr" rid="R15" id="53" class="deo:Reference">15</xref>] have used a finite-state grammar to generate their artificial language, and Hunt and Aslin [<xref ref-type="bibr" rid="R16" id="54" class="deo:Reference">16</xref>] used a serial reaction time task, hence borrowing the prototypical situations of IL to investigate the properties of SL. A recent set of results on the role of attention further strengthens the similarity between IL and SL. Although a few earlier IL studies claimed that at least some forms of learning do not require attention, the bulk of recent evidence supports the opposite conclusion. For instance, Shanks and collaborators (e.g. [<xref ref-type="bibr" rid="R18" id="55" class="deo:Reference">18</xref>]) showed that performances in serial reaction time tasks are degraded under double-task conditions (see also [<xref ref-type="bibr" rid="R19" id="56" class="deo:Reference">19</xref>]). Likewise, Chun and Jiang (e.g. [<xref ref-type="bibr" rid="R20" id="57" class="deo:Reference">20</xref>]) showed that implicit learning in the contextual cuing paradigm is robust only when relevant, predictive information is selectively attended to (see also [<xref ref-type="bibr" rid="R21" id="58" class="deo:Reference">21</xref>]). In covariation learning, Hoffman and Sebald [<xref ref-type="bibr" rid="R22" id="59" class="deo:Reference">22</xref>] showed that no learning occurs without attention, even when the to-be-learned covariations are highly salient (for reviews on earlier studies, see [<xref ref-type="bibr" rid="R23" id="60" class="deo:Reference">23</xref>, <xref ref-type="bibr" rid="R24" id="61" class="deo:Reference">24</xref>]. The same conclusion emerges from studies in SL. When the performance of participants in a dual task setting is compared with that of participants attending to the to-be-learned materials, the former is always degraded compared to the latter. This has been observed in standard word segmentation tasks [<xref ref-type="bibr" rid="R25" id="62" class="deo:Reference">25</xref>] as well as in paradigms using visual shapes [<xref ref-type="bibr" rid="R8" id="63" class="deo:Reference">8</xref>, <xref ref-type="bibr" rid="R26" id="64" class="deo:Reference">26</xref>]. Thus arguably, IL and SL studies now pursue essentially the same objective - namely, the study of domain-general learning mechanisms acting on attended information in incidental, unsupervised learning situations (e.g. [<xref ref-type="bibr" rid="R17" id="65" class="deo:Reference">17</xref>]).</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="67" page="2" column="2">A new question: chunk formation versus statistical computation</h1>
        <region class="DoCO:TextChunk" id="82" page="2" column="2">Although the similarities between IL and SL are impressive, comparing the interpretations favored in both fields leads us to a thought-provoking observation. In the IL literature, several models have been developed as alternatives to the initial rule-based view. The first alternative idea in artificial grammar learning research was that participants memorized the displayed strings of letters, then performed their grammaticality judgments on the basis of the similarity between the test items and the study items. The role of similarity in grammaticality judgments has been shown in some studies (e.g. [<xref ref-type="bibr" rid="R27" id="68" class="deo:Reference">27</xref>]). However, there is also significant evidence that participants memorize fragments of strings, and that grammaticality judgments rely, at least partly, on this form of knowledge. It has been argued that the fragments or chunks provide a most efficient coding of the information, because learning makes their selection increasingly adapted to the structure of the material (Box 2). This kind of interpretation has been applied as well to other IL paradigms such as serial reaction-time tasks [<xref ref-type="bibr" rid="R28" id="69" class="deo:Reference">28</xref>] By contrast, the interpretation proposed in the SL approach postulates that participants perform statistical computations. Evidence for segmentation is generally attributed to the ability of participants to compute some kind of conditional probabilities between successive or contiguous elements. This interpretation prevails for auditory artificial languages (e.g. [<xref ref-type="bibr" rid="R14" id="70" class="deo:Reference">14</xref>, <xref ref-type="bibr" rid="R15" id="71" class="deo:Reference">15</xref>]) as well as for visual scenes (e.g. [<xref ref-type="bibr" rid="R7" id="72" class="deo:Reference">7</xref>, <xref ref-type="bibr" rid="R9" id="73" class="deo:Reference">9</xref>]). At the computational level, this interpretation is generally implemented by connectionist networks, most often SRNs (e.g. [<xref ref-type="bibr" rid="R29" id="74" class="deo:Reference">29</xref>]). Note that the contrast we draw here is not as clear-cut as our presentation suggests. There have been a few attempts to account for word segmentation with chunking models (e.g. [<xref ref-type="bibr" rid="R30" id="75" class="deo:Reference">30</xref>]), although they have been virtually ignored in SL literature. More significantly, the performance in IL paradigms has been often simulated with SRNs (e.g. [<xref ref-type="bibr" rid="R31" id="76" class="deo:Reference">31</xref>, <xref ref-type="bibr" rid="R32" hidden="1" id="77" class="deo:Reference">32</xref> <xref ref-type="bibr" rid="R33" id="78" class="deo:Reference">33</xref>]). Because SRNs, like any connectionist network, are sensitive to statistical regularities, this means that certain IL researchers have construed implicit learning as statistical computations [<xref ref-type="bibr" rid="R3" id="79" class="deo:Reference">3</xref>, <xref ref-type="bibr" rid="R32" id="80" class="deo:Reference">32</xref>, <xref ref-type="bibr" rid="R34" id="81" class="deo:Reference">34</xref>]. However, the coexis- tence of chunk-based theories and connectionist models within the IL literature has not drawn much attention, largely because their common opposition to rule-based models overshadowed their differences. The joint consideration of IL and SL studies now brings the contrast between the two accounts on the front of the scene.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="83" page="2" column="2">Combining chunks and statistics: three possible scenarios</h1>
        <region class="DoCO:TextChunk" id="88" page="2" column="2">Nobody denies the existence of chunk knowledge. The advocates of statistical approaches claim themselves that learning shapes some kind of psychological units. For instance, Saffran and collaborators [<xref ref-type="bibr" rid="R15" id="84" class="deo:Reference">15</xref>, <xref ref-type="bibr" rid="R35" id="85" class="deo:Reference">35</xref>] have shown that training with unsegmented speech results in the formation of word-like units, rather than in strings of sounds the probability of which varies on a continuous dimension. Likewise, Baker and collaborators [<xref ref-type="bibr" rid="R26" id="86" class="deo:Reference">26</xref>] and Fiser and Aslin [<xref ref-type="bibr" rid="R9" id="87" class="deo:Reference">9</xref>] emphasize that the end result of SL</region>
        <outsider class="DoCO:TextBox" type="footer" id="89" page="2" column="2">www.sciencedirect.com</outsider>
        <outsider class="DoCO:TextBox" type="header" id="90" page="3" column="1">Review</outsider>
        <outsider class="DoCO:TextBox" type="header" id="91" page="3" column="1">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="92" page="3" column="1">235</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="93" confidence="possible" page="3" column="1">Box 2. Artificial grammar meets word segmentation</h1>
        <region class="unknown" id="96" page="3" column="1"> <xref ref-type="fig" rid="FI" id="94" class="deo:Reference">Figure I</xref> shows a finite-state grammar that has been widely used in IL studies. After exposure to strings of letters generated by this grammar (e.g. a or b below), participants are able to discriminate new grammatical and ungrammatical strings of letters. It is now generally accepted that artificial grammar learning relies, at least partly, on the formation of small chunks. If those chunks were selected randomly, as illustrated in line (a) below, memorizing chunks would be difficult and inefficient: there would be many chunks, infrequently repeated across strings, and their recombination would have a low probability of generating a new grammatical string. Instead, learning consists in forming chunks that recur as often as possible in different strings, and whose recombination has high chance of generating a new grammatical string [<xref ref-type="bibr" rid="R59" id="95" class="deo:Reference">59</xref>]. Line (b) below shows how the strings of letters displayed in line (a) can be segmented into more relevant units. For instance, the chunks now implicitly encode the recursive loop RFV, shown in red in the grammar diagram. Note that the issue of artificial grammar learning framed in this way appears very close to that investigated in word segmentation studies. In both cases, learning consists of finding the most relevant units to encode information. D V S X R F H M T P TRENDS in Cognitive Sciences</region>
        <region class="DoCO:FigureBox" id="FI">
          <caption class="deo:Caption" id="97" confidence="possible" page="3" column="1">Figure I. A typical finite-state grammar, with a recursive loop of letters, RFV, highlighted.</caption>
        </region>
        <region class="DoCO:TextChunk" id="109" page="3" column="1">with visual displays is the formation of objects. This leaves three possibilities to account for the available evidence: The first possibility is that statistical computations and chunk formation are independent processes. Meulemans and Van Der Linden [ <xref ref-type="bibr" rid="R36" id="98" class="deo:Reference">36</xref>] have argued for this view, with the additional assumption that chunk formation is responsible for conscious knowledge, and statistical computation for improved performance in implicit tasks (for related hypotheses, see [<xref ref-type="bibr" rid="R37" id="99" class="deo:Reference">37</xref>, <xref ref-type="bibr" rid="R38" id="100" class="deo:Reference">38</xref>]). This hypothesis is grounded on the dissociation between performance and explicit knowledge observed in amnesic patients. However, alternative interpretations have been proposed for this dissociation, notably by Shanks and collaborators [<xref ref-type="bibr" rid="R33" id="101" class="deo:Reference">33</xref>, <xref ref-type="bibr" rid="R39" id="102" class="deo:Reference">39</xref>, <xref ref-type="bibr" rid="R40" id="103" class="deo:Reference">40</xref>]. Shanks and collaborators assume a single knowledge basis, and hence, in addition to the advantage of better parsimony, their interpretation provides a natural account for the ubiquitous relationships<marker type="column" number="2"/><marker type="block"/> observed in normal participants between conscious knowledge and performance. The second possibility is that statistical computations and chunk formation are two successive steps in the learning process. Chunks would be inferred from prior statistical computations. Typically, chunk boundaries are defined as the points where the predictibility of successive or spatially contiguous elements is the lowest. This interpretation is largely prevalent in SL research, both for oral stimuli (e.g. [<xref ref-type="bibr" rid="R35" id="105" class="deo:Reference">35</xref>]) and for visual scenes (e.g. [<xref ref-type="bibr" rid="R9" id="106" class="deo:Reference">9</xref>]). The third possibility is that the formation of chunks is the only effective process, with the sensitivity to statistical structure being a by-product of this process. At least two computationally implemented models illustrate this option, the Competitive Chunking model [<xref ref-type="bibr" rid="R41" id="107" class="deo:Reference">41</xref>] and PARSER [<xref ref-type="bibr" rid="R30" id="108" class="deo:Reference">30</xref>]. In PARSER , for instance, the chunks are formed from the outset on a random basis, as a natural consequence of the capacity-limited attentional processing of the incoming information. These chunks are then forgotten or strengthened according to the laws governing associative memory. We will now focus on the last two possibilities, the first in which chunking is based on prior statistical analyses, and the second in which chunking is a primitive process the result of which amounts to simulating statistical computations.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="110" page="3" column="2">Does efficient chunking need prior statistical computations?</h1>
        <region class="DoCO:TextChunk" id="126" page="3" column="2">We are not aware of empirical arguments from proponents of chunk-based theories against the models assuming statistical computations, except that this assumption could be unnecessary. By contrast, SL researchers have occasionally argued that chunk models are only sensitive to the raw frequency of co-occurrences [ <xref ref-type="bibr" rid="R14" id="111" class="deo:Reference">14</xref>], whereas studies in SL have shown that participants were sensitive to more subtle statistics, such as conditional (or transi- tional) probabilities (e.g. [<xref ref-type="bibr" rid="R14" id="112" class="deo:Reference">14</xref>, <xref ref-type="bibr" rid="R42" id="113" class="deo:Reference">42</xref>]). Indeed, most chunk- based learning models, such as the competitive chunking model [<xref ref-type="bibr" rid="R41" id="114" class="deo:Reference">41</xref>] or the measures of chunk strength used in the influential studies by Knowlton and collaborators (e.g. [<xref ref-type="bibr" rid="R43" id="115" class="deo:Reference">43</xref>]) exclusively exploit frequency information, certainly because this initially appeared to be sufficient to account for a large part of the available evidence. However, the exclusive focus on frequency of many chunk-based models is somewhat surprising in itself. Although chunk-based models are claimed to implement associative learning principles, assuming that chunk memory only depends on their frequency amounts to neglecting some of the most basic laws governing the formation of associations. Indeed, it has long been known that the strength of memory traces does not only depend on the number of repetitions of the study pairs. In particular, forgetting is due in large part to the interference generated by the prior or subsequent events that are related in some way to the target event. The sequential material used in both IL and SL studies is certainly prone to generate strong and pervasive interference, because it is typically generated by recombining a small number of primitives. Now, and this is the crucial point, taking into account the effect of interference in evaluating chunk<marker type="page" number="4"/><marker type="column" number="1"/><marker type="block"/> strength amounts to considering other measures of association than the raw frequency of co-occurrences. Box 3 illustrates how implementing forward interference is sufficient to make chunk strength sensitive to transi- tional probabilities, which SL researchers consider so important. Moreover, Perruchet and Peereman [<xref ref-type="bibr" rid="R44" id="121" class="deo:Reference">44</xref>] have shown that PARSER , thanks to the role ascribed to interference in chunk formation, was even sensitive to contingency, that is to a measure of association more comprehensive than conditional probabilities. The above remarks suggest that it might turn out to be difficult to decide between concurrent interpretations based on a simple consideration of their explanatory power. Because IL and SL have mainly evolved as separate fields of research, the challenge has not often been addressed. A few recent studies, however, have begun to explore situations designed in such a way that predictions drawn from chunk-based models and statistical approaches differ. In these studies, some version of an SRN is used to quantify the predictions of statistical approaches, whereas the chunking models are rep- resented by the Competitive Chunking Model [<xref ref-type="bibr" rid="R45" id="122" class="deo:Reference">45</xref>] or PARSER [<xref ref-type="bibr" rid="R37" id="123" class="deo:Reference">37</xref>, <xref ref-type="bibr" rid="R44" id="124" class="deo:Reference">44</xref>, <xref ref-type="bibr" rid="R46" id="125" class="deo:Reference">46</xref>]. Although a detailed review of these studies is beyond the scope of this review, suffice it to say that, overall, their results do not clearly favor one or the other account. These preliminary results suggest that the present accounts will need to be amended. Further models would also allow to encompass data that neither the chunk- based models nor the statistical approaches in their current instantiations seem to be able to explain. In the past few years, several studies have shown the possibility of incidentally learning the relations between elements that are not contiguous in space and/or time</region>
        <outsider class="DoCO:TextBox" type="footer" id="117" page="3" column="2">www.sciencedirect.com</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="118" page="4" column="1">236</outsider>
        <outsider class="DoCO:TextBox" type="header" id="119" page="4" column="1">Review</outsider>
        <outsider class="DoCO:TextBox" type="header" id="120" page="4" column="1">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="127" confidence="possible" page="4" column="1">Box 3. Statistical computations and chunk-based models: how do they converge towards the same predictions?</h1>
        <region class="unknown" id="133" page="4" column="1">Above is a 20-letter sequence made up from 8 different letters. Let us assume that they stand for syllables (although they could equally stand for tones of different pitches, the consonant letters typically used in artificial grammar learning studies, the locations of a target on a screen typically involved in serial reaction-time studies, or any other events). The sequence can be viewed as the random succession of four bisyllabic words (they have been colored for ease of reading). How can the words be discovered? One solution consists of considering the frequency of all the bisyllabic units. However, column (a) of <xref ref-type="table" rid="TI" id="128" class="deo:Reference">Table I</xref> shows that, because AB and GH are more frequent than the other words, the ‘part-word’ BG turns out to be as frequent as the ‘words’ CD and EF. Aslin and collaborators [42,<xref ref-type="bibr" rid="R6" id="129" class="deo:Reference">6</xref>, <xref ref-type="bibr" rid="R7" id="130" class="deo:Reference">7</xref>, <xref ref-type="bibr" rid="R16" id="131" class="deo:Reference">16</xref>, <xref ref-type="bibr" rid="R42" id="132" class="deo:Reference">42</xref>,6,7,16] used a similar design to show that participants do not exploit co-occurrence frequencies, but rather the Transitional Probabilities (TP: Prob. y/xZfrequency of xy/frequency of x). Indeed, as indicated in column (b), considering TPs solves the problem (all word- internal TPs are stronger than TPs straddling word boundaries), hence the prevalent claim in the SL literature that participants compute TP. However, as shown in column (c), the same result can emerge if one considers instead that participants memorize chunks, as in IL studies. If memory for chunks was dependent only on their frequency, values in (c) would be identical to values in (a). However, memory consolidation and forgetting also depends on interference. Classical studies on interference show that the memory for AB is impaired by the presentation of AC or AD. For the sake of illustration, we have assumed</region>
        <region class="DoCO:TextChunk" id="135" page="4" column="2">(Box 4). Because the chunking process is usually construed as the clustering of adjacent events, these data confront the chunking models with a difficult challenge, as noted by Kuhn and Dienes [<xref ref-type="bibr" rid="R47" id="134" class="deo:Reference">47</xref>]. In principle, they do not raise the same problem for statistical approaches, because the notion of statistical computations does not care about the nature of the data (e.g. contiguous or not) on which statistics may be computed. However, there is a consensus among researchers working on language and visual perception that models relying on statistical computations alone need to be constrained to avoid combinatorial explosion. The adjacency of the to-be-learned elements provides such a natural constraint (which is implemented, for instance, in SRNs). Thus, the possibility of learning nonadjacent dependencies entails either an in-depth revi- sion of chunk-based models, or a significant departure from the most frequent computational implementation of statistical approaches.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="136" page="4" column="2">Implications for the issue of consciousness</h1>
        <region class="DoCO:TextChunk" id="137" page="4" column="2">One of the major implication of the debate outlined above is the function of consciousness in the learning process. If the chunks are inferred from the results of statistical computations, then most of the learning process must be thought of as unconscious, because statistical computations are not performed consciously in the context of incidental learning paradigms. Of course, this does not mean that chunks, once formed, are functionally inert in further steps of conscious activities, but simply that their initial emergence is guided by unconscious computations. On the other hand, if the final chunks evolve from the progressive modification of primitive chunks, then the function of consciousness in chunk formation can be</region>
        <region class="unknown" id="138" page="4" column="2">here that each occurrence of AB strengthens it by 1 unit, and each occurrence of another letter pair beginning with A decreases the AB strength by 0.5 unit. These parameters were selected arbitrarily, but the crucial outcome – namely that all the words have a stronger strength than any part-word – remains true whatever the parameters (the Pearson r between (b) and (c) is 0.95).</region>
        <region class="DoCO:TableBox" id="TI">
          <caption class="deo:Caption" id="139" page="4" column="2">Table I. Analysis of the letter sequence shown above</caption>
          <content>
            <table class="DoCO:Table" number="I" page="4">
              <thead class="table">
                <tr class="table">
                  <th class="table"></th>
                  <th class="table"> (a)</th>
                  <th class="table"></th>
                  <th class="table"> (b)</th>
                  <th class="table"> (c)</th>
                </tr>
                <tr class="table">
                  <th class="table"> Units</th>
                  <th class="table"> Frequency</th>
                  <th class="table"></th>
                  <th class="table"> TP</th>
                  <th class="table"> Chunk strength</th>
                </tr>
              </thead>
              <tbody>
                <tr class="table">
                  <td class="table"></td>
                  <td class="table"> xy</td>
                  <td class="table"> x</td>
                  <td class="table"> xy/x</td>
                  <td class="table"> xyK((xKxy)*0.5)</td>
                </tr>
                <tr class="table">
                  <td class="table"></td>
                  <td class="table"> 3</td>
                  <td class="table"> 3</td>
                  <td class="table"> 1</td>
                  <td class="table"> 3</td>
                </tr>
                <tr class="table">
                  <td class="table"></td>
                  <td class="table"> 2</td>
                  <td class="table"> 2</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                </tr>
                <tr class="table">
                  <td class="table"></td>
                  <td class="table"> 2</td>
                  <td class="table"> 2</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                </tr>
                <tr class="table">
                  <td class="table"></td>
                  <td class="table"> 3</td>
                  <td class="table"> 3</td>
                  <td class="table"> 1</td>
                  <td class="table"> 3</td>
                </tr>
                <tr class="table">
                  <td class="table"> BE</td>
                  <td class="table"> 1</td>
                  <td class="table"> 3</td>
                  <td class="table"> 0.33</td>
                  <td class="table"> 0</td>
                </tr>
                <tr class="table">
                  <td class="table"> BG</td>
                  <td class="table"> 2</td>
                  <td class="table"> 3</td>
                  <td class="table"> 0.67</td>
                  <td class="table"> 1.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> DE</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> DG</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> FA</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> FC</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> HA</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
                <tr class="table">
                  <td class="table"> HC</td>
                  <td class="table"> 1</td>
                  <td class="table"> 2</td>
                  <td class="table"> 0.5</td>
                  <td class="table"> 0.5</td>
                </tr>
              </tbody>
            </table>
          </content>
          <region class="TableInfo" id="140" confidence="possible" page="4" column="2">(a) (b) (c) Units Frequency TP Chunk strength xy x xy/x xyK((xKxy)*0.5) 3 3 1 3 2 2 1 2 2 2 1 2 3 3 1 3 BE 1 3 0.33 0 BG 2 3 0.67 1.5 DE 1 2 0.5 0.5 DG 1 2 0.5 0.5 FA 1 2 0.5 0.5 FC 1 2 0.5 0.5 HA 1 2 0.5 0.5 HC 1 2 0.5 0.5</region>
        </region>
        <outsider class="DoCO:TextBox" type="footer" id="141" page="4" column="2">www.sciencedirect.com</outsider>
        <outsider class="DoCO:TextBox" type="header" id="142" page="5" column="1">Review</outsider>
        <outsider class="DoCO:TextBox" type="header" id="143" page="5" column="1">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="144" page="5" column="1">237</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="145" confidence="possible" page="5" column="1">Box 4. Learning non-adjacent dependencies</h1>
        <region class="unknown" id="161" page="5" column="1">Both IL and SL approaches have focused on the human ability to detect and exploit the relations between elements in close temporal or spatial proximity. However, linguistic structures, as well as other domains of high-level knowledge such as music, also include remote dependencies. That is to say, a relation exists between two events, A and C, irrespective of the intervening events (X), as illustrated in (a) below. In the past few years, this has given rise to a set of studies investigating the possibility of learning non-adjacent dependencies in artificial languages [<xref ref-type="bibr" rid="R60" id="146" class="deo:Reference">60</xref>, <xref ref-type="bibr" rid="R61" hidden="1" id="147" class="deo:Reference">61</xref>, <xref ref-type="bibr" rid="R62" hidden="1" id="148" class="deo:Reference">62</xref>, <xref ref-type="bibr" rid="R63" id="149" class="deo:Reference">63</xref>] and in music [<xref ref-type="bibr" rid="R64" id="150" class="deo:Reference">64</xref>, <xref ref-type="bibr" rid="R65" id="151" class="deo:Reference">65</xref>] in incidental conditions. The results show a consensus that learning non-adjacent dependencies is possible, but under far more restrictive conditions than those required for learning the relations between contiguous events. Gomez [<xref ref-type="bibr" rid="R60" id="152" class="deo:Reference">60</xref>, <xref ref-type="bibr" rid="R66" id="153" class="deo:Reference">66</xref>] showed that the degree to which the AXC relationships are learned depends on the variability of the middle element (X). For Newport and Aslin (e.g. [<xref ref-type="bibr" rid="R61" id="154" class="deo:Reference">61</xref>]) and Onnis et al. [<xref ref-type="bibr" rid="R62" id="155" class="deo:Reference">62</xref>], the crucial factor is the similarity between A and C. Another facilitating condition is that the AXC units are displayed as individualized, pre-segmented units, rather than embedded within a continuous stream of stimuli. Closely related are studies in which the to-be learned stimuli are generated by a bi-conditional grammar [<xref ref-type="bibr" rid="R40" id="156" class="deo:Reference">40</xref>, <xref ref-type="bibr" rid="R47" id="157" class="deo:Reference">47</xref>], as in (b), or in which the dependencies are self-embedded [67,68,<xref ref-type="bibr" rid="R4" id="158" class="deo:Reference">4</xref>, <xref ref-type="bibr" rid="R67" id="159" class="deo:Reference">67</xref>, <xref ref-type="bibr" rid="R68" id="160" class="deo:Reference">68</xref>,4], as in (c). In these more complex cases, the possibility of obtaining evidence of learning in truly incidental conditions does not seem clearly established yet. Non adjacent dependency: The relation is between A and C, whatever X Biconditional grammar: The relations are between A and X, B and Y, etc. Self embedded dependencies: The relations are between A and X, B and Y, etc.</region>
        <region class="DoCO:TextChunk" id="164" page="5" column="1">construed differently. Starting from the postulate that chunks are the actual content of phenomenal experience, Perruchet and Vinter [<xref ref-type="bibr" rid="R48" id="162" class="deo:Reference">48</xref>, <xref ref-type="bibr" rid="R49" id="163" class="deo:Reference">49</xref>] outlined a view of the human mind in which consciousness is thought of as self- organized. In this model, the optimal coding of the incoming information occurs as a natural by-product of the evolution of conscious percepts and representations, under the action of simple associative learning and memory processes.</region>
      </section>
      <section class="deo:Conclusion">
        <h1 class="DoCO:SectionTitle" id="165" page="5" column="1">Conclusion</h1>
        <region class="DoCO:TextChunk" id="166" page="5" column="1">Recent evolution of research on both IL, initially aimed at studying rule abstraction in complex situations, and SL, initially focused on word segmentation, suggests that the two lines of research explore the same domain-general incidental learning processes. Bringing together these two domains of research, however, reveals a divergence between the interpretation favored in IL, which focuses on the formation of chunks, and the interpretation favored in SL, which relies on statistical computations. One possibility is that chunks are inferred from the results of (unconscious) statistical computations. Another possibility is that (perhaps conscious) chunks are formed from the outset and then evolve as a result of basic associative learning principles. It is clear that there are many challenges for future research in these two areas (see Box 5).</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="167" confidence="possible" page="5" column="2">Box 5. Questions for future research</h1>
        <region class="unknown" id="168" page="5" column="2">† Bringing together IL and SL domains of research suggests many directions for further studies, because each domain has explored a limited set of issues, and it appears necessary to confirm that the conclusions reached in one domain may be generalized to the experimental paradigms typical of the other one. The following two questions instantiate this research strategy. † A large part of the recent IL literature is concerned with the relative invariance of implicit learning mechanisms with age, in children and elderly people. Furthermore, several studies have investigated whether these mechanisms are preserved in people with mental retardation, and in patients with psychiatric and neurological disorders. Are results the same with the paradigms generally used in SL studies? Likewise, there has been some brain imaging studies of IL, and investigating whether the same neural regions would mediate SL would be of interest. † Although both IL and SL studies involve arbitrary materials, it turns out that these materials can never be considered to be completely neutral with regards to learning. For instance, participants may be guided towards (or diverted from) the discovery of its underlying structure by prior knowledge of related real situations, the acoustic or visual features of the materials, and so on. In SL research, the interactions between the statistical structure and the other features of the situations that might affect learning have been taken as a valuable problem of its own, especially in the context of lexicon formation in young children. Similar problems should be explored with the paradigms used in IL research. † Are conditional probabilities the main statistic to which human behavior is sensitive, as the literature on SL assumes? Research on conditioning has suggested that conditioned performances depend on more elaborate measures of association, such as Delta P or contingency. IL/SL research on this question has hardly scratched the surface in this area. † Irrespective of the importance given to chunks in the dynamics of learning, it seems essential to investigate this notion further. For instance, can chunks be thought of as the content of the attentional focus, or is it possible to assume the existence of functional chunks that participants would not be aware of?</region>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="169" confidence="possible" page="5" column="2">Acknowledgements</h1>
        <region class="DoCO:TextChunk" id="170" confidence="possible" page="5" column="2">This work was supported by grants from the Centre National de la Recherche Scientifique (CNRS, UMR 5022 and FRE 2987), from the Universit  ́ de Bourgogne, from the R  ́gion de Bourgogne (AAFE), and from the Universit  ́ Paris V. The authors thank Stephanie Chambaron, Suzanne Filipic, Bob French, Barbara Tillmann, and the anonymous reviewers of a first draft for their help at various stages of elaboration.</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="171" confidence="possible" page="5" column="2">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="172" page="5" column="2">1 Reber, A.S. (1967) Implicit learning of artificial grammars. J. Verbal Learn. Verbal Behav. 6, 855–863</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="173" page="5" column="2">2 Reber, A.S. (1993) Implicit Learning and Tacit Knowledge: An Essay on the Cognitive Unconscious, Oxford University Press</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="174" page="5" column="2">3 Cleeremans, A. et al. (1998) Implicit learning: News from the front. Trends Cogn. Sci. 2, 406–416</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="175" page="5" column="2">4 Shanks, D.R. (2005) Implicit learning. In Handbook of Cognition (Lamberts, K. and Goldstone, R., eds), pp. 202–220, Sage Publications</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="176" page="5" column="2">5 Saffran, J.R. et al. (1996) Statistical learning by 8-month-old infants. Science 274, 1926–1928</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="177" page="5" column="2">6 Fiser, J. and Aslin, R.N. (2001) Unsupervised statistical learning of higher-order spatial structures from visual scenes. Psychol. Sci. 12, 499–504</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="178" page="5" column="2">7 Fiser, J. and Aslin, R.N. (2002) Statistical learning of higher-order temporal structure from visual shape sequences. J. Exp. Psychol. Learn. Mem. Cogn. 28, 458–467</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="179" page="5" column="2">8 Turk-Browne, N.B. et al. (2005) The automaticity of visual statistical learning. J. Exp. Psychol. Gen. 134, 552–564</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="180" page="5" column="2">9 Fiser, J. and Aslin, R.N. (2005) Encoding multielement scenes: Statistical learning of visual features hierarchies. J. Exp. Psychol. Gen. 134, 521–537</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="185" page="6" column="1">10 Conway, C.M. and Christiansen, M.H. Statistical learning within and between modalities: Pitting abstract against stimulus-specific representations. Psychol. Sci. (in press)</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="186" page="6" column="1">11 Saffran, J.R. et al. (1999) Statistical learning of tone sequences by human infants and adults. Cognition 70, 27–52</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="187" page="6" column="1">12 Saffran, J.R. et al. (2005) Changing the tune: Absolute and relative pitch processing by adults and infants. Dev. Sci. 8, 1–7</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="188" page="6" column="1">13 Conway, C.M. and Christiansen, M.H. (2005) Modality-constrained statistical learning of tactile, visual, and auditory sequences. J. Exp. Psychol. Learn. Mem. Cogn. 31, 24–39</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="189" page="6" column="1">14 Saffran, J.R. (2001) The use of predictive dependencies in language learning. J. Mem. Lang. 44, 493–515</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="190" page="6" column="1">15 Saffran, J.R. and Wilson, D.P. (2003) From syllables to syntax: Multilevel statistical learning by 12-month-old infants. Infancy 4, 273–284</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="191" page="6" column="1">16 Hunt, R.H. and Aslin, R.N. (2001) Statistical learning in a serial reaction time task: Access to separable statistical cues by individual learners. J. Exp. Psychol. Gen. 130, 658–680</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="192" page="6" column="1">17 Kirkham, N.Z. et al. (2002) Visual statistical learning in infancy: Evidence for a domain general learning mechanism. Cognition 83, B35–B42</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="193" page="6" column="1">18 Shanks, D.R. et al. (2005) Attentional load and implicit sequence learning. Psychol. Res. 69, 369–382</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="194" page="6" column="1">19 Remillard, G. (2003) Pure perceptual-based sequence learning. J. Exp. Psychol. Learn. Mem. Cogn. 29, 581–597</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="195" page="6" column="1">20 Jiang, Y. and Chun, M.M. (2001) Selective attention modulates implicit learning. Q. J. Exp. Psychol. 54A, 1105–1124</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="196" page="6" column="1">21 Jiang, Y. and Leung, A-W. (2005) Implicit learning of ignored visual context. Psychon. Bull. Rev. 12, 100–106</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="197" page="6" column="1">22 Hoffmann, J. and Sebald, A. (2005) When obvious covariations are not even learned implicitly. Eur. J. Cog. Psychol 17, 449–480</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="198" page="6" column="1">23 Shanks, D.R. (2003) Attention and awareness in ‘implicit’ sequence learning. In Attention and Implicit Learning (Jim  ́nez, L., ed.), pp. 11–42, John Benjamins</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="199" page="6" column="1">24 Hsiao, A.T. and Reber, A.S. (1998) The role of attention on implicit sequence learning. In Handbook of Implicit Learning (Stadler, M.A. and Frensch, P., eds), pp. 471–494, Sage Publications</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="200" page="6" column="1">25 Toro, J.M. et al. (2005) Speech segmentation by statistical learning depends on attention. Cognition 97, B25–B34</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="201" page="6" column="1">26 Baker, C.I. et al. (2004) Role of attention and perceptual grouping in visual statistical learning. Psychol. Sci. 15, 460–466</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="202" page="6" column="1">27 Pothos, E.M. and Bailey, T.M. (2000) The role of similarity in artificial grammar learning. J. Exp. Psychol. Learn. Mem. Cogn. 26, 847–862</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="203" page="6" column="1">28 Buchner, A. et al. (1998) On the role of fragmentary knowledge in a sequence learning task. Q. J. Exp. Psychol. 51A, 251–281</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="204" page="6" column="1">29 Christiansen, M.H. et al. (1998) Learning to segment speech using multiple cues: A connectionist model. Lang. Cogn. Processes 13, 221–268</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="205" page="6" column="1">30 Perruchet, P. and Vinter, A. (1998) PARSER: A model for word segmentation. J. Mem. Lang. 39, 246–263</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="206" page="6" column="1">31 Cleeremans, A. and McClelland, J.L. (1991) Learning the structure of event sequences. J. Exp. Psychol. Gen. 120, 235–253</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="207" page="6" column="1">32 Cleeremans, A. (1993) Mechanims of Implicit Learning: A Connec- tionnist Model of Sequence Processing, MIT Press</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="208" page="6" column="1">33 Kinder, A. and Shanks, D.R. (2003) Neuropsychological dissociations between priming and recognition: a single-system connectionist account. Psychol. Rev. 110, 728–744</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="209" page="6" column="1">34 Tillmann, B. et al. (2000) Implicit learning of tonality: A self- organizing approach. Psychol. Rev. 107, 885–913</ref>
          <ref rid="R35" class="deo:BibliographicReference" id="210" page="6" column="1">35 Saffran, J.R. (2001) Words in a sea of sounds: The output of statistical learning. Cognition 81, 149–169</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="211" page="6" column="1">36 Meulemans, T. and Van der Linden, M. (2003) Implicit learning of complex information in amnesia. Brain Cogn. 52, 250–257</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="212" page="6" column="1">37 Jimenez, L. (2005) Chunk structure in implicit and explicit sequence learning, 2nd European Workshop on Movement Science (Vienna), Abstract No. 2.1.6</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="213" page="6" column="1">38 Anderson, J.R. and Lebiere, C. (1998) The Atomic Components of Thought, Erlbaum</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="214" page="6" column="1">39 Shanks, D.R. et al. Disruption of sequential priming in organic and pharmacological amnesia: A role for the medial temporal lobes in implicit contextual learning. Neuropsychopharmacology (in press)</ref>
          <ref rid="R40" class="deo:BibliographicReference" id="215" page="6" column="2">40 Shanks, D.R. et al. (2002) Modularity and artificial grammar learning. In Implicit Learning and Consciousness (French, R. and Cleeremans, A., eds), pp. 93–120, Psychology Press</ref>
          <ref rid="R41" class="deo:BibliographicReference" id="216" page="6" column="2">41 Servan-Schreiber, D. and Anderson, J.R. (1990) Learning artificial grammars with competitive chunking. J. Exp. Psychol. Learn. Mem. Cogn. 16, 592–608</ref>
          <ref rid="R42" class="deo:BibliographicReference" id="217" page="6" column="2">42 Aslin, R.N. et al. (1998) Computation of conditional probability statistics by 8-month-old infants. Psychol. Sci. 9, 321–324</ref>
          <ref rid="R43" class="deo:BibliographicReference" id="218" page="6" column="2">43 Chang, G.Y. and Knowlton, B.J. (2004) Visual feature learning in artificial grammar classification. J. Exp. Psychol. Learn. Mem. Cogn. 30, 714–722</ref>
          <ref rid="R44" class="deo:BibliographicReference" id="219" page="6" column="2">44 Perruchet, P. and Peereman, R. (2004) The exploitation of distribu- tional information in syllable processing. J. Neuroling. 17, 97–119</ref>
          <ref rid="R45" class="deo:BibliographicReference" id="220" page="6" column="2">45 Boucher, L. and Dienes, Z. (2003) Two ways of learning associations. Cogn. Sci. 27, 807–842</ref>
          <ref rid="R46" class="deo:BibliographicReference" id="221" page="6" column="2">46 Giroux, I. and Rey, A. (2005) Word and sub-word units in speech perception. Proceedings of the 46th Annual Meeting of the Psychonomic Society (Toronto), Abstract No. 3061</ref>
          <ref rid="R47" class="deo:BibliographicReference" id="222" page="6" column="2">47 Kuhn, G. and Dienes, Z. Implicit learning of non-local musical rules. J. Exp. Psychol. Learn. Mem. Cogn. (in press)</ref>
          <ref rid="R48" class="deo:BibliographicReference" id="223" page="6" column="2">48 Perruchet, P. (2005) Statistical approaches to language acquisition and the self-organizing consciousness: A reversal of perspective. Psychol. Res. 69, 316–329</ref>
          <ref rid="R49" class="deo:BibliographicReference" id="224" page="6" column="2">49 Perruchet, P. and Vinter, A. (2002) The self-organizing consciousness. Behav. Brain Sci. 25, 297–388</ref>
          <ref rid="R50" class="deo:BibliographicReference" id="225" page="6" column="2">50 Marcus, G.F. et al. (1999) Rule learning by seven-month-old infants. Science 283, 77–80</ref>
          <ref rid="R51" class="deo:BibliographicReference" id="226" page="6" column="2">51 Dienes, Z. and Altmann, G. (1997) Transfer of implicit knowledge across domains: How implicit and how abstract?. In How Implicit is Implicit Learning? (Berry, D., ed.), pp. 107–123, Oxford University Press</ref>
          <ref rid="R52" class="deo:BibliographicReference" id="227" page="6" column="2">52 Pacton, S. et al. (2001) Implicit learning out of the lab: The case of orthographic regularities. J. Exp. Psychol. Gen. 130, 401–426</ref>
          <ref rid="R53" class="deo:BibliographicReference" id="228" page="6" column="2">53 Pacton, S. et al. (2005) Children’s implicit learning of graphotactic and morphological regularities. Child Dev. 76, 324–339</ref>
          <ref rid="R54" class="deo:BibliographicReference" id="229" page="6" column="2">54 Vokey, J.R. and Higham, P.A. (2005) Abstract analogies and positive transfer in artificial grammar learning. Can. J. Exp. Psychol. 59, 54–61</ref>
          <ref rid="R55" class="deo:BibliographicReference" id="230" page="6" column="2">55 Gomez, R.L. (1997) Transfer and complexity in artificial grammar learning. Cogn. Psychol. 33, 154–207</ref>
          <ref rid="R56" class="deo:BibliographicReference" id="231" page="6" column="2">56 Redington, M. and Chater, N. (2002) Knowledge representation and transfer in artificial grammar learning. In Implicit Learning and Consciousness (French, R. and Cleeremans, A., eds), pp. 121–143, Psychology Press</ref>
          <ref rid="R57" class="deo:BibliographicReference" id="232" page="6" column="2">57 Gomez, R.L. et al. (2000) The basis of transfer in artificial grammar learning. Mem. Cogn. 28, 253–263</ref>
          <ref rid="R58" class="deo:BibliographicReference" id="233" page="6" column="2">58 Tunney, R.J. and Altmann, G.T.M. (2001) Two modes of transfer in artificial grammar learning. J. Exp. Psychol. Learn. Mem. Cogn. 27, 614–639</ref>
          <ref rid="R59" class="deo:BibliographicReference" id="234" page="6" column="2">59 Perruchet, P. et al. (2002) The formation of structurally relevant units in artificial grammar learning. Q. J. Exp. Psychol. 55A, 485–503</ref>
          <ref rid="R60" class="deo:BibliographicReference" id="235" page="6" column="2">60 Gomez, R. (2002) Variability and detection of invariant structure. Psychol. Sci. 13, 431–436</ref>
          <ref rid="R61" class="deo:BibliographicReference" id="236" page="6" column="2">61 Newport, E.L. and Aslin, R.N. (2004) Learning at a distance: I. Statistical learning of non-adjacent dependencies. Cogn. Psychol. 48, 127–162</ref>
          <ref rid="R62" class="deo:BibliographicReference" id="237" page="6" column="2">62 Onnis, L. et al. (2005) Phonology impacts segmentation in online speech processing. J. Mem. Lang. 53, 225–237</ref>
          <ref rid="R63" class="deo:BibliographicReference" id="238" page="6" column="2">63 Perruchet, P. et al. (2004) Learning non-adjacent dependencies: No need for algebraic-like computations. J. Exp. Psychol. Gen. 133, 573–583</ref>
          <ref rid="R64" class="deo:BibliographicReference" id="239" page="6" column="2">64 Creel, S.C. et al. (2004) Distant melodies: Statistical learning of nonadjacent dependencies in tone sequences. J. Exp. Psychol. Learn. Mem. Cogn. 30, 1119–1130</ref>
          <ref rid="R65" class="deo:BibliographicReference" id="240" page="6" column="2">65 Dienes, Z. and Longuet-Higgins, C. (2004) Can musical transform- ations be implicitly learned? Cogn. Sci. 28, 531–558</ref>
          <ref rid="R66" class="deo:BibliographicReference" id="241" page="6" column="2">66 Gomez, R.L. and Maye, J. (2005) The developmental trajectory of nonadjacent dependency learning. Infancy 7, 183–206</ref>
          <ref rid="R67" class="deo:BibliographicReference" id="242" page="6" column="2">67 Poletiek, F.H. (2002) Implicit learning of a recursive rule in an artificial grammar. Acta Psychol. (Amst.) 111, 323–335</ref>
          <ref rid="R68" class="deo:BibliographicReference" id="243" page="6" column="2">68 Perruchet, P. and Rey, A. (2005) Does the mastery of center-embedded linguistic structures distinguish humans from nonhuman primates? Psychonomic Bull. Rev. 12, 307–313</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="footer" id="181" page="5" column="2">www.sciencedirect.com</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="182" page="6" column="1">238</outsider>
        <outsider class="DoCO:TextBox" type="header" id="183" page="6" column="1">Review</outsider>
        <outsider class="DoCO:TextBox" type="header" id="184" page="6" column="1">TRENDS in Cognitive Sciences Vol.10 No.5 May 2006</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="244" page="6" column="2">www.sciencedirect.com All in-text references underlined in blue are linked to publications on ResearchGate, letting you access and read them immediately.</outsider>
      </section>
    </body>
  </article>
</pdfx>
