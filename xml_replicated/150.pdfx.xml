<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>1c59b34506f268c0f6b248c33d8e60d75746f21d961ddc42c91f516ba7d9f136</job>
    <base_name>10</base_name>
    <doi>http://dx.doi.org/10.1111/j.1467-9280.2008.02044.x</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="1">P SY CH OL OG I C AL S CIE N CE</outsider>
      <region class="unknown" id="2">Research Article</region>
      <title-group>
        <article-title class="DoCO:Title" id="3">Sensitivity to Object Viewpoint and Action Instructions During Search for Targets in the Lower Visual Field Sara Forti 1,2 and Glyn W. Humphreys 1</article-title>
      </title-group>
      <region class="unknown" id="4">1 Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, and 2 Neuropsychology Unit, IRCCS ‘‘Eugenio Medea,’’ Bosisio Parini, Italy</region>
      <abstract class="DoCO:Abstract" id="5">ABSTRACT— We contrasted visual search for targets presented in prototypical views and targets presented in nonprototypical views, when targets were defined by their names and when they were defined by the action that would normally be performed on them. The likelihood of the first fixation falling on the target was increased for prototypical- view targets falling in the lower visual field. When targets were defined by actions, the durations of fixations were reduced for targets in the lower field. The results are consistent with eye movements in search being affected by representations within the dorsal visual stream, where there is strong representation of the lower visual field. These representations are sensitive to the familiarity or the affordance offered by objects in prototypical views, and they are influenced by action-based templates for targets.</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <region class="DoCO:TextChunk" id="7" page="1" column="1">In visual search tasks, participants are typically asked to detect particular targets presented among varying numbers of distractors. How the target is defined appears to affect the nature of the search process. <xref ref-type="bibr" rid="R9" id="6" class="deo:Reference">Humphreys and Riddoch (2001)</xref> reported data from a patient with unilateral visual neglect, who frequently failed to detect targets on the side of space contralateral to his lesion when targets were defined by their names. However, this neglect was strikingly reduced when the patient was asked to find targets that were defined by the action that would be performed on them (e.g., ‘‘find the object to drink from’’ vs. ‘‘find the cup’’). To account</region>
      <region class="DoCO:TextChunk" id="8" confidence="possible" page="1" column="1">Address correspondence to Glyn W. Humphreys, Behavioural Brain Sciences Centre, School of Psychology, University of Birmingham, Birmingham B15 2TT, United Kingdom, e-mail: g.w.humphreys@ bham.ac.uk.</region>
      <region class="DoCO:TextChunk" id="28" page="1" column="2">for these findings, the authors suggested that the patient was able to match input with a template based on the action, but was unable to match input with a template derived from the name of the object. This was true even though the patient knew what each object was from its name, and even though he showed normal identifi- cation of single objects. The patient may have been able to main- tain the action template better than any visual template derived from the object’s name, so that an action template helped him sustain search on the affected side; alternatively, the patient may have been able to respond to affordances that were computed in- dependently of an object’s identity and that were detectable from objects on both the ipsi- and contralesional sides of space. A study by <xref ref-type="bibr" rid="R1" id="9" class="deo:Reference">Bekkering and Neggers (2002)</xref> provides converg- ing evidence from normal observers. In this study, participants either pointed to or grasped a target defined by a conjunction of its orientation and color. Saccades to distractors having the same orientation as the target were more likely when a grasping response was made than when a pointing response was made. This suggests that contrasting actions can differentially weight visual information, with orientation being weighted more strongly for selection when a grasping rather than a pointing response is required (see also Hannus, Cornelissen, Lindemann, &amp; <xref ref-type="bibr" rid="R6" id="10" class="deo:Reference">Bekkering, 2005</xref>). These data are consistent with models in which search can be guided in a top-down fashion by templates defined by the target or the action to be made with the target (cf. <xref ref-type="bibr" rid="R3" id="11" class="deo:Reference">Duncan &amp; Humphreys, 1989</xref>; Moores, Laiti, &amp; <xref ref-type="bibr" rid="R11" id="12" class="deo:Reference">Chelazzi, 2003</xref>; <xref ref-type="bibr" rid="R15" id="13" class="deo:Reference">Wolfe, 1994</xref>). Apparently, holding a template for a particular action and holding a template based on a visual definition of an object can shape the search process differently. In the study reported in this article, we sought to examine further the contrast between searching for a target defined by an<marker type="page" number="2"/><marker type="column" number="1"/><marker type="block"/> action and searching for a target defined by its name. We measured eye movements while normal participants searched for named-defined and action-defined targets. Performance was analyzed separately for trials with targets in the upper visual field and trials with targets in the lower visual field. The dorsal area of V1 represents the lower visual field and projects primarily to the dorsal visual pathway, whereas the ventral area of V1 represents the upper visual field and projects primarily to the ventral visual pathway (<xref ref-type="bibr" rid="R8" id="19" class="deo:Reference">Horton &amp; Hoyt, 1991</xref>; <xref ref-type="bibr" rid="R14" id="20" class="deo:Reference">Previc, 1990</xref>). Thus, there are stronger projections from the lower visual field than from the upper visual field into posterior parietal cortex (e.g., area V6A; Galletti, Fattori, Gamberini, &amp; <xref ref-type="bibr" rid="R4" id="21" class="deo:Reference">Kutz, 1999</xref>). It is possible that searching by action and searching by name differentially recruit the dorsal and ventral visual pathways to support performance. <xref ref-type="bibr" rid="R10" id="22" class="deo:Reference">Milner and Goodale (1993)</xref>, for example, argued that the ventral pathway is functionally specialized for object recognition (the ‘‘what’’ pathway) and the dorsal pathway is functionally specialized for the actions linked to objects (the ‘‘how’’ pathway; see also <xref ref-type="bibr" rid="R2" id="23" class="deo:Reference">Creem &amp; Proffitt, 2001</xref>). It may follow that searching by action, recruiting the dorsal visual stream, favors information in the lower visual field. In addition, <xref ref-type="bibr" rid="R14" id="24" class="deo:Reference">Previc (1990)</xref> argued that because the lower visual field represents near space, neural regions responding to this area are specialized for the analysis of features relevant to actions with objects in near space. In contrast, searching for an object defined by its name may favor information in the upper visual field, which may be more specialized for distal properties of objects tied to their identity (cf. <xref ref-type="bibr" rid="R14" id="25" class="deo:Reference">Previc, 1990</xref>). In addition to examining the effects of instruction, we evalu- ated search for targets in prototypical relative to nonprototypical views. Though the time needed to recognize objects and to de- rive action-related information about objects should be less for stimuli in prototypical views than for stimuli in nonprototypical views (e.g., Palmer, Rosch, &amp; <xref ref-type="bibr" rid="R13" id="26" class="deo:Reference">Chase, 1981</xref>), this effect may be most pronounced for action decisions and for neural regions responsive to action affordances from objects. For example, in Humphreys and Riddoch’s (2001) study of neglect, the benefits for searching by action occurred when objects appeared in prototypical views for action. Similarly, <xref ref-type="bibr" rid="R16" id="27" class="deo:Reference">Yoon and Humphreys (2007)</xref> reported that compared with semantic decisions made in response to objects, action decisions are more sensitive to viewpoint. Accordingly, dorsal regions, which are sensitive to action, might be particularly affected by viewpoint.</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="15" page="1" column="2">42</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="16" page="1" column="2">Downloaded from Copyright pss.sagepub.com r 2008 at Association Bobst Library, New for Psychological York University on Science April 19, 2016</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="17" page="1" column="2">Volume 19—Number 1</outsider>
      <outsider class="DoCO:TextBox" type="header" id="18" page="2" column="1">Sara Forti and Glyn W. Humphreys</outsider>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="29" page="2" column="1">METHOD</h1>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="30" confidence="possible" page="2" column="1">Participants</h2>
          <region class="DoCO:TextChunk" id="31" page="2" column="1">The 14 participants (11 females and 3 males; ages 17–39 years, M 5 25.7) were all right-handed and had either normal or cor- rected-to-normal vision.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="32" confidence="possible" page="2" column="1">Apparatus</h2>
          <region class="DoCO:TextChunk" id="34" page="2" column="1">The experiment was controlled by a 1.5-GHz Pentium IV com- puter. Stimuli were presented on a Trinitron Multiscan G240 <marker type="column" number="2"/><marker type="block"/> monitor (17 in.), using a screen resolution of 600 Â 800 pixels. The display height was adjusted for each participant by setting the height of the chair he or she sat on. Eye movements were recorded using a head-mounted eyetracker (SMI Eyelink V2.04; SensoMotoric Instruments GmbH, Berlin, Germany) with a sam- pling rate of 250 Hz. Responses were registered using a button box.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="35" confidence="possible" page="2" column="2">Procedure</h2>
          <region class="DoCO:TextChunk" id="45" page="2" column="2">The display sequence is depicted in <xref ref-type="fig" rid="F1a" id="36" class="deo:Reference">Figure 1a</xref>. Each trial started with a black fixation point, shown against a white background screen. The duration of this display was unlimited. When ready, the participant pressed a button to remove the fixation point, and the instructions regarding what to search for were displayed for 2,000 ms (black text on a white background). A second fixation point (600 ms) preceded the stimulus display, which remained present until the participant responded. Participants were in- structed to look for and to fixate the target; once they were sure they had found the target, they were to press a button to end the trial. The speed of the button-press response was not empha- sized. The target was present in all trials. Presentation of stimuli was self-paced, and subjects were allowed to take an unlimited number of breaks. The stimuli were black-and-white photographs of real objects (see <xref ref-type="fig" rid="F1b" id="37" class="deo:Reference">Fig. 1b</xref>). On any trial, all the stimuli were depicted in either a prototypical or a nonprototypical view (view was randomized across trials). When an object was depicted in a prototypical view, all its main features were visible, and the object was aligned for action. In the nonprototypical view, the object was rotated away from its usual view, and it was not oriented for a right-hand action; typically, the graspable part of the object was positioned toward the nondominant (left) hand (for our right- handed participants).<marker type="page" number="3"/><marker type="column" number="1"/><marker type="block"/> Each photograph was inscribed into an area measuring 100 Â 100 pixels (4.61 Â 4.61 at a viewing distance of 60 cm), and the relative size of the objects was taken into account (e.g., a bicycle was bigger than a pen). Within each display, eight stimuli were presented in a circle with a radius of 170 pixels (7.41); the two middle objects were placed at eye level, in order to have the three upper objects falling in the upper visual field and the three lower objects falling in the lower visual field. The target’s position was randomized across trials. In the analyses, we ex- cluded trials in which the target was one of the two middle objects, considering only stimuli in the upper and lower visual fields. There were two instruction conditions, presented in two sep- arate blocks of 240 trials each, and block order was randomized across participants. In the name condition, the participants were given the names of the objects they had to look at (e.g., ‘‘scis- sors’’); in the action condition, each target was defined by the associated action (e.g., ‘‘cut paper’’). Thus, the target was am- biguously specified in the action condition, because there are typically multiple objects consistent with a given action. However, within a search display, there was only one object consistent with the instructions given (i.e., only one object with the name given in name search and only one object consistent with the action given in action search). We used a set of 60 familiar objects; 20 that could be defined either by a name or by a specific action were used as targets, and the remaining 40 were always used as distractors.</region>
          <region class="DoCO:FigureBox" id="F1">
            <image class="DoCO:Figure" src="10.page_002.image_01.png" thmb="10.page_002.image_01-thumb.png"/>
            <caption class="deo:Caption" id="40" page="2" column="2">Fig. 1. Illustration of the display sequence (a) and of an object in its prototypical and nonprototypical views (b). The example sequence shown here is from the name condition.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="footer" id="41" page="2" column="2">Volume 19—Number 1</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="42" page="2" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="43" page="2" column="2">43</outsider>
          <outsider class="DoCO:TextBox" type="header" id="44" page="3" column="1">Object Viewpoint, Visual Field, and Action Instructions During Search</outsider>
        </section>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="46" page="3" column="1">RESULTS</h1>
        <region class="DoCO:TextChunk" id="47" page="3" column="1">We considered the effects of three variables: the instructions (search by name vs. search by action), the viewpoint (prototypical vs. nonprototypical), and the target’s visual field (upper vs. lower). 1 The data were analyzed in three-way repeated measures analyses of variance. Including only correct trials (i.e., those on which the target was eventually fixated), we measured (a) the probability that the first fixation was on the target, (b) the time taken until the first fixation on the target, (c) the duration of the first fixation on the target, (d) the total number of fixations on the target, and (e) the total length of fixations on the target (summed across different fixations in a trial).</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="48" confidence="possible" page="3" column="1">Number of Fixations on the Target Probability of the First Fixation Being on the Target</h2>
          <region class="DoCO:TextChunk" id="49" page="3" column="1">The probability of the first fixation being on the target showed a significant effect of viewpoint, F(1, 13) 5 50.3, p rep &gt; .99: Prototypical-view targets received more first fixations (M 5 12.2%) than nonprototypical-view targets (M 5 5.3%). There</region>
          <region class="DoCO:TextChunk" id="52" confidence="possible" page="3" column="1">1 We also examined effects of whether items fell in the left or right visual field, because some studies indicate differences between the upper and lower visual fields on either only the left side (<xref ref-type="bibr" rid="R12" id="50" class="deo:Reference">Niebauer &amp; Christman, 1998</xref>) or only the right side (Handy, Grafton, Shroff, Ketay, &amp; <xref ref-type="bibr" rid="R5" id="51" class="deo:Reference">Gazzaniga, 2003</xref>), depending on the task. However, we failed to find effects of left versus right field. Hence, the data are averaged across this factor.</region>
          <region class="DoCO:TextChunk" id="54" page="3" column="2">was also a significant main effect of the target’s visual field, F(1, 13) 5 22.6, p rep &gt; .99, with targets in the lower visual field receiving more first fixations (M 5 12.2%) than targets in the upper visual field (M 5 5.3%). These two factors interacted, F(1, 13) 5 14.2, p rep &gt; .99: The effect of visual field was enhanced for objects depicted in a prototypical orientation, though visual field was significant for both views. There was no main effect of instructions, F(1, 13) 5 1.2, p rep 5 .64, and no interactions involving this factor were significant (all Fs &lt; .0). The results for this dependent measure are depicted in the top panel of <xref ref-type="fig" rid="F2" id="53" class="deo:Reference">Figure 2</xref>.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="55" confidence="possible" page="3" column="2">Time Until the First Fixation on the Target</h2>
          <region class="DoCO:TextChunk" id="57" page="3" column="2">This measure showed no reliable effects (see <xref ref-type="fig" rid="F2" id="56" class="deo:Reference">Fig. 2</xref>, bottom panel).</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="58" confidence="possible" page="3" column="2">Duration of the First Fixation on the Target</h2>
          <region class="DoCO:TextChunk" id="72" page="3" column="2">The duration of the first fixation on the target showed a reliable main effect of viewpoint, with longer fixations to nonprototypical than to prototypical targets, F(1, 13) 5 10.33, p rep 5 .852, but no effects of instructions or the target’s visual field, F(1, 13) 5 2.46 and F &lt; 1.0, both p rep s &lt; .88. There was an interaction between the type of instruction and the target’s visual field, F(1, 13) 5 10.926, p rep 5 .86. In the action condition, first-fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13) 5 2.1, p rep 5 .88. In the name condition, the durations of the first fixation on the target were, if anything, shorter for targets in the upper than for those in the lower visual field, t(13) 5 1.8, p rep 5 .82. We also found a reliable interaction between instructions and viewpoint, F(1, 13) 5 17.88, p rep &gt; .99: First fixations to targets in prototypical viewers were shorter than first fixations to targets in nonprototypical views in the action condition, t(13) 5 3.8, p rep 5 .98, but not in the name condition, t(13) 5 1.4, p rep 5 .74. Finally, there was a reliable three-way interaction among instructions, viewpoint, and visual field, F(1, 13) 5 6.44, p rep 5 .92 (see <xref ref-type="fig" rid="F3" id="59" class="deo:Reference">Fig. 3</xref>, top panel). The effects of viewpoint were pronounced only in the action condition for targets in the upper field, t(13) 5 À3.8, p rep 5 .98.<marker type="block"/> The number of fixations on the target (prior to responding to finding the target) showed a reliable main effect of viewpoint, F(1, 13) 5 6.23, p rep 5 .91; there were more fixations on nonprototypical-view than on prototypical-view targets. The effect of instructions was not reliable, F(1, 13) 5 1.06, p rep 5 .63, though the main effect of the target’s visual field approached significance, F(1, 13) 5 3.81, p rep 5 .85. There was an interaction between instructions and visual field, F(1, 13) 5 5.98, p rep 5 .91. In the action condition, fewer fixations were made to targets in the lower visual field than to targets in the upper visual field, t(13) 5 3.0, p 5 .95; in the name condition, there was no<marker type="page" number="4"/><marker type="column" number="1"/><marker type="block"/> effect of visual field, t(13) 5 0.3, p rep 5 .29. These effects held across both prototypical and nonprototypical views, F(1, 13) &lt; 1.0 for the interaction of instructions, viewpoint, and visual field. The bottom panel in <xref ref-type="fig" rid="F3" id="69" class="deo:Reference">Figure 3</xref> presents the mean numbers of fixations on targets.<marker type="block"/> Total Length of Fixations on the Target This measure showed a main effect of viewpoint, F(1, 13) 5 7.50, p rep 5 .93, with total fixation time being longer for nonprototypical than for prototypical objects; the main effect of instructions was not reliable (F &lt; 1.0), but that of field approached significance, F(1, 13) 5 4.00, p rep 5 .85. There was one reliable interaction, between instructions and visual field, F(1, 13) 5 5.18, p rep &gt; .89. In the action condition, fixation durations were shorter for targets in the lower visual field than for targets in the upper visual field, t(13) 5 2.7, p rep 5 .93; in the name condition, there was no effect of visual field, t(13) 5 0.3, p rep 5 .33. The data are shown in the middle panel of <xref ref-type="fig" rid="F3" id="71" class="deo:Reference">Figure 3</xref>.</region>
          <region class="unknown" id="62" page="3" column="2">rep</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="63" page="3" column="2">44</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="64" page="3" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="65" page="3" column="2">Volume 19—Number 1</outsider>
          <outsider class="DoCO:TextBox" type="header" id="66" page="4" column="1">Sara Forti and Glyn W. Humphreys</outsider>
          <region class="DoCO:FigureBox" id="F2">
            <image class="DoCO:Figure" src="10.page_004.image_02.png" thmb="10.page_004.image_02-thumb.png"/>
            <caption class="deo:Caption" id="68" page="4" column="1">Fig. 2. Probability of the first fixation falling on the target (top panel) and mean time taken before first fixations to targets (bottom panel), as a function of viewpoint, visual field, and instructions (search by name vs. action).</caption>
          </region>
        </section>
      </section>
      <section class="deo:Discussion">
        <h1 class="DoCO:SectionTitle" id="73" page="4" column="1">DISCUSSION</h1>
        <region class="DoCO:TextChunk" id="92" page="4" column="1">Search varied as a function of the orientation of the stimuli and the instructions given for the search task. We discuss each effect in turn. Generally, we found an effect of orientation in four of the five eye movement parameters measured, with performance being facilitated for stimuli depicted in a prototypical view. <marker type="column" number="2"/><marker type="block"/> Thus, compared with nonprototypical-view targets, prototypical-view targets were more likely to receive first fixations, had shorter total fixation durations, and required fewer fixations before the detection response was initiated. These effects of viewpoint are consistent with the literature on object recognition and on action decisions in response to objects, which shows that the familiarity of view is a strong determiner of performance (<xref ref-type="bibr" rid="R13" id="75" class="deo:Reference">Palmer et al., 1981</xref>; <xref ref-type="bibr" rid="R16" id="76" class="deo:Reference">Yoon &amp; Humphreys, 2007</xref>). Interestingly, though, viewpoint interacted with visual field when the probability of making a first fixation to a target and the duration of the first fixation to the target were measured. The increased probability of making a first fixation to a prototypical-view target was more pronounced when the target was in the lower visual field than when it was in the upper visual field. The instruction manipulation influenced several other eye movement parameters. Specifically, the action instructions facilitated performance as measured by parameters reflecting eye movements after targets had been fixated (<xref ref-type="fig" rid="F3" id="77" class="deo:Reference">Fig. 3</xref>). These effects were confined to targets falling in the lower visual field. The duration of the first fixation made to the target, the number of fixations made to the target before the detection response was made, and the average total length of the fixations on the target were all selectively reduced for targets in the lower visual field in the action condition. When objects were cued by their names, these effects of field were absent (if anything, there was a tendency for the duration of the first fixations on targets to be reduced for targets in the upper visual field).<marker type="page" number="5"/><marker type="column" number="1"/><marker type="block"/> To understand these results, it is useful to differentiate between effects on the first saccade made in search and effects on subsequent fixation behavior. The probability of the first saccade being directed at a target was affected by the orientation of the stimuli and the visual field of the target, but not by the instructions. The first saccade was more likely to go to a prototypical-view than to a nonprototypical-view target, but only when that target fell in the lower visual field; indeed, only when a<marker type="column" number="2"/><marker type="block"/> prototypical-view target fell in the lower visual field was the likelihood of the first fixation going to the target greater than chance. In many search tasks, search is biased to start in the upper visual field (<xref ref-type="bibr" rid="R7" id="86" class="deo:Reference">Heywood &amp; Churcher, 1980</xref>). However, there was no evidence for such a bias in the present study. We cal- culated the probability of the first saccade being directed toward the upper versus the lower visual field, irrespective of the target’s location, and found no difference in the rate of downward<marker type="page" number="6"/><marker type="column" number="1"/><marker type="block"/> versus upward saccades, either as a main effect, F(1, 13) 5 3.09, p rep 5 .81, or in combination with instructions or viewpoint (both Fs &lt; 1.0). The data suggest that there was no systematic tendency, across participants, for search to start or end in set locations. The tendency for first fixations to go to a prototypical- view target in the lower field, then, does not reflect a general pattern in search, but rather reflects the capture of overt attention by the stimulus. This result is consistent with the prototypical-view target being detected by the dorsal visual stream prior to the eye movement being programmed—so that the effect emerged only when the target was in the lower visual field. The data suggest that the dorsal stream is sensitive to either the familiarity of the viewpoint or the affordance when the object is in the appropriate orientation for action. Viewpoint had an early effect on search, influencing where the first saccade was made. However, the task instructions did affect fixation behavior after the first saccade. Fixation durations were reduced, and fewer fixations were made, when targets were in the lower visual field and the action instructions were given. In the name condition, first-fixation durations tended to be reduced for targets in the upper visual field. These results suggest that the different task instructions affected a stage of processing in which fixated information was matched to a template defining the target. There appears to be a better match of stimulus information to an action-based template for a target falling in the lower, rather than the upper, visual field, whereas, if anything, there is a better match to a template derived from the object’s name when the target is in the upper, rather than the lower, visual field. This fit to the template in the action task is also better for objects depicted in prototypical views, given that the duration of the first fixation in this condition was shorter for targets in prototypical views than for targets in nonprototypical views. These results are consistent with action-based templates being represented in the dorsal visual stream. 2 Although action instructions reduced the duration of the first fixation to targets in the lower visual field, first fixations were much longer under action than name instructions when targets fell in the upper visual field. This is not surprising. There is inherently more ambiguity about targets defined by action than about targets defined by their name (‘‘Is there an object that cuts paper present?’’ vs. ‘‘Are scissors present?’’), and one can thus expect that it would take more time to verify that a target matches a verbal instruction under action than under name instructions. The striking result is that this advantage for the name condition was reversed for targets in the lower field, which suggests that an action template was matched directly to the stimulus in this case. It should be noted that once an observer makes a first saccade to an item in the upper or lower visual field, that item is no longer</region>
        <outsider class="DoCO:TextBox" type="footer" id="79" page="4" column="2">Volume 19—Number 1</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="80" page="4" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="81" page="4" column="2">45</outsider>
        <outsider class="DoCO:TextBox" type="header" id="82" page="5" column="1">Object Viewpoint, Visual Field, and Action Instructions During Search</outsider>
        <region class="DoCO:FigureBox" id="F3">
          <image class="DoCO:Figure" src="10.page_005.image_03.png" thmb="10.page_005.image_03-thumb.png"/>
          <caption class="deo:Caption" id="84" page="5" column="1">Fig. 3. Mean duration of the first fixation on the target (top panel), mean total length of fixations on the target (middle panel), and mean number of fixations on the target (bottom panel), as a function of viewpoint, visual field, and instructions (search by name vs. action).</caption>
        </region>
        <outsider class="DoCO:TextBox" type="page_nr" id="88" page="5" column="2">46</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="89" page="5" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="90" page="5" column="2">Volume 19—Number 1</outsider>
        <outsider class="DoCO:TextBox" type="header" id="91" page="6" column="1">Sara Forti and Glyn W. Humphreys</outsider>
        <region class="DoCO:TextChunk" id="93" confidence="possible" page="6" column="1">2 The action effects reported here may also reflect processing in the premotor cortex and the frontal eye fields, which is related to action planning, but we know of no evidence indicating a field preference in these cortical regions.</region>
        <region class="DoCO:TextChunk" id="96" page="6" column="2">in the same retinotopic location, though the object remains in the same position with respect to the observer’s body. Also, after the first saccade, objects originally in the lower visual field may tend still to be represented in near space, and objects originally in the upper visual field to be represented in far space (cf. <xref ref-type="bibr" rid="R14" id="94" class="deo:Reference">Previc, 1990</xref>). If processing biases in the dorsal stream are sensitive to the position of objects with respect to the observer’s body, or if the dorsal stream is more sensitive to object locations in near space than to object locations in far space, then the emergence of the lower-field advantage in searching by action can be explained. In addition, it is possible that the advantage of the lower visual field reflects the superior extraction of information from the retinotopic lower field, which then facilitates matching to the action template. The opposite tendency, for an upper-field advantage in searching for objects defined by their names, also arose for fixation behavior subsequent to the first saccade, which suggests that this tendency, too, reflects a process involving matching to memory, rather than directing attention in the first place. In conclusion, the data indicate that action instructions and viewpoint-dependent familiarity or affordance have specific effects on search for objects appearing in the lower visual field. The results fit with the idea that the dorsal visual stream, where there is strong representation of the lower visual field, can both direct overt attention (the first saccade) and modulate the time required to match a stimulus to a template of the target.<marker type="block"/> Acknowledgments—This work was supported by grants from the Biotechnology and Biological Sciences Research Council, Engineering and Physical Sciences Research Council, and Med- ical Research Council (UK).</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="97" page="6" column="2">REFERENCES</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="98" page="6" column="2">Bekkering, H., &amp; Neggers, S.F.W. (2002). Visual search is modulated by action intentions. Psychological Science, 13, 370–374.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="99" confidence="possible" page="6" column="2">Creem, S.H., &amp; Proffitt, D.R. (2001). Defining the cortical visual systems: ‘‘What’’, ‘‘Where’’, and ‘‘How.’’ Acta Psychologica, 107, 43–68.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="100" confidence="possible" page="6" column="2">Duncan, J., &amp; Humphreys, G.W. (1989). Visual search and stimulus similarity. Psychological Review, 96, 433–458.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="101" confidence="possible" page="6" column="2">Galletti, C., Fattori, P., Gamberini, M., &amp; Kutz, D.F. (1999). The cortical visual area V6: Brain location and visual topography. Eu- ropean Journal of Neuroscience, 11, 3922–3936.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="102" confidence="possible" page="6" column="2">Handy, T.C., Grafton, S.T., Shroff, N.M., Ketay, S., &amp; Gazzaniga, M.S. (2003). Graspable objects grab attention when the potential for action is recognized. Nature Neuroscience, 6, 421–427.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="103" confidence="possible" page="6" column="2">Hannus, A., Cornelissen, F.W., Lindemann, O., &amp; Bekkering, H. (2005). Selection-for-action in visual search. Acta Psychologica, 118, 171–191.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="104" confidence="possible" page="6" column="2">Heywood, S., &amp; Churcher, J. (1980). Structure of the visual array and saccadic latency: Implications for oculomotor control. Quarterly Journal of Experimental Psychology, 32, 335–341.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="105" confidence="possible" page="6" column="2">Horton, J.C., &amp; Hoyt, W.F. (1991). Quadrantic visual-field defects: A hallmark of lesions in extrastriate (V2/V3) cortex. Brain, 114, 1703–1718.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="110" page="7" column="1">Humphreys, G.W., &amp; Riddoch, M.J. (2001). Detection by action: Evidence for affordances in search in neglect. Nature Neuroscience, 4, 84–88.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="111" confidence="possible" page="7" column="1">Milner, A.D., &amp; Goodale, M.A. (1993). Visual pathways to perception and action. Progress in Brain Research, 95, 317–337.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="112" confidence="possible" page="7" column="1">Moores, E., Laiti, L., &amp; Chelazzi, L. (2003). Associative knowledge controls deployment of visual selective attention. Nature Neuroscience, 6, 182–189.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="113" confidence="possible" page="7" column="1">Niebauer, C.L., &amp; Christman, S.D. (1998). Upper and lower visual field differences in categorical and coordinate judgments. Psychonomic Bulletin &amp; Review, 5, 147–151.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="114" confidence="possible" page="7" column="1">Palmer, S., Rosch, E., &amp; Chase, P. (1981). Canonical perspective and the perception of objects. In J.B. Long &amp; A.D. Baddeley (Eds.), Attention and performance, IX (pp. 135–151). Hillsdale, NJ: Erlbaum.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="115" page="7" column="2">Previc, F.H. (1990). Functional specialization in the lower and upper visual fields in humans: Its ecological origins and neurophysio- logical implications. Behavioral and Brain Sciences, 13, 519– 541.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="116" confidence="possible" page="7" column="2">Wolfe, J.M. (1994). Guided Search 2.0: A revised model of visual search. Psychonomic Bulletin &amp; Review, 1, 202–238.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="117" confidence="possible" page="7" column="2">Yoon, E.Y., &amp; Humphreys, G.W. (2007). Dissociative effects of viewpoint and semantic priming on action and semantic decisions: Evidence for dual routes to action from vision. Quarterly Journal of Experimental Psychology, 60, 601–623.</ref>
          <ref class="deo:BibliographicReference" id="118" page="7" column="2">(R ECEIVED 4/24/07; R EVISION ACCEPTED 6/3/07)</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="footer" id="106" page="6" column="2">Volume 19—Number 1</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="107" page="6" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="108" page="6" column="2">47</outsider>
        <outsider class="DoCO:TextBox" type="header" id="109" page="7" column="1">Object Viewpoint, Visual Field, and Action Instructions During Search</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="119" page="7" column="2">48</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="120" page="7" column="2">Downloaded from pss.sagepub.com at Bobst Library, New York University on April 19, 2016</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="121" page="7" column="2">Volume 19—Number 1</outsider>
      </section>
    </body>
  </article>
</pdfx>
