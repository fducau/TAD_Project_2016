<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>ef11dedb3455bd7581de88bfffc77fcc8ad6e4308bb2b770b646d1c54b884e26</job>
    <base_name>2y</base_name>
    <doi>10.1037/0278-7393.34.2.353</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="1">Journal of Experimental Psychology: Learning, Memory, and Cognition 2008, Vol. 34, No. 2, 353–368</outsider>
      <outsider class="DoCO:TextBox" type="header" id="2">Copyright 2008 by the American Psychological Association 0278-7393/08/$12.00 DOI: 10.1037/0278-7393.34.2.353</outsider>
      <title-group>
        <article-title class="DoCO:Title" id="3">Tracing Attention and the Activation Flow in Spoken Word Planning Using Eye Movements</article-title>
      </title-group>
      <region class="DoCO:TextChunk" id="4" confidence="possible">Ardi Roelofs Radboud University Nijmegen</region>
      <abstract class="DoCO:Abstract" id="5" confidence="possible">The flow of activation from concepts to phonological forms within the word production system was examined in 3 experiments. In Experiment 1, participants named pictures while ignoring superimposed distractor pictures that were semantically related, phonologically related, or unrelated. Eye movements and naming latencies were recorded. The distractor pictures affected the latencies of gaze shifting and vocal naming. The magnitude of the phonological effects increased linearly with latency, excluding lapses of attention as the cause of the effects. In Experiment 2, no distractor effects were obtained when both pictures were named. When pictures with superimposed distractor words were named or the words were read in Experiment 3, the words influenced the latencies of gaze shifting and picture naming, but the pictures yielded no such latency effects in word reading. The picture–word asymmetry was obtained even with equivalent reading and naming latencies. The picture–picture effects suggest that activation spreads continuously from concepts to phonological forms, whereas the picture–word asymmetry indicates that the amount of activation is limited and task dependent. Keywords: attention, cascade processing, eye movements, word production</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <region class="DoCO:TextChunk" id="12" page="1" column="1">Does activation spread in an automatic and continuous fashion through associative memory, or is the activation flow discrete and goal dependent at some points? This issue has been intensively investigated in the cognitive and brain sciences (e.g., D. E. Meyer, Osman, Irwin, &amp; <xref ref-type="bibr" rid="R32" id="6" class="deo:Reference">Yantis, 1988</xref>). Following a seminal study by <xref ref-type="bibr" rid="R25" id="7" class="deo:Reference">Levelt et al. (1991)</xref>, the nature of the flow of activation has also been a major issue in psycholinguistic research on object naming. The naming of objects seems to involve the activation of concepts, lemmas, morphemes, phonemes, and syllable motor programs in associative memory (e.g., Levelt, Roelofs, &amp; <xref ref-type="bibr" rid="R24" id="8" class="deo:Reference">Meyer, 1999</xref>). Lemmas code the words’ syntactic properties. For example, in the WEAVER model (<xref ref-type="bibr" rid="R24" id="9" class="deo:Reference">Levelt et al., 1999</xref>; <xref ref-type="bibr" rid="R39" id="10" class="deo:Reference">Roelofs, 1992</xref>, 1997, 2003), the conceptually driven production of the word cat involves the activation in a lexical network of the representation of the concept CAT(X), the lemma of cat specifying that the word is a noun (for languages such as Dutch, lemmas also specify grammat- ical gender), the morpheme cat , the phonemes /k/, /æ/, and /t/, and the syllable motor program [kæt]. A fragment of the lexical network of WEAVER is illustrated in <xref ref-type="fig" rid="F1" id="11" class="deo:Reference">Figure 1</xref>. No consensus exists in the literature as to whether activation spreads from level</region>
      <region class="DoCO:TextChunk" id="14" confidence="possible" page="1" column="1">Ardi Roelofs, Nijmegen Institute for Cognition and Information and F. C. Donders Centre for Cognitive Neuroimaging, Radboud University Nijmegen, the Netherlands. I am indebted to Bicoor Bolla-Bong for his help in preparing and running the experiments and to Kim Verhoef, Markus Damian, and the members of the Utterance Encoding Group of the Max Planck Institute for Psycholinguistics in Nijmegen for helpful comments. The preparation of this article was supported by a Vici grant from the Netherlands Organiza- tion for Scientific Research. Correspondence concerning this article should be addressed to Ardi Roelofs, Nijmegen Institute for Cognition and Information, Radboud University Nijmegen, Spinoza Building B.01.08, Montessorilaan 3, 6525 HR Nijmegen, the Netherlands. E-mail: <email id="13">A.Roelofs@nici.ru.nl</email></region>
      <region class="DoCO:TextChunk" id="39" page="1" column="2">to level in an automatic and continuous fashion or whether the activation flow is discrete and goal dependent at some points in the network (for recent discussions see, e.g., <xref ref-type="bibr" rid="R3" id="15" class="deo:Reference">Bloem &amp; La Heij, 2003</xref>; <xref ref-type="bibr" rid="R33" id="16" class="deo:Reference">Morsella &amp; Miozzo, 2002</xref>; <xref ref-type="bibr" rid="R34" id="17" class="deo:Reference">Navarrete &amp; Costa, 2005</xref>; <xref ref-type="bibr" rid="R29" id="18" class="deo:Reference">Roelofs, 2003</xref>). Up until now, the discussions in the literature on spoken word planning have typically concentrated on the two most extreme theoretical positions (but see Dell &amp; <xref ref-type="bibr" rid="R11" id="19" class="deo:Reference">O’Seaghdha, 1991</xref>): The spread of activation is either automatic and continuous versus discrete and goal dependent at some points. However, according to a third intermediate theoretical position, which is explored in the present article, activation spreads from level to level in a continuous fashion, but the amount of activation that spreads through the system is limited and task dependent. For example, following <xref ref-type="bibr" rid="R10" id="20" class="deo:Reference">Dell (1986)</xref>, I proposed in several articles (e.g., <xref ref-type="bibr" rid="R39" id="21" class="deo:Reference">Roelofs, 1992</xref>, 1997, 2003) that retrieval of information from the lexical network involves selective attentional enhancement of the activation of goal- related nodes (cf. <xref ref-type="bibr" rid="R21" id="22" class="deo:Reference">LaBerge, 1995</xref>; <xref ref-type="bibr" rid="R36" id="23" class="deo:Reference">Posner &amp; Dehaene, 1994</xref>). The enhancements occur only when the task requires the retrieval of lexical information. Activation of nodes decreases with network distance. In the absence of activation enhancements, the network distance between concepts and phonological forms is too long to obtain much phonological activation induced by concepts. In addition, the connections between lemmas and word forms may be weak, which limits the amount of activation that spreads between levels at this point in the lexical network (<xref ref-type="bibr" rid="R29" id="24" class="deo:Reference">Roelofs, 2003</xref>). <xref ref-type="bibr" rid="R24" id="25" class="deo:Reference">Levelt et al. (1999)</xref> argued that perceived objects continuously activate their concepts and lemmas, whereas the morphemes, phonemes, and motor programs of the object names are activated only when a speaker has the goal of naming the objects and selects a lemma. Lemma selection is goal dependent, and the goal of object naming allows the connection between lemmas and word forms to be made. Consequently, only the form corresponding to a selected lemma becomes activated. For example, in referring to a perceived<marker type="page" number="2"/><marker type="column" number="1"/><marker type="block"/> cat by saying “cat,” the concepts CAT(X) and DOG(X), the lemmas of cat and dog, and the phonological form of cat become activated, but the form of dog remains inactive. In contrast, other researchers (e.g., <xref ref-type="bibr" rid="R10" id="33" class="deo:Reference">Dell, 1986</xref>) have argued that all word forms corresponding to the activated concepts and lemmas become continuously activated. According to this view, the form of dog is also activated in planning to say “cat.” More recently, <xref ref-type="bibr" rid="R2" id="34" class="deo:Reference">Altmann and Davidson (2001)</xref> and <xref ref-type="bibr" rid="R3" id="35" class="deo:Reference">Bloem and La Heij (2003)</xref> argued that although objects activate their concepts and related ones, the lemmas, morphemes, phonemes, and motor programs of the object names are activated only when a speaker has the goal of naming the objects. In seeing a cat, the concepts CAT(X) and DOG(X) become activated, but the lemma and form of cat become active only when a speaker wants to name the cat. Thus, whereas <xref ref-type="bibr" rid="R10" id="36" class="deo:Reference">Dell (1986)</xref> and <xref ref-type="bibr" rid="R24" id="37" class="deo:Reference">Levelt et al. (1999)</xref> assumed that activation spreads continuously from concepts to lemmas, Altmann and Davidson and Bloem and La Heij argued that the activation flow is discrete in that only a selected concept activates its lemma. Moreover, whereas Dell assumed that activation spreads continuously from lemmas to word forms, <xref ref-type="bibr" rid="R24" id="38" class="deo:Reference">Levelt et al. (1999)</xref> argued that the spread of activation is discrete in that only a selected lemma activates its word form.</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="27" page="1" column="2">353</outsider>
      <outsider class="DoCO:TextBox" type="header" id="28" page="2" column="1">ROELOFS</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="29" page="2" column="1">354</outsider>
      <region class="unknown" id="30" page="2" column="1">perceived object FELINE(X) CAT(X) perceived noun cat word CAT &lt;cat&gt; /k/ /æ/ /t/ [kæt]</region>
      <region class="DoCO:FigureBox" id="F1">
        <caption class="deo:Caption" id="32" page="2" column="1">Figure 1. Fragment of the lexical network of the WEAVER al., 1999; <xref ref-type="bibr" rid="R39" id="31" class="deo:Reference">Roelofs, 1992</xref>, 2003).</caption>
      </region>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="40" confidence="possible" page="2" column="1">Review of Empirical Evidence</h1>
        <region class="DoCO:TextChunk" id="98" page="2" column="1">Seminal evidence that activation spreads continuously from concepts to lemmas but not from lemmas to word forms came from a series of experiments by <xref ref-type="bibr" rid="R25" id="41" class="deo:Reference">Levelt et al. (1991)</xref>. They tested for the activation of the phonological form of semantic competitors of a picture name. For example, is the phonological form of the word dog activated in naming a pictured cat? Participants were asked to name pictured objects (e.g., a pictured cat) and, on some critical<marker type="column" number="2"/><marker type="block"/> trials, to interrupt the preparation of the picture name and decide whether an auditory probe presented after picture onset was a word or not (auditory lexical decision). If activation spreads continuously from concepts to phonological forms, the phonemes of semantic competitors of the target (e.g., the phoneme /d/ of the word dog, which is a semantic competitor of cat) should become active. <xref ref-type="bibr" rid="R25" id="45" class="deo:Reference">Levelt et al. (1991)</xref> obtained no effect on the lexical decision latencies for spoken probes that were phonologically related to semantic competitors (e.g., the probe DOLL, which is phonologically related to dog), whereas they obtained interference for probes that were semantic competitors (DOG) or directly phonologically related (CAP). These results support the view that activation spreads continuously from concepts to lemmas, yielding the semantic interference for semantic competitors (DOG), but not from lemmas to word forms, explaining the lack of activation for the phonemes of those semantic competitors (e.g., the /d/ of DOG), as indexed by the absence of an effect on DOLL (see also Jescheniak, Hahne, &amp; <xref ref-type="bibr" rid="R18" id="46" class="deo:Reference">Schriefers, 2003</xref>). Using word reading rather than auditory lexical decision, Peterson and <xref ref-type="bibr" rid="R35" id="47" class="deo:Reference">Savoy (1998)</xref> replicated the findings of <xref ref-type="bibr" rid="R25" id="48" class="deo:Reference">Levelt et al. (1991)</xref>. However, whereas <xref ref-type="bibr" rid="R25" id="49" class="deo:Reference">Levelt et al. (1991)</xref> obtained semantic and phonological interference effects on the lexical decisions, Peterson and Savoy obtained semantic and phonological facilitation of word reading. Clearly, the direction of the effects (interference versus facilitation) depends on the task. Moreover, Peterson and Savoy reported activation of the phonological form of near-synonyms of the picture name (e.g., for PULL, related to puss, in naming a pictured cat), indicating that the phonological activation of semantic competitors may be detected when the semantic relation between words is strong. This suggests that activation in the word production system cascades between levels.<marker type="page" number="3"/><marker type="column" number="1"/><marker type="block"/> Alternatively, it may be that near-synonyms are a special case. <xref ref-type="bibr" rid="R24" id="53" class="deo:Reference">Levelt et al. (1999)</xref> suggested that speakers habitually or mistakenly select both words in cases of near-synonymy and repair the multiple selection later in the planning process (e.g., after phonological encoding). According to this view, the activation of the forms of near-synonyms is the result of misselection and covert repair rather than a continuous spread of activation from lemmas to forms. <xref ref-type="bibr" rid="R17" id="54" class="deo:Reference">Griffin and Bock (1998)</xref> argued, however, specifically for the continuous activation view. They observed that the effect of word frequency (i.e., high-frequency words are produced faster than low-frequency words) is smaller in syntactically constrained than unconstrained sentential contexts. Earlier evidence suggested that the effect of word frequency arises during accessing lexical forms or morphemes (<xref ref-type="bibr" rid="R19" id="55" class="deo:Reference">Jescheniak &amp; Levelt, 1994</xref>; <xref ref-type="bibr" rid="R41" id="56" class="deo:Reference">Roelofs, 1998</xref>). If the transition from lemma to word form is a discrete step, then syntactic constraint and word frequency should yield additive effects. Setting aside misselection, the interaction between syntactic constraint and word frequency therefore suggests that activation spreads continuously from lemmas to word forms. Furthermore, <xref ref-type="bibr" rid="R6" id="57" class="deo:Reference">Cutting and Ferreira (1999)</xref> observed that when speakers named pictures of objects with a homophone name (e.g., they said “ball” to a toy ball, whereby the other meaning of ball was party), an auditory distractor word that was semantically related to the other meaning (DANCE) speeded picture naming relative to an unrelated control. This suggests that hearing a distractor like DANCE activated the other meaning of ball (party), which automatically activated the word form of ball, speeding the naming of the toy ball. More recently, <xref ref-type="bibr" rid="R33" id="58" class="deo:Reference">Morsella and Miozzo (2002)</xref> presented the primes directly as distractor pictures in picture naming. Speakers were given pictures in green superimposed onto pictures in red. The task was to name the pictures in green while ignoring the pictures in red. The picture names were phonologically related or unrelated. Morsella and Miozzo observed that target pictures were named faster when the distractor picture was phonologically related than when it was unrelated. This suggests that activation spreads continuously from the distractor picture to the phonological form of its name. <xref ref-type="bibr" rid="R34" id="59" class="deo:Reference">Navarrete and Costa (2005)</xref> replicated and extended these findings. Taken together, the empirical evidence seems to favor the position of <xref ref-type="bibr" rid="R10" id="60" class="deo:Reference">Dell (1986)</xref> over the positions of <xref ref-type="bibr" rid="R24" id="61" class="deo:Reference">Levelt et al. (1999)</xref>, <xref ref-type="bibr" rid="R2" id="62" class="deo:Reference">Altmann and Davidson (2001)</xref>, and <xref ref-type="bibr" rid="R3" id="63" class="deo:Reference">Bloem and La Heij (2003)</xref>. Activation seems to cascade from concepts to phonological forms. Other evidence indicates, however, that the amount of activation that spreads from concepts to phonological forms is limited, in line with the data of <xref ref-type="bibr" rid="R25" id="64" class="deo:Reference">Levelt et al. (1991)</xref> and <xref ref-type="bibr" rid="R35" id="65" class="deo:Reference">Peterson and Savoy (1998)</xref>. It is often assumed that pictures have direct access to concepts and only indirect access to word forms, whereas words have direct access to word forms and only indirect access to concepts (cf. <xref ref-type="bibr" rid="R39" id="66" class="deo:Reference">Roelofs, 1992</xref>, 2003), as illustrated in <xref ref-type="fig" rid="F1" id="67" class="deo:Reference">Figure 1</xref>. Naming pictures requires concept selection, whereas words can be read aloud without concept selection. The latter is achieved by mapping input word-forms (e.g., CAT) directly onto output word- forms (e.g., cat , /k/, /æ/, /t/, and [kæt]), as illustrated in <xref ref-type="fig" rid="F1" id="68" class="deo:Reference">Figure 1</xref>. Semantically related written words (e.g., DOG) superimposed onto pictured objects (e.g., a cat) hamper the naming of the objects. However, the pictures have no effect on reading the words aloud (e.g., M. O. Glaser &amp; <xref ref-type="bibr" rid="R13" id="69" class="deo:Reference">Glaser &amp; Glaser, 1982</xref> W. R. Glaser &amp; D  ̈ngelhoff, 1984; W. R. Glaser &amp; <xref ref-type="bibr" rid="R15" id="70" class="deo:Reference">Glaser &amp; Glaser, 1989</xref> <xref ref-type="bibr" rid="R29" id="71" class="deo:Reference">Roelofs, 2003</xref>,<marker type="column" number="2"/><marker type="block"/> 2006a, 2006b; <xref ref-type="bibr" rid="R49" id="73" class="deo:Reference">Smith &amp; Magee, 1980</xref>; see <xref ref-type="bibr" rid="R26" id="74" class="deo:Reference">MacLeod, 1991</xref>, for a review). The absence of an effect of picture distractors on word reading suggests that the amount of activation that spreads from pictures to word forms is limited (<xref ref-type="bibr" rid="R29" id="75" class="deo:Reference">Roelofs, 2003</xref>). One may argue that the interference of pictures on word reading is absent because words are read without accessing the mental lexicon, namely via the application of grapheme–phoneme correspondence rules (e.g., mapping the c of cat onto /k/), and that the rule application shields word reading from distracting pictures. However, that does not seem to be the case. Digits (e.g., the digit 3) superimposed onto dice (e.g., two dots) affect dice naming, whereas the dice have no effect at all on digit naming (<xref ref-type="bibr" rid="R20" id="76" class="deo:Reference">Roelofs, 2006b</xref>). However, digits cannot be read by applying grapheme–phoneme correspondence rules. This suggests that the absence of an effect of pictures/dice on word reading is due to the limited amount of activation spreading from pictures/dice to word forms (see <xref ref-type="bibr" rid="R29" id="77" class="deo:Reference">Roelofs, 2003</xref>, 2006a, 2006b, for further discussion). <xref ref-type="bibr" rid="R3" id="78" class="deo:Reference">Bloem and La Heij (2003)</xref> argued that the finding of <xref ref-type="bibr" rid="R33" id="79" class="deo:Reference">Morsella and Miozzo (2002)</xref> concerning the effect of a phonological relation between target and distractor pictures is problematic in the light of the finding by <xref ref-type="bibr" rid="R7" id="80" class="deo:Reference">Damian and Bowers (2003)</xref> that a semantic relation between pictures does not yield an effect. <xref ref-type="bibr" rid="R34" id="81" class="deo:Reference">Navarrete and Costa (2005)</xref> also obtained no semantic effect of picture distractors on picture naming latencies. According to Bloem and La Heij, if a distractor picture has no semantic effect on naming another picture, suggesting that activation does not spread continuously from concepts to lemmas, it is surprising that a phonological relationship has an effect, suggesting a continuous spread of activation from concepts to lemmas and from lemmas to word forms. The reasoning of Bloem and La Heij is not completely convincing, however. First, whereas <xref ref-type="bibr" rid="R7" id="82" class="deo:Reference">Damian and Bowers (2003)</xref> obtained no semantic effect of picture distractors on picture naming, W. R. <xref ref-type="bibr" rid="R15" id="83" class="deo:Reference">Glaser and Glaser (1989)</xref> obtained semantic interference. It seems that the difference in effects between studies is related to methodological differences. Whereas in the study of Damian and Bowers the superimposed pictures differed in size and the participants had to name the largest picture, in the study of W. R. Glaser and Glaser the onset of the presentation of the two pictures differed, and participants had to name the first (or second) picture that appeared on the screen. Using the same technique as W. R. Glaser and Glaser, <xref ref-type="bibr" rid="R3" id="84" class="deo:Reference">La Heij, Heikoop, Akerboom, and Bloem (2003)</xref> replicated the semantic interference. Moreover, in a second experiment, the selection of the target picture was made easier by reducing the presentation duration of the distractor picture. Then semantic facilitation was obtained. On the basis of these findings, La Heij et al. concluded that “the ease of target selection is at least one of the factors that contributed to the reversal from semantic interference in Experiment 1 into semantic facilitation in Experiment 2” (p. 58). To conclude, in contrast to what <xref ref-type="bibr" rid="R3" id="85" class="deo:Reference">Bloem and La Heij (2003)</xref> maintained, picture distractors may yield semantic effects, depending on the task situation. Second, the model of word planning proposed by <xref ref-type="bibr" rid="R3" id="86" class="deo:Reference">Bloem and La Heij (2003)</xref> does not distinguish between lexical selection and phonological encoding, so semantic and phonological effects are expected to co-occur. This makes the presence of a phonological effect in the absence of a semantic effect surprising. However, other models attribute semantic and phonological effects to different planning processes. For example, the WEAVER model<marker type="page" number="4"/><marker type="column" number="1"/><marker type="block"/> assumes that lemma retrieval and phonological encoding are dis- tinct processes, which are differentially sensitive to semantic and phonological manipulations, as is evident, for example, from the difference in time course of semantic and phonological effects (<xref ref-type="bibr" rid="R24" id="90" class="deo:Reference">Levelt et al., 1999</xref>). Thus, phonological manipulations may have an effect even when semantic manipulations do not (cf. Schriefers, Meyer, &amp; <xref ref-type="bibr" rid="R48" id="91" class="deo:Reference">Levelt, 1990</xref>). These two arguments against the reasoning of <xref ref-type="bibr" rid="R3" id="92" class="deo:Reference">Bloem and La Heij (2003)</xref> do not mean, however, that the picture–picture results obtained by <xref ref-type="bibr" rid="R33" id="93" class="deo:Reference">Morsella and Miozzo (2002)</xref> and <xref ref-type="bibr" rid="R34" id="94" class="deo:Reference">Navarrete and Costa (2005)</xref> provide straightforward evidence for cascading. As the results of <xref ref-type="bibr" rid="R3" id="95" class="deo:Reference">La Heij et al. (2003)</xref> indicate, how participants deal with the selective attention problem posed by naming one of two superimposed pictures is in itself a complicated issue (e.g., Allport, Tipper, &amp; <xref ref-type="bibr" rid="R1" id="96" class="deo:Reference">Chmiel, 1985</xref>). Participants have to name the green picture and ignore the red picture. A theoretical possibility is that participants plan the names of both pictures and then finally select the motor program for the green picture name from an articulatory buffer and initiate articulation (<xref ref-type="bibr" rid="R20" id="97" class="deo:Reference">Roelofs, 2006a</xref>). Thus, the phonological facilitation might arise from a particular planning strategy adopted for dealing with the selective attention problem posed by overlapping pictures rather than reflect a continuous spread of activation.</region>
        <region class="unknown" id="43" page="2" column="2">DOG(X) concepts dog lemmas &lt;dog&gt; morphemes /d/ / / /g/ phonemes [d g] syllable motor programs</region>
        <region class="unknown" id="44" page="2" column="2">model of spoken word production (Levelt et</region>
        <outsider class="DoCO:TextBox" type="header" id="51" page="3" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="52" page="3" column="1">355</outsider>
        <outsider class="DoCO:TextBox" type="header" id="88" page="4" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="89" page="4" column="1">356</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="99" confidence="possible" page="4" column="1">Overview of the Present Experiments</h1>
        <region class="DoCO:TextChunk" id="128" page="4" column="1">Research on spoken word planning has shown that there is a close link between phonological activation and gaze shifting in picture naming (e.g., A. S. Meyer, Sleiderink, &amp; <xref ref-type="bibr" rid="R30" id="100" class="deo:Reference">Levelt, 1998</xref>; <xref ref-type="bibr" rid="R16" id="101" class="deo:Reference">Griffin, 2001</xref>), whereby gaze shifts index shifts of attention (Roelofs, 2007). For example, when speakers are asked to name two objects in a row, they look longer at first-to-be-named objects with two- versus one-syllable names even when the object recognition times are the same (A. S. Meyer, Roelofs, &amp; <xref ref-type="bibr" rid="R29" id="102" class="deo:Reference">Levelt, 2003</xref>). The effect of the phonological length suggests that the shift of gaze from one object to the other is initiated only after the phonological form of the name for the object has been planned sufficiently (cf. Korvorst, Roelofs, &amp; <xref ref-type="bibr" rid="R20" id="103" class="deo:Reference">Levelt, 2006</xref>; <xref ref-type="bibr" rid="R23" id="104" class="deo:Reference">Levelt &amp; Meyer, 2000</xref>). A. S. <xref ref-type="bibr" rid="R23" id="105" class="deo:Reference">Meyer and Van der Meulen (2000)</xref> observed that phonologically related spoken distractor words reduce picture naming latencies and gaze shift latencies compared to phonologically unrelated distractors. Thus, again, gaze shifts were linked to phonological activation. Moreover, <xref ref-type="bibr" rid="R23" id="106" class="deo:Reference">Levelt and Meyer (2000)</xref> and <xref ref-type="bibr" rid="R20" id="107" class="deo:Reference">Korvorst et al. (2006)</xref> observed that gaze shift latencies may reflect the phonological length of the utterance even when vocal response latencies do not. If distractor pictures activate the phonological form of their names, they should affect not only the latency of naming the target pictures but also the latency of gaze shifting. Earlier research suggests that the variability in latencies tends to be less for gaze shifting than for vocal responding (A. S. <xref ref-type="bibr" rid="R29" id="108" class="deo:Reference">Meyer et al., 2003</xref>; A. S. <xref ref-type="bibr" rid="R23" id="109" class="deo:Reference">Meyer &amp; Van der Meulen, 2000</xref>). Effects in the picture–picture task tend to be small (around 10 –20 ms in the studies of <xref ref-type="bibr" rid="R3" id="110" class="deo:Reference">La Heij et al., 2003</xref>; <xref ref-type="bibr" rid="R33" id="111" class="deo:Reference">Morsella &amp; Miozzo, 2002</xref>; <xref ref-type="bibr" rid="R34" id="112" class="deo:Reference">Navarrete &amp; Costa, 2005</xref>). By measuring gaze shift latencies in addition to vocal response latencies, the chances are enhanced for detecting the effects if they are there. The present article reports three eye-tracking experiments that further explored the issue of the extent to which activation spreads between word planning levels and how the activation flow is<marker type="column" number="2"/><marker type="block"/> influenced by attention. In particular, the reported research examined effects of picture distractors in naming one of two superimposed pictures (Experiment 1), naming both pictures (Experiment 2), and reading words (Experiment 3). In all the experiments, the target was presented in green color and the distractor in red. Experiment 1 concerned a replication and extension of the studies of <xref ref-type="bibr" rid="R33" id="114" class="deo:Reference">Morsella and Miozzo (2002)</xref> and <xref ref-type="bibr" rid="R34" id="115" class="deo:Reference">Navarrete and Costa (2005)</xref>. Different from Morsella and Miozzo, all pictures occurred both as targets and distractors. This manipulation served to optimize a comparison between Experiment 1 and Experiment 2, where both pictures had to be named, and therefore both were part of the response set. The picture–picture stimuli (Experiments 1 and 2) and picture–word stimuli (Experiment 3) were presented on the left-hand side of a computer screen. To give the participants an incentive to move their gaze away from the picture–picture or picture–word stimuli, a secondary stimulus requiring a manual response was presented on the right-hand side of the screen. This response involved pressing a left or right button to indicate the direction of a left- or right-pointing arrow. Phonological effects in the picture–picture task do not neces- sarily support a continuous spread of activation within the word production system. The effects may also be obtained when speakers mistakenly select the names of both pictures, as suggested by <xref ref-type="bibr" rid="R24" id="116" class="deo:Reference">Levelt et al. (1999)</xref> for synonyms. <xref ref-type="bibr" rid="R4" id="117" class="deo:Reference">Bloem, Van den Boogaard, and La Heij (2004)</xref> suggested that lapses of attention, leading to an erroneous selection of the wrong picture name on some of the trials, explain the picture–picture effects observed by <xref ref-type="bibr" rid="R33" id="118" class="deo:Reference">Morsella and Miozzo (2002)</xref>. The robustness of the effects was tested by examining the latency distributions in Experiment 1. If phonological effects are due to an erroneous selection of the red picture name on some of the trials, followed by a covert repair, the effects should be present for only a part of the latency distribution, namely for the slow responses only. Instead, if the effects reflect cascading of activation, the difference in the latency between the related and unrelated conditions should be present through most of the latency range. The latency distributions were examined using “quantile– quantile” plots (<xref ref-type="bibr" rid="R51" id="119" class="deo:Reference">Thomas &amp; Ross, 1980</xref>; <xref ref-type="bibr" rid="R53" id="120" class="deo:Reference">Wilk &amp; Gnanadesikan, 1968</xref>). A quantile– quantile plot is a standard technique for deter- mining whether two distributions belong to the same distribution family. If they do, the plot should be linear, indicating that the distributions differ only by a scale or shift factor. Linearity in a distribution plot indicates that the difference between conditions varies proportionately with latency (e.g., De Jong, Liang, &amp; <xref ref-type="bibr" rid="R9" id="121" class="deo:Reference">Lauber, 1994</xref>; <xref ref-type="bibr" rid="R38" id="122" class="deo:Reference">Ridderinkhof, 2002</xref>; <xref ref-type="bibr" rid="R54" id="123" class="deo:Reference">Zhang &amp; Kornblum, 1997</xref>). If a linear function is obtained, this would exclude that the effects are caused by lapses of attention. Selecting the names of both pictures may be the way that participants deal with the selective attention problem in the picture–picture task. Experiment 2 explicitly examined the effect of multiple selection. On each trial, participants named both pictures, first the green one and then the red one. If the phonological effects in Experiment 1 are due to the selection of the names of both the green and the red pictures, the results from naming one picture in Experiment 1 should be replicated with the naming of both pictures in Experiment 2. The absence of an effect of picture distractors on word reading reported in the literature suggests that the amount of activation that spreads from concepts to word forms is limited and attention dependent (<xref ref-type="bibr" rid="R29" id="124" class="deo:Reference">Roelofs, 2003</xref>). Experiment 3 examined the influence<marker type="page" number="5"/><marker type="column" number="1"/><marker type="block"/> of picture distractors on word reading using picture–word versions of the stimuli used in Experiments 1 and 2. Participants named the picture or word of picture–word stimuli depending on whether the picture or word was presented in green (the picture or word in red had to be ignored), which varied randomly from trial to trial. If phonological effects of picture distractors are obtained on picture naming (Experiment 1) but not on word reading (Experiment 3), this would corroborate the existing evidence that the amount of activation spreading from concepts to word forms is limited and task dependent.</region>
        <outsider class="DoCO:TextBox" type="header" id="126" page="5" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="127" page="5" column="1">357</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="129" confidence="possible" page="5" column="1">Experiment 1</h1>
        <region class="DoCO:TextChunk" id="131" page="5" column="1">In the first experiment, participants were presented with green pictures superimposed onto red pictures. Eye movements were recorded while participants named the green picture of the picture– picture stimuli (presented on the left side of a computer screen) and manually responded by pressing a left or right button in response to the left- or right-pointing arrows ( or , presented on the right side of the screen). For example, they said “hammer” in response to a pictured hammer in green color, while trying to ignore a pictured chisel in red (the semantically related condition) or a pictured sandal in red (the semantically unrelated condition). Or they said “circle” in response to a pictured circle in green, while trying to ignore a pictured circus in red (the phonologically related condition) or a pictured <xref ref-type="table" rid="Tin" id="130" class="deo:Reference">table in</xref> red (the phonologically unrelated condition). To minimize the chance that participants would iden- tify the direction of the arrows by their peripheral vision, the arrows were flanked by two Xs on each side, yielding XX XX and XX XX as stimuli.</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="132" page="5" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="137" page="5" column="1">Participants. The experiment was carried out with a group of 24 paid participants from the pool at the Max Planck Institute for Psycholinguistics in Nijmegen. All participants were young adults who were native speakers of Dutch. None of the participants took part in one of the other experiments. Materials and design. From the picture gallery available at the Max Planck Institute, 40 pictured objects were selected. All pictures had disyllabic names. The pictures were chosen such that 10 pairs of pictures had names that were semantically related and the 10 remaining pairs had names that were phonologically related. The pictures with phonologically related names shared the first syllable. The unrelated conditions were created by recombining the pictures such that each semantically related picture also served as a semantically unrelated picture and each phonologically related picture also served as a phonologically unrelated picture. The Appendix lists the materials. The pictures were line drawings on a black background. They were digitized and scaled to fit into a virtual frame of 10 cm 10 cm. On average, the pictures subtended 8.7° horizontally and 8.7° vertically at a viewing distance of 66 cm (roughly the distance between the participant and the screen). The arrows were presented in 28-point uppercase Arial font, subtending 3.5° horizontally and 0.9° vertically. The hori- zontal distance between the middle of the picture–picture stimuli and the arrow stimuli was 15.2°. There were two independent variables: type and relation. The variable type indicated whether the pictures were from the semantic or <marker type="column" number="2"/><marker type="block"/> the phonological sets. The variable relation indicated whether the paired pictures were related or unrelated. Both variables were tested within participants. Relation was tested within items and type was tested between items. A participant received 20 picture–picture pair- ings in each of the four distractor conditions, yielding 80 picture– picture stimuli in total. Each picture pair was presented twice, yielding 160 trials per participant in total. The order of presenting the stimuli across trials was random, except that repetitions of pictures and words on successive trials were not permitted. Apparatus. Materials were presented on a 39-cm ViewSonic 17PS screen. Eye movements were measured using an SMI EyeLink-HiSpeed 2D headband-mounted eye-tracking system (SensoMotoric Instruments GmbH, Teltow, Germany). The eye tracker was controlled by a Pentium 90 MHz computer. The experiment was run under the Nijmegen Experiment Setup (NESU) with a NESU button box on a Pentium 400 MHz computer. The participants’ utterances were recorded over a Sennheiser ME400 microphone to a SONY DTC55 digital audio tape (DAT) recorder. Vocal response latencies were measured using an electronic voice key. Procedure. The participants were tested individually. They were seated in front of the computer monitor, a panel with a left and a right push button, and the microphone. The distance between participant and screen was approximately 66 cm. Participants were given written instructions telling them how their eyes would be monitored and what the task was. The experimenter also orally described the eye-tracking equipment and restated the instructions. The participants were told that they had to name the green picture of picture–picture stimuli presented on the left side of a computer screen and manually respond by pressing a left or right button in response to the arrows presented on the right side of the screen. To familiarize them with the pictures, the participants received a booklet showing them all pictures used in the experiment together with the expected names. When a participant had read the instructions and studied the picture booklet, the headband of the eye-tracking system was placed on the participant’s head, and the system was calibrated and validated. For pupil-to-gaze calibration, a grid of 3 3 positions had been defined. During a calibration trial, a fixation target appeared once, in random order, in each of these positions for one second. Participants were asked to fixate upon each target until the next target appeared. After the calibration trial, the estimated positions of the participant’s fixations and the distances from the fixation targets were displayed to the experimenter. Calibration was considered adequate if there was at least one fixation within 1.5° of each fixation target. When calibration was inadequate, the procedure was repeated, sometimes after adjusting the eye cam- eras. Successful calibration was followed by a pupil-to-gaze validation trial. For the participants, this trial did not differ from the calibration trial, but the data collected during the validation trial were used to estimate the participants’ gaze positions, and the error (i.e., the distance between the estimated gaze position and the target position) was measured. Validation was considered com- pleted if the average error was less than 1.0° and the worst error less than 1.5°. Depending on the result of the validation trial, the calibration and validation trials were repeated or testing began. After successful calibration and validation, a block of 40 prac- tice trials was administered, in which each picture was shown and named once. This was followed by the 160 experimental trials. The<marker type="page" number="6"/><marker type="column" number="1"/><marker type="block"/> structure of a trial was as follows. A trial started by the simulta- neous presentation of the left picture–picture and right arrow stimuli. The stimuli remained on the screen until the participant pushed the button in response to the arrow. The arrows were presented in white. The colored pictures and the arrows were presented on a black background. Before the start of the next trial there was a blank interval of 1.5 sec. The position of the left and right eyes was determined every 4 ms. Drift correction occurred automatically after every 8 trials. Analyses. A naming response was considered to be invalid when it included a speech error, when a wrong word was produced, or when the voice key was triggered incorrectly. Error trials were discarded from the analyses of the naming latencies and gaze shift latencies. To analyze the speakers’ gaze shifts, their eye fixations were classified as falling within or on the outer contours of the left stimulus or elsewhere. Although viewing was binocular and the positions of both eyes were tracked, only the position of the right eye was analyzed. Gaze shift latency was defined as the time interval between the beginning of the first fixation on the left stimulus and the end of the last fixation before the first shift of gaze was initiated to the right arrow. The vocal response latencies, gaze shift latencies, and errors were submitted to analyses of variance. The analyses were performed both by participants (F 1 ) and by items (F 2 ). Faster responding in the related than unrelated condition will be called descriptively facilitation and slower responding will be called interference.</region>
        <outsider class="DoCO:TextBox" type="header" id="135" page="6" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="136" page="6" column="1">358</outsider>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="138" page="6" column="1">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="140" page="6" column="1"> <xref ref-type="table" rid="T1" id="139" class="deo:Reference">Table 1</xref> gives for each distractor condition the mean latencies, their standard deviations, and the error percentages for the vocal responses and gaze shifts. The table shows that the vocal naming latencies were slightly shorter (11 ms) in the semantically related than unrelated condition, and the gaze shift latencies showed a similar, but larger effect (25 ms). The latencies were shorter in the phonologically related than unrelated condition for both the vocal responses and the gaze shifts (respectively, 29 and 27 ms). Vocal responses. The statistical analysis of the vocal response latencies yielded a main effect of relation (related vs. unrelated), F 1 (1, 23) 12.14, MSE 799, p .002; F 2 (1, 38) 5.59, MSE 1,436, p .02, but not of type (semantic vs. phonological), F 1 (1, 23) 6.86, MSE 1,069, p .02; F 2 (1, 38) 1, MSE 7,571, p .40. Type and relation did not interact, F 1 (1, 23) 1.60, MSE 1,401, p .22; F 2 (1, 38) 1.43, MSE 1,436, p .24. There was a by-items effect of type on the error</region>
        <region class="DoCO:TextChunk" id="142" confidence="possible" page="6" column="1"> <xref ref-type="table" rid="T1" id="141" class="deo:Reference">Table 1</xref> Vocal Gaze Type Relation M SD E% M SD Semantic Related 805 213 2.1 653 179 Unrelated 816 238 2.1 678 185 Phonological Related 779 198 0.7 634 174 Unrelated 808 207 1.7 661 176</region>
        <region class="DoCO:TextChunk" id="150" page="6" column="2">rates, F 1 (1, 23) 2.77, p .11; F 2 (1, 38) 4.98, p .03. There were no other effects on the errors (all ps .10). Although type and relation did not interact, the magnitude of the relatedness effect was numerically smaller for the semantic than for the phonological distractors. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately revealed that the semantic effect did not reach significance, t 1 (23) 1.0, p .33; t 2 (19) 1.17, p .26, but there was a phonological effect, t 1 (23) 3.45, p .002; t 2 (19) 2.05, p .05. This suggests that the relatedness effect was driven by the phonological distractors. Gaze shifts. The statistical analysis of the gaze shift latencies yielded a main effect of relation, F 1 (1, 23) 23.14, MSE 709, p .001; F 2 (1, 38) 5.72, MSE 2,512, p .02, but not of type, F 1 (1, 23) 6.58, MSE 1,206, p .02; F 2 (1, 38) 1, MSE 7,374, p .40. Type and relation did not interact, F 1 (1, 23) 1, MSE 774, p .88; F 2 (1, 38) 1, MSE 2,512, p .80. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there were semantic and phonological effects in the analysis by participants, respectively, t 1 (23) 3.47, p .002; t 2 (19) 1.91, p .07, and t 1 (23) 3.21, p .004; t 2 (19) 1.60, p .13. Whereas the main effect of relation was significant both by participants and by items, the relatedness effects within the semantic and phonological conditions separately reached significance in the analysis by participants only, presumably because dividing the pictures by type reduced the power of the analysis by items. To conclude, the effects obtained for the vocal response latencies were basically replicated for the gaze shift latencies, except that the semantic effect was now more robust. To summarize, the experiment replicated the facilitation effect of phonological relatedness obtained by <xref ref-type="bibr" rid="R33" id="143" class="deo:Reference">Morsella and Miozzo (2002)</xref> and <xref ref-type="bibr" rid="R34" id="144" class="deo:Reference">Navarrete and Costa (2005)</xref> not only for the vocal responses but also for the corresponding gaze shifts. The effect of phonological relatedness of two pictures was obtained in the context of a semantic facilitation effect, which was present in the gaze shift latencies. <xref ref-type="table" rid="T1" id="145" class="deo:Reference">Table 1</xref> suggests that the difference in semantic effect between vocal responding and gaze shifting may be due to greater variability in the vocal latency data. The standard deviations of the latencies tended to be greater for the vocal responses than for the gaze shifts and greater for the semantic than for the phonological conditions. This may explain why there was no robust semantic effect in the vocal responses. <xref ref-type="bibr" rid="R4" id="146" class="deo:Reference">Bloem et al. (2004)</xref> suggested that erroneously selecting the wrong picture name on some of the trials explains the phonological picture–picture effects, as observed by <xref ref-type="bibr" rid="R33" id="147" class="deo:Reference">Morsella and Miozzo (2002)</xref> and in the present experiment. This hypothesis was evalu- ated by examining the latency distributions for the vocal responses and gaze shifts in the phonologically related and unrelated conditions. To obtain the latency distributions, I divided the rank- ordered latencies for each participant into deciles (10% quantiles) and computed mean latencies for each decile, separately for the vocal responses and gaze shifts and for the phonologically related and unrelated conditions. By averaging these means across participants, so-called Vincentized cumulative distribution functions are obtained (<xref ref-type="bibr" rid="R37" id="148" class="deo:Reference">Ratcliff, 1979</xref>). Vincentizing the latency data across individual participants provides a way of averaging data while preserving the shapes of the individual distributions. <xref ref-type="fig" rid="F2" id="149" class="deo:Reference">Figure 2</xref> shows the distributional plots for Experiment 1. Rank-ordering the</region>
        <outsider class="DoCO:TextBox" type="header" id="151" page="7" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="152" page="7" column="1">359</outsider>
        <region class="unknown" id="153" page="7" column="1">RELATION related unrelated 1.0 FREQUENCY 0.9 0.8 0.7 RELATIVE 0.6 0.5 0.4 CUMULATIVE 0.3 0.2 0.1 400 600 800 1000 1200</region>
        <disp-formula class="DoCO:FormulaBox" id="Fms">
          <label class="DoCO:Label" id="154">ms</label>
          <content class="DoCO:Formula" id="155" page="7" column="1">GAZE SHIFT LATENCY</content>
        </disp-formula>
        <region class="DoCO:FigureBox" id="F2">
          <caption class="deo:Caption" id="156" page="7" column="1">Figure 2. Vincentized cumulative distribution curves for the vocal responses and gaze shifts in the phonologically related and unrelated conditions of Experiment 1.</caption>
        </region>
        <region class="DoCO:TextChunk" id="163" page="7" column="1">latencies for each item and using these to compute Vincentized cumulative distribution functions yielded equivalent distributional plots (which are not shown). <xref ref-type="fig" rid="F2" id="157" class="deo:Reference">Figure 2</xref> shows that the phonological effect was present throughout the entire latency range for the gaze shifting, except in the 10% quickest gaze shifts. This suggests that when gaze shifts occur really early, before phonological encoding, no phonological effect is obtained. The phonological effect was present across the entire latency distribution for the vocal responses. For both the vocal responses and gaze shifts, the difference between the related and unrelated conditions increased with latency. Statistical analysis revealed that there was no interaction of relation (related vs. unrelated) and decile (1–10) for the vocal responses, F(9, 207) 1.18, MSE 3,266, p .31, but there was an interaction for the gaze shifts, F(9, 207) 3.73, MSE 3,055, p .001. Further<marker type="column" number="2"/><marker type="block"/> analyses revealed that the increase of the phonological effect with latency was not disproportionate. The latencies in the related and unrelated conditions were linearly related for both the vocal responses and the gaze shifts, as illustrated by the quantile– quantile plots in <xref ref-type="fig" rid="F3" id="161" class="deo:Reference">Figure 3</xref>. The figure shows the relationship between condition distributions based on a grouping of the latencies by participants. Grouping of the latencies by items (not shown) yielded the same results. This finding of a linear relationship between latencies excludes an interpretation of the phonological effects in terms of lapses of attention (<xref ref-type="bibr" rid="R4" id="162" class="deo:Reference">Bloem et al., 2004</xref>).</region>
        <region class="unknown" id="159" page="7" column="1">(ms) 1100 R 2 = 0.9939 LATENCY 900 GAZE-SHIFT 700 UNRELATED 500 300 300 500 700 900 1100 RELATED GAZE-SHIFT LATENCY (ms)</region>
        <region class="unknown" id="160" page="7" column="2">600 800 1000 1200 VOCAL RESPONSE LATENCY (ms)</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="164" confidence="possible" page="7" column="2">Experiment 2</h1>
        <region class="DoCO:TextChunk" id="170" page="7" column="2">In the second experiment, participants were presented with the same picture–picture stimuli as in Experiment 1. Eye movements <marker type="page" number="8"/><marker type="column" number="1"/><marker type="block"/> were recorded while participants named both pictures of the picture–picture stimuli and manually responded to the arrows. For example, they said “hammer chisel” in response to a pictured hammer in green color and a pictured chisel in red (semantically related) and they said “hammer sandal” in response to a pictured hammer in green color and a pictured sandal in red (semantically unrelated). Or they said “circle circus” in response to a pictured circle in green and a pictured circus in red (phonologically related) and they said “circle table” in response to a pictured circle in green and a pictured <xref ref-type="table" rid="Tin" id="169" class="deo:Reference">table in</xref> red (phonologically unrelated). The utterances had to be produced fluently, without a pause between the two names. If the phonological effects obtained in Experiment 1 were due to the selection of both picture names, the results from naming one picture in Experiment 1 should be replicated with the naming of both pictures in Experiment 2.</region>
        <region class="unknown" id="166" page="7" column="2">(ms) LATENCY 1100 R 2 = 0.9973 VOCAL-RESPONSE 900 700 UNRELATED 500 500 700 900 1100 RELATED VOCAL-RESPONSE LATENCY (ms)</region>
        <outsider class="DoCO:TextBox" type="header" id="167" page="8" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="168" page="8" column="1">360</outsider>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="171" page="8" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="172" page="8" column="1">The method was the same as in Experiment 1, except that the participants named both pictures on each trial, first the green one and then the red one. The experiment was run with 18 new participants.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="173" page="8" column="1">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="175" page="8" column="1"> <xref ref-type="table" rid="T2" id="174" class="deo:Reference">Table 2</xref> gives for each distractor condition the mean latencies, their standard deviations, and the error percentages for the vocal responses and gaze shifts. The table shows that the latencies of the vocal responses were slightly longer in the semantically related than unrelated condition (17 ms), whereas those of the gaze shifts did not differ (0 ms). The latencies also did not differ much between the phonologically related and unrelated conditions for the vocal responding and gaze shifting (respectively, 7 and 11 ms). Vocal responses. The statistical analysis of the vocal response latencies yielded no effect of relation, F 1 (1, 17) 1, MSE 2,268, p .62; F 2 (1, 38) 1, MSE 2,640, p .74, but there was an effect of type, F 1 (1, 17) 18.57, MSE 2,039, p .001; F 2 (1, 38) 4.36, MSE 9,033, p .04. Type and relation did not interact, F 1 (1, 17) 1.53, MSE 2,313, p .23; F 2 (1, 38) 1.06, MSE 2,640, p .31. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately confirmed that there were no semantic and phonological effects, respectively, t 1 (17) 1.26, p .23; t 2 (19) 1.24, p .23, and t 1 (17) 0.52, p .61; t 2 (19) 0.41, p .68. There were no effects in the analysis of the error rates (all ps .40).</region>
        <region class="DoCO:TextChunk" id="177" confidence="possible" page="8" column="1"> <xref ref-type="table" rid="T2" id="176" class="deo:Reference">Table 2</xref> Vocal Gaze Type Relation M SD E% M SD Semantic Related 978 312 4.7 1,431 320 Unrelated 962 313 3.6 1,431 321 Phonological Related 922 286 3.8 1,379 299 Unrelated 928 287 4.0 1,390 307</region>
        <region class="DoCO:TextChunk" id="184" page="8" column="2">Gaze shifts. The statistical analysis of the gaze shift latencies yielded no effect of relation, F 1 (1, 17) 1, MSE 10,018, p .83; F 2 (1, 38) 1, MSE 10,626, p .84, and also no reliable effect of type, F 1 (1, 17) 8.11, MSE 4,812, p .01; F 2 (1, 38) 2.06, MSE 24,997, p .16. Type and relation did not interact, F 1 (1, 17) 1, MSE 2,684, p .65; F 2 (1, 38) 1, MSE 10,626, p .73. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there were no semantic and phonological effects, respectively, t 1 (17) 0.00, p .99; t 2 (19) 0.10, p .91, and t 1 (17) 0.39, p .70; t 2 (19) 0.35, p .73. <xref ref-type="fig" rid="F4" id="178" class="deo:Reference">Figure 4</xref> shows that the phonological effect was absent throughout the entire latency range for the gaze shifting and vocal responding. Statistical analysis revealed that there was no interaction of relation and decile for the gaze shifts, F(9, 153) 0.19, MSE 10,814, p .95, and also none for the vocal responses, F(9, 153) 1.15, MSE 2,958, p .33. Thus, the absence of phonological effects is a robust phenomenon, and it does not depend on latency. To summarize, the experiment yielded no semantic and phonological relatedness effects on the latencies of naming and gaze shifting. If the phonological effects in Experiment 1 were due to the selection of the names of both the green and the red pictures, the results from naming one picture in Experiment 1 should be replicated with the naming of both pictures in Experiment 2. This was not the case, which suggests that the effects of Experiment 1 did not arise because of selecting the names of both pictures. This raises the question of why semantic and phonological effects were obtained in naming one of the two pictures (Experiment 1), whereas no such effects were obtained in naming both pictures (Experiment 2). Elsewhere (<xref ref-type="bibr" rid="R24" id="179" class="deo:Reference">Levelt et al., 1999</xref>; <xref ref-type="bibr" rid="R39" id="180" class="deo:Reference">Roelofs, 1992</xref>, 1997, 2003), it was argued that effects of distractor words in picture naming reflect not only the activation flow within the word production network but also the attentional weighting of node activations in selecting a node (cf. <xref ref-type="bibr" rid="R5" id="181" class="deo:Reference">Bundesen, 1990</xref>, for visual attention). Whether the outcome is interference or facilitation may depend on the task and experimental context. The findings from Experiments 1 and 2 suggest that the outcome for picture–picture stimuli depends on whether one or two pictures have to be named. When both pictures have to be named (the task in Experiment 2), both picture names have to be planned. This may make the related red picture name a stronger competitor for the green picture name than when only the green picture name has to be planned (the task in Experiment 1) and the red one can be ignored. The larger attentional weight assigned to the picture in red in naming both pictures may counteract its facilitatory effect on the naming of the picture in green. The net result may be a null effect, as empirically observed. Whereas the gaze shifts were initiated, on average, 145 ms before the onset of articulation in Experiment 1, they happened, on average, 450 ms after articulation onset in Experiment 2. This difference in timing can be explained by assuming that gaze shift latencies reflected the phonological planning of the whole utterance referring to the picture–picture stimulus, whereas speech onset latencies did not. The utterance included the names of both pictures in Experiment 2 (e.g., “hammer chisel”), but only the name of the green picture in Experiment 1 (e.g., “hammer”). <xref ref-type="bibr" rid="R23" id="182" class="deo:Reference">Levelt and Meyer (2000)</xref> and <xref ref-type="bibr" rid="R20" id="183" class="deo:Reference">Korvorst et al. (2006)</xref> observed that gaze shift latencies may reflect the phonological length of the</region>
        <outsider class="DoCO:TextBox" type="header" id="185" page="9" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="186" page="9" column="1">361</outsider>
        <region class="unknown" id="187" page="9" column="1">RELATION related unrelated 1.0 FREQUENCY 0.8 0.9 0.7 RELATIVE 0.6 0.5 0.4 CUMULATIVE 0.3 0.2 0.1 800 1200 1600 2000 2400</region>
        <disp-formula class="DoCO:FormulaBox" id="Fms">
          <label class="DoCO:Label" id="188">ms</label>
          <content class="DoCO:Formula" id="189" page="9" column="1">GAZE SHIFT LATENCY</content>
        </disp-formula>
        <region class="DoCO:FigureBox" id="F4">
          <caption class="deo:Caption" id="190" page="9" column="1">Figure 4. Vincentized cumulative distribution curves for the vocal responses and gaze shifts in the phonologically related and unrelated conditions of Experiment 2.</caption>
        </region>
        <region class="DoCO:TextChunk" id="194" page="9" column="1">utterance even when vocal response latencies do not. For example, Levelt and Meyer instructed their participants to describe colored left and right objects (e.g., a big red scooter and a ball) in a simple or in a complex way. Participants either had to respond with “the scooter and the ball” or “the big red scooter and the ball.” The gaze shift latencies for the left stimulus (the scooter) were much shorter for the simple utterances than for the complex utterances. However, the vocal response latencies did not differ between the two utterance types. Furthermore, the shift of gaze to the right stimulus was initiated before articulation onset for the simple utterances, but after articulation onset for the complex utterances, similar to what was observed in the present Experiments 1 and 2. This suggests that the shift of attention and gaze, but not the onset of articulation, is triggered by the completion of phonological encoding of the utterance referring to the left stimulus. Whereas semantic and phonological effects were absent in the present experiment, <xref ref-type="bibr" rid="R12" id="191" class="deo:Reference">Freedman, Martin, and Biegler (2004)</xref> observed semantic effects in a double-picture naming task used to study the role of short-term memory in noun phrase production. There are several methodological differences between the experiments, which may have yielded the difference in effects. First, whereas the two pictures were superimposed in the present experiment, they were presented side by side in the experiment of Freedman et al. Second, whereas semantically related and unrelated trials were randomly intermixed in the present experiments, the related and unrelated conditions were presented in different blocks of trials by Freedman et al. Third, whereas the participants produced two nouns in the present experiments, they produced conjoined noun phrases (i.e., the two nouns were connected by the word “and”) in the study of Freedman et al. Fourth, whereas the pictures remained on the screen until the onset of the manual response to the arrows in the present experiment, the pictures disappeared from the screen as soon as the participants began the utterance in the experiment of Freedman et al. The latter forced the participants to attend to both pictured objects before speech onset,<marker type="column" number="2"/><marker type="block"/> which allowed Freedman et al. to study the role of short-term memory in producing the noun phrases. It seems plausible to assume that the need to use short-term memory in the experiment of Freedman et al., but not in the present experiment, is responsible for the difference in semantic effect between experiments.</region>
        <region class="unknown" id="193" page="9" column="2">600 800 1000 1200 1400 VOCAL RESPONSE LATENCY (ms)</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="195" confidence="possible" page="9" column="2">Experiment 3</h1>
        <region class="DoCO:TextChunk" id="212" page="9" column="2">Picture distractors yielded semantic and phonological effects in Experiment 1 but no such effects in Experiment 2, supporting the cascade view. The literature indicates, however, that there is no effect of picture distractors on word reading (e.g., M. O. Glaser &amp; <xref ref-type="bibr" rid="R13" id="196" class="deo:Reference">Glaser &amp; Glaser, 1982</xref> W. R. Glaser &amp; D  ̈ngelhoff, 1984; W. R. Glaser &amp; <xref ref-type="bibr" rid="R15" id="197" class="deo:Reference">Glaser &amp; Glaser, 1989</xref> <xref ref-type="bibr" rid="R29" id="198" class="deo:Reference">Roelofs, 2003</xref>, 2006a, 2006b; <xref ref-type="bibr" rid="R49" id="199" class="deo:Reference">Smith &amp; Magee, 1980</xref>). The absence of an effect of pictures on word reading suggests that the amount of activation that spreads from concepts to word forms is limited (<xref ref-type="bibr" rid="R29" id="200" class="deo:Reference">Roelofs, 2003</xref>). The picture–word asymmetry in effects between picture naming and word reading does not seem to be due to the relative speed of processing of pictures and words per se. Words are typically named faster than the corresponding pictures, namely some 100 –200 ms (e.g., <xref ref-type="bibr" rid="R26" id="201" class="deo:Reference">MacLeod, 1991</xref>; <xref ref-type="bibr" rid="R29" id="202" class="deo:Reference">Roelofs, 2003</xref>). However, when one compensates for the slower processing of pictures by presenting them in advance of the words to be named (e.g., 300 or 400 ms), still no interference on word reading is observed (W. R. Glaser &amp; D  ̈ngelhoff, 1984). A similar asymmetry is obtained between naming colors and reading their names in the color–word Stroop task (<xref ref-type="bibr" rid="R50" id="203" class="deo:Reference">Stroop, 1935</xref>; see MacLeod, 1991, for a review) and also between color naming and spoken color–word naming (<xref ref-type="bibr" rid="R43" id="204" class="deo:Reference">Roelofs, 2005</xref>). Again, an effect of distractor color is absent even when the colors are preexposed to compensate for the difference in processing speed between colors and words (M. O. Glaser &amp; <xref ref-type="bibr" rid="R13" id="205" class="deo:Reference">Glaser &amp; Glaser, 1982</xref> <xref ref-type="bibr" rid="R43" id="206" class="deo:Reference">Roelofs, 2005</xref>). This suggests that the asymmetry between naming pictures and colors, on the one hand, and naming written or spoken words, on the other, is due to an architectural difference (i.e., a byproduct of network<marker type="page" number="10"/><marker type="column" number="1"/><marker type="block"/> distance as illustrated in <xref ref-type="fig" rid="F1" id="210" class="deo:Reference">Figure 1</xref>, see <xref ref-type="bibr" rid="R29" id="211" class="deo:Reference">Roelofs, 2003</xref>, 2005) rather than a difference in relative speed of processing. Experiment 3 investigated the impact of picture distractors on word reading using picture–word versions of the stimuli used in Experiments 1 and 2. The pictures were in red and the words in green or vice versa. Participants named the picture or word of the picture–word stimuli depending on whether the picture or word was presented in green, which varied randomly from trial to trial. If the effects of picture distractors obtained in Experiment 1 are absent in word reading, this would corroborate the available evidence that the amount of activation that spreads from concepts to word forms is limited. As in the previous experiments, both vocal response latencies and eye movements were recorded.</region>
        <outsider class="DoCO:TextBox" type="header" id="208" page="10" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="209" page="10" column="1">362</outsider>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="213" page="10" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="214" page="10" column="1">The method was the same as in Experiment 1, except that picture–word stimuli were used. There were 20 picture–word pairs per condition in each task, yielding 160 trials per participant. Participants named the picture or the word of the picture–word stimuli depending on whether the picture or the word was presented in green, which varied randomly from trial to trial. The distractor words were presented in 36-point lowercase Arial font. On average, the words subtended 5.2° horizontally and 1.3° vertically. The experiment was run with 14 new participants.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="215" page="10" column="1">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="217" page="10" column="1"> <xref ref-type="table" rid="T3" id="216" class="deo:Reference">Table 3</xref> gives for each task and distractor condition the mean latencies, their standard deviations, and the error percentages for the vocal responses and gaze shifts. The table shows that the latencies of picture naming and gaze shifting were longer in the semantically related than unrelated condition (respectively, 33 and 41 ms for the vocal responses and gazes). Also, the latencies were longer in the phonologically related than unrelated condition for both picture naming and gaze shifting (respectively, 38 and 53 ms). However, the latencies for word reading and gaze shifting were similar in the semantically related and unrelated conditions</region>
        <region class="DoCO:TextChunk" id="219" confidence="possible" page="10" column="1"> <xref ref-type="table" rid="T3" id="218" class="deo:Reference">Table 3</xref> Vocal Gaze Type Relation M SD E% M SD Picture naming Semantic Related 947 267 1.8 844 174 Unrelated 914 263 3.2 803 150 Phonological Related 884 268 2.1 802 171 Unrelated 846 235 2.1 749 133 Word reading Semantic Related 680 169 1.1 581 132 Unrelated 677 203 0.4 584 116 Phonological Related 688 173 0.4 613 130 Unrelated 691 191 0.4 603 134</region>
        <region class="DoCO:TextChunk" id="231" page="10" column="2">(respectively, 3 and 3 ms difference). Also, the latencies for word reading and gaze shifting were similar in the phonologically related and unrelated conditions (respectively, 3 and 10 ms difference). Thus, there were no differences among conditions for word reading. Vocal responses. The statistical analysis of the vocal response latencies yielded main effects of task, F 1 (1, 13) 344.52, MSE 3,732, p .001; F 2 (1, 76) 260.54, MSE 7,023, p .001, type, F 1 (1, 13) 6.51, MSE 3,176, p .02; F 2 (1, 76) 4.15, MSE 7,023, p .04, and relation, F 1 (1, 13) 5.92, MSE 1,537, p .03; F 2 (1, 76) 3.53, MSE 3,071, p .06. Moreover, there were interactions of task and type, F 1 (1, 13) 60.80, MSE 675, p .001; F 2 (1, 76) 8.15, MSE 7,023, p .006, task and relation, F 1 (1, 13) 7.11, MSE 1,234, p .02; F 2 (1, 76) 3.72, MSE 3,071, p .06, but not of type and relation, F 1 (1, 13) 1, MSE 2,509, p .89; F 2 (1, 76) 1, MSE 3,071, p .91. For the picture naming latencies, there were effects of type, F 1 (1, 13) 29.56, MSE 2,029, p .001; F 2 (1, 38) 8.15, MSE 10,318, p .007, and relation, F 1 (1, 13) 10.63, MSE 1,680, p .006; F 2 (1, 38) 6.14, MSE 3,623, p .02. Type and relation did not interact, F 1 (1, 13) 1, MSE 1,758, p .97; F 2 (1, 38) 1, MSE 3,623, p .93. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there were semantic and phonological effects in the analysis by participants, respectively, t 1 (13) 2.39, p .03; t 2 (19) 1.59, p .13, and t 1 (13) 2.18, p .05; t 2 (19) 1.94, p .07. Again, whereas the main effect of relation was significant both by participants and by items, the relatedness effects within the semantic and phonological conditions separately reached significance in the analysis by participants only, presumably because dividing the items by type reduced the power of the analysis by items. For the word reading latencies, there were no effects of type and relation, and type and relation did not interact (all Fs 1). Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there were no semantic and phonological effects, respectively, t 1 (13) 0.22, p .83; t 2 (19) 0.14, p .88, and t 1 (13) 0.20, p .84; t 2 (19) 0.24, p .81. To conclude, there were effects in picture naming but not in word reading. The error rates differed between tasks, F 1 (1, 13) 10.48, p .006; F 2 (1, 76) 15.52, p .001, showing that more errors were made in the picture naming than in the word reading task. Given that more errors were made in the slower task, there is no evidence for a speed–accuracy trade-off. There were no other error effects (all ps .15). Gaze shifts. The statistical analysis of the gaze shift latencies yielded main effects of task, F 1 (1, 13) 172.86, MSE 6,750, p .001; F 2 (1, 76) 171.52, MSE 9,780, p .001, relation, F 1 (1, 13) 5.37, MSE 3,257, p .04; F 2 (1, 76) 5.45, MSE 4,381, p .02, but not of type, F 1 (1, 13) 1.01, MSE 3,459, p .33; F 2 (1, 76) 1, MSE 9,780, p .44. Moreover, there were interactions of task and type, F 1 (1, 13) 17.42, MSE 2,144, p .001; F 2 (1, 76) 5.55, MSE 9,780, p .021, task and relation, F 1 (1, 13) 7.66, MSE 1,731, p .02; F 2 (1, 76) 4.54, MSE 4,381, p .04, but not of type and relation, F 1 (1, 13) 1, MSE 2,061, p .46; F 2 (1, 76) 1, MSE 4,381, p .59. For picture naming, there was an effect of type in the by- participants analysis, F 1 (1, 13) 11.57, MSE 2,751, p .005; <marker type="page" number="11"/><marker type="column" number="1"/><marker type="block"/> F 2 (1, 38) 3.03, MSE 15,997, p .09, and there was an effect of relation, F 1 (1, 13) 10.83, MSE 2,826, p .006; F 2 (1, 38) 7.22, MSE 6,048, p .011. Type and relation did not interact, F 1 (1, 13) 1, MSE 2,331, p .63; F 2 (1, 38) 1, MSE 6,048, p .80. Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there was a semantic effect in the analysis by participants, t 1 (13) 2.76, p .02; t 2 (19) 1.59, p .13, and a phonological effect, t 1 (13) 2.32, p .04; t 2 (19) 2.29, p .03. For word reading, there were no effects of type, F 1 (1, 13) 3.16, MSE 2,851, p .10; F 2 (1, 38) 3.31, MSE 3,664, p .08, or relation (both Fs 1), and type and relation did not interact (both Fs 1). Planned comparisons between the related and unrelated conditions within the semantic and phonological conditions separately showed that there were no semantic and phonological effects, respectively, t 1 (13) 0.26, p .80; t 2 (19) 0.26, p .80, and t 1 (13) 0.52, p .61; t 2 (19) 0.57, p .58. Thus, there were effects in picture naming but not in word reading. <xref ref-type="fig" rid="F5" id="223" class="deo:Reference">Figure 5</xref> shows the distributional plots for the latencies of the gaze shifts and vocal responses of word reading and picture naming in the phonologically related and unrelated conditions. The left panel shows that the phonological effect on the gaze shifts was absent throughout the latency distribution for word reading, whereas the effect was present across the entire latency range except for the short latencies in picture naming. This suggests that when the gaze shifts occur early, before the onset of phonological encoding, phonological effects are absent. Statistical analysis revealed that there was an interaction of relation and decile for picture naming, F(9, 117) 5.82, MSE 4,862, p .001, but there was no reliable interaction for word reading, F(9, 117) 1.74, MSE 1,731, p .09. The right panel shows that the phonological effect on the vocal responses was also absent throughout the latency distribution for word<marker type="column" number="2"/><marker type="block"/> reading, whereas the effect was present throughout the latency range for picture naming. Statistical analysis revealed that there were no interactions of relation and decile for picture naming, F(9, 117) 1.87, MSE 6,012, p .06, and word reading, F(9, 117) 0.50, MSE 3,065, p .87. <xref ref-type="fig" rid="F5" id="226" class="deo:Reference">Figure 5</xref> also reveals that for both the gaze shifts and the vocal responses, the asymmetry in effects between picture naming and word reading existed even in the overlapping latency ranges, namely between 460 and 1,000 ms for gaze shifting and between 540 and 1,000 ms for vocal responding. The presence of the asymmetry in the absence of a latency difference provides evidence that the picture–word asymmetry is a byproduct of network distance (<xref ref-type="bibr" rid="R29" id="227" class="deo:Reference">Roelofs, 2003</xref>, 2005) rather than being caused by a difference in relative speed of processing. To summarize, word distractors yielded semantic and phonological effects in picture naming, whereas picture distractors yielded no effect on word reading, regardless of latency. The asymmetry in effects was obtained in the latencies of both vocal responding and gaze shifting. The picture–word asymmetry suggests that the amount of activation that cascades from concepts to word forms is limited and attention dependent (<xref ref-type="bibr" rid="R29" id="228" class="deo:Reference">Roelofs, 2003</xref>). Whereas phonologically related distractor words usually speed up picture naming compared to unrelated words (e.g., <xref ref-type="bibr" rid="R8" id="229" class="deo:Reference">Damian &amp; Martin, 1999</xref>; <xref ref-type="bibr" rid="R48" id="230" class="deo:Reference">Schriefers et al., 1990</xref>), they yielded phonological interference in the present experiment. Thus, the fact that the distractor word affords the other task in the experiment (oral reading) does influence the nature of the effect it has on picture naming. The phonological interference effect suggests that the phonologically related distractor words were stronger competitors in the present experiment than they normally are (i.e., when they are not the targets of the other task in an experiment), turning the usual phonological facilitation into interference.</region>
        <outsider class="DoCO:TextBox" type="header" id="221" page="11" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="222" page="11" column="1">363</outsider>
        <region class="DoCO:FigureBox" id="Fx225">
          <image class="DoCO:Figure" src="2y.page_011.image_01.png" thmb="2y.page_011.image_01-thumb.png"/>
        </region>
        <outsider class="DoCO:TextBox" type="header" id="232" page="12" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="233" page="12" column="1">364</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="234" confidence="possible" page="12" column="1">WEAVER Simulations</h1>
        <region class="DoCO:TextChunk" id="243" page="12" column="1">Following <xref ref-type="bibr" rid="R24" id="235" class="deo:Reference">Levelt et al. (1999)</xref> and <xref ref-type="bibr" rid="R29" id="236" class="deo:Reference">Roelofs (1992, 2003)</xref>, the difference in the direction of the distractor effects between experiments (facilitation in Experiment 1, no effect in Experiment 2, and interference in Experiment 3) was explained as a difference in trade-off between facilitation and interference in word planning, depending on the task situation. Here, I report the results of WEAVER simulations of the phonological effect that demon- strate the utility of this approach. The procedures in simulating the phonological effects were identical to the procedures in the simulations reported by <xref ref-type="bibr" rid="R40" id="237" class="deo:Reference">Roelofs (1997)</xref>, except that the effect of picture rather than spoken word distractors was examined in the present simulations. The phonological effect of picture distractors was simulated by giving input activation to the morpheme nodes of both the target and the distractor picture names. For example, the target picture name was Dutch hamer (English hammer), and the name of the distractor picture was phonologically related (havik, English hawk) or phonologically unrelated (bezem, English broom). To simulate weak cascading of activation, the input to the distractor morpheme (i.e., havik or bezem ) was only 5% of the input to the target (i.e., hamer ). This yielded a basic phonological facilitation effect of 27 ms in the simulations. The real effect in Experiment 1 was 29 ms. <xref ref-type="bibr" rid="R29" id="238" class="deo:Reference">Roelofs (2003)</xref> showed that WEAVER accounts for the picture–word asymmetry if the spreading rate between lemmas and word forms is lower than 40% of the spreading rate within the form network. Thus, a weakly cascading version of WEAVER accounts for the picture– picture phonological facilitation effect, on the one hand, and the picture–word asymmetry, on the other. In WEAVER , phonological encoding is followed by the selection of syllable motor programs from a mental syllabary. Based on the constructed phonological word representation, corresponding syllable motor programs are isolated in the syllabary. The probability of actual selection of a syllable program node at a particular moment in time is given by the ratio of the activation of the target syllable program and the sum of the activations of all stored syllable motor programs (<xref ref-type="bibr" rid="R40" id="239" class="deo:Reference">Roelofs, 1997</xref>). The attentional weighting of the activations in the ratio may depend on the task situation (<xref ref-type="bibr" rid="R24" id="240" class="deo:Reference">Levelt et al., 1999</xref>). The outcomes of Experiment 3 suggest that phonologically related distractors are stronger competitors in a task-mixing situation than in a normal picture–word interference experiment with only one task (i.e., picture naming). The confidence of the system in an isolated target syllable may be lower when tasks are mixed than when they are blocked. The negative effect of phonological overlap in a task-mixing situation was simulated by reducing the weight of the target syllable in the selection ratio, representing lower confidence in the target. For example, a weight of 0.8 implied that the model was less likely than normal (with a weight of 1.0) to select the target syllable because it was part of the distractor name. <xref ref-type="fig" rid="F6" id="241" class="deo:Reference">Figure 6</xref> shows the effect of the attentional weight on the phonological facilitation effect. When the weight is still large (e.g., 0.8 or 0.6), there is only a small reduction in the size of the phonological facilitation effect. However, with smaller weights (e.g., 0.4 or 0.2), the phonological facilitation effect (observed in Experiment 1) turns into phonological interference (observed in Experiment 3). A similar explanation may be given for the difference in direction of semantic effects. Whereas <xref ref-type="bibr" rid="R7" id="242" class="deo:Reference">Damian and Bowers (2003)</xref></region>
        <region class="unknown" id="244" page="12" column="2">100 (ms) 80 EFFECT 60 PHONOLOGICAL Facilitation Interference -20 20 40 0 -40 1.0 0.8 0.6 0.4 0.2 ATTENTIONAL WEIGHT</region>
        <region class="DoCO:FigureBox" id="F6">
          <caption class="deo:Caption" id="245" page="12" column="2">Figure 6.</caption>
        </region>
        <region class="DoCO:TextChunk" id="246" confidence="possible" page="12" column="2">The phonological effect as a function of the attentional weight in WEAVER simulations.</region>
        <region class="DoCO:TextChunk" id="254" page="12" column="2">obtained no semantic effect of picture distractors on picture naming, W. R. <xref ref-type="bibr" rid="R15" id="247" class="deo:Reference">Glaser and Glaser (1989)</xref> obtained semantic interference, and <xref ref-type="bibr" rid="R3" id="248" class="deo:Reference">La Heij et al. (2003)</xref> obtained semantic interference or facilitation depending on the ease of target selection. Thus, it seems that if separating the target and distractor is easy, the system’s confidence in the isolated lemma is high, and the lemma receives a large weight in the selection ratio relative to other lemmas. Consequently, semantic facilitation appears (cf. <xref ref-type="fig" rid="F6" id="249" class="deo:Reference">Figure 6</xref>). In contrast, if separating target and distractor is difficult, the system’s confidence in the isolated lemma is lower, and the lemma receives a smaller weight in the selection ratio. As a consequence, semantic interference occurs (cf. <xref ref-type="fig" rid="F6" id="250" class="deo:Reference">Figure 6</xref>). <xref ref-type="bibr" rid="R39" id="251" class="deo:Reference">Roelofs (1992)</xref> dem- onstrated the utility of such an approach through computer simulations. To summarize, the simulations revealed that a weakly cascading version of WEAVER can account for the phonological effect in the picture–picture task, on the one hand, and the picture–word asymmetry, on the other. Moreover, the simulations showed that the differences in direction of the phonological effects (facilitation in Experiment 1, no effect in Experiment 2, and interference in Experiment 3) may be explained as differences in trade-off between facilitation and interference, depending on the task situation (cf. <xref ref-type="bibr" rid="R24" id="252" class="deo:Reference">Levelt et al., 1999</xref>). A similar account may be given for the difference in direction of the semantic effects (cf. <xref ref-type="bibr" rid="R39" id="253" class="deo:Reference">Roelofs, 1992</xref>). Clearly, the proposed account of the variation in direction of effects is tentative and needs to be examined further in future research. However, it is important to note that the difference in direction of effects does not really affect the main conclusions. The presence of a phonological effect in the picture–picture task in Experiment 1 suggests that context pictures activate the phonological forms of their names. This conclusion holds regardless of whether the effect is one of facilitation or interference. The phonological effect per se supports the cascade view. Moreover, the absence of an effect of pictures on word reading in Experiment 3 suggests that the amount of activation that spreads from concepts to phonological forms is limited and task dependent. This conclusion holds regardless of whether the effects of the words in naming the pictures concern facilitation or interference.</region>
        <outsider class="DoCO:TextBox" type="header" id="255" page="13" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="256" page="13" column="1">365</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="257" confidence="possible" page="13" column="1">General Discussion</h1>
        <region class="DoCO:TextChunk" id="287" page="13" column="1">The present article reported three experiments that examined the relative merits of the continuous and discrete views on the activation flow within the word production system. Experiment 1 was a replication and extension of <xref ref-type="bibr" rid="R33" id="258" class="deo:Reference">Morsella and Miozzo (2002)</xref> and <xref ref-type="bibr" rid="R34" id="259" class="deo:Reference">Navarrete and Costa (2005)</xref>, testing for an effect of phonological relatedness of two pictures with the use of eye tracking. Different from Morsella and Miozzo, all pictures occurred both as targets and distractors. This manipulation served to optimize a comparison between Experiment 1 and Experiment 2, where both pictures had to be named and therefore both were part of the response set. Experiment 1 replicated the effect of phonological relatedness obtained by Morsella and Miozzo not only for the vocal responses but also for the gaze shifts. The effect of phonological relatedness of two pictures was obtained in the context of a semantic effect, which was clearly present in the gaze shift latencies. Distractor pictures that are part of the response set may be more salient than distractor pictures that are not. Moreover, naming a picture may strengthen the stimulus–response connection. Present- ing a previously named picture as distractor may lead to more activation of the distractor’s name than presenting a distractor picture that has not been named before (e.g., Waszak, Hommel, &amp; <xref ref-type="bibr" rid="R52" id="260" class="deo:Reference">Allport, 2003</xref>). It may be argued that the phonological facilitation effect is due to the fact that the distractor pictures were possible responses in the present experiments. However, this cannot be the case, because <xref ref-type="bibr" rid="R33" id="261" class="deo:Reference">Morsella and Miozzo (2002)</xref> and <xref ref-type="bibr" rid="R34" id="262" class="deo:Reference">Navarrete and Costa (2005)</xref> obtained the phonological facilitation effect for distractor pictures that were not targets in the experiment. Similarly, A. S. <xref ref-type="bibr" rid="R28" id="263" class="deo:Reference">Meyer and Damian (2007)</xref> investigated effects of phonological begin- and end-overlap between two pictures, as well as potential effects of a familiarization phase. Both types of overlap yielded comparable phonological facilitation effects, and whether participants had been familiarized with the pictures prior to the experimental session did not really matter. The phonological effect did not change systematically over six repetitions of the materials. Moreover, a greater salience or stimulus–response connection strength of distractor pictures could only lead to phonological activation of their names in a discrete system if the greater salience or strength leads to the selection of the concept (<xref ref-type="bibr" rid="R3" id="264" class="deo:Reference">Bloem &amp; La Heij, 2003</xref>) or the lemma (<xref ref-type="bibr" rid="R24" id="265" class="deo:Reference">Levelt et al., 1999</xref>) of the distractor’s name. Selection is goal dependent in the model of word planning proposed by <xref ref-type="bibr" rid="R24" id="266" class="deo:Reference">Levelt et al. (1999)</xref>. However, Experiment 2 showed that when the goal explicitly includes the selection of the name of the picture in red, this still does not yield phonological facilitation. Phonological effects in the picture–picture task do not neces- sarily support a continuous spread of activation within the word production system. The effects may also be obtained as a result of misselection. <xref ref-type="bibr" rid="R24" id="267" class="deo:Reference">Levelt et al. (1999)</xref> suggested that in case of synonyms, speakers mistakenly select the names of both pictures. <xref ref-type="bibr" rid="R4" id="268" class="deo:Reference">Bloem et al. (2004)</xref> argued that the participants in the experiment of <xref ref-type="bibr" rid="R33" id="269" class="deo:Reference">Morsella and Miozzo (2002)</xref> mistakenly selected the wrong picture name on some of the trials. This would explain the phonological effect. However, distributional analyses in Experiment 1 revealed that the phonological effect increased linearly with latency, for both the vocal responses and the gaze shifts. The linearity excludes that the effect occurred on some of the trials (i.e., the slow ones) only. This suggests that the phonological effect does not arise because of lapses of attention. Still, the<marker type="column" number="2"/><marker type="block"/> findings on the latency distributions are compatible with the idea that selecting the names of both pictures is the way that participants deal with the selective attention problem in the picture– picture task. Experiment 2 examined the effect of planning the names of both pictures. On each trial, participants named both pictures, first the green one and then the red one. If the phonological effects in Experiment 1 were due to the selection of the names of both the green and the red pictures, the results from naming one picture in Experiment 1 should be replicated with the naming of both pictures in Experiment 2. This was not the case, which suggests that the effects in Experiment 1 did not arise because of a special planning strategy adopted to deal with the overlapping pictures. Picture distractors yielded semantic and phonological facilitation effects in Experiment 1 but no such effects in Experiment 2, supporting the continuous view. The literature suggests, however, that the amount of activation that cascades from concepts to word forms is restricted, because there is no effect of picture distractors on word reading. Experiment 3 examined the influence of picture distractors on word reading using picture–word versions of the stimuli used in Experiments 1 and 2. Participants named the picture or word of picture–word stimuli depending on whether the picture or word was presented in green, which varied randomly from trial to trial. The experiment showed that word distractors yielded semantic and phonological effects in picture naming, but picture distractors yielded no effect on word reading. The picture– word asymmetry suggests that the spread of activation from concepts to word forms is limited and attention dependent. The attention dependence of the flow of activation also explains why there is a phonological facilitation effect in the picture– picture task, whereas there is no easily detectable activation of the phonological form of semantic competitors of a picture name, as observed for picture naming in the dual-task paradigm used by <xref ref-type="bibr" rid="R25" id="271" class="deo:Reference">Levelt et al. (1991)</xref>, <xref ref-type="bibr" rid="R35" id="272" class="deo:Reference">Peterson and Savoy (1998)</xref>, and <xref ref-type="bibr" rid="R29" id="273" class="deo:Reference">Roelofs (2003)</xref>. A major difference between the picture–picture task and picture naming in a dual-task situation is that the competitor that yields phonological activation is explicitly presented as a picture in the picture–picture task but not in the dual-task situation. In performing the picture–picture task, both the target and the distractor picture are probably given attention as part of the process of separating them (cf. <xref ref-type="bibr" rid="R1" id="274" class="deo:Reference">Allport et al., 1985</xref>; <xref ref-type="bibr" rid="R27" id="275" class="deo:Reference">MacLeod, 1998</xref>). This would mean that the competitor that yields phonological activation is more activated in the picture–picture task than in picture naming in the dual-task paradigm, explaining the phonological effect. As indicated, a difference in selective attention also explains why picture distractors yield a phonological effect in picture naming, whereas they have no effect at all in word reading. Only when participants attentionally enhance the activation of the picture name do pictures have an effect on word reading, as observed by Peterson and Savoy, and as observed by <xref ref-type="bibr" rid="R29" id="276" class="deo:Reference">Roelofs (2003)</xref> for the color–word Stroop task. These differences among studies suggest that the amount of activation that cascades through the system is limited. The evidence from the present experiments for limited cascading agrees with the observation of Roelofs, O  ̈ zdemir, and Levelt (2007) that passive picture viewing does not lead to significant phonological activation. Participants were shown pictures while hearing a tone or a spoken word presented 600 ms after picture onset. When a spoken word was presented, participants indicated<marker type="page" number="14"/><marker type="column" number="1"/><marker type="block"/> whether it contained a prespecified phoneme. When the tone was presented, they indicated whether the picture name contained the phoneme (one experiment), or they named the picture (another experiment). Phoneme monitoring latencies for the spoken words were shorter when the picture name contained the prespecified phoneme compared to when it did not. However, no priming of phoneme monitoring was obtained (in another experiment) when the pictures required no response but were only passively viewed, regardless of monitoring latency. These results suggest that attentional enhancements are a precondition for obtaining phonological activation from pictures. What do the present findings imply for existing theories of lexical access in word production? <xref ref-type="bibr" rid="R24" id="280" class="deo:Reference">Levelt et al. (1999)</xref> argued that perceived objects continuously activate their concepts and lemmas, whereas the morphemes, phonemes, and syllable motor programs of the object names are activated only when a speaker has the goal of naming the objects. <xref ref-type="bibr" rid="R10" id="281" class="deo:Reference">Dell (1986)</xref> argued that all word forms corresponding to the activated concepts and lemmas become continuously activated. And <xref ref-type="bibr" rid="R2" id="282" class="deo:Reference">Altmann and Davidson (2001)</xref> and <xref ref-type="bibr" rid="R3" id="283" class="deo:Reference">Bloem and La Heij (2003)</xref> argued that although objects activate their concepts and related ones, the lemmas, morphemes, phonemes, and motor programs of the object names are only activated when a speaker has the goal of naming the objects. The phonological facilitation effect from distractor pictures in Experiment 1 and the absence of the effect in Experiment 2 challenges the claim of Bloem and La Heij that only selected concepts activate their lemmas and forms, and it challenges the claim of <xref ref-type="bibr" rid="R24" id="284" class="deo:Reference">Levelt et al. (1999)</xref> that only selected lemmas activate their word forms. The phonological facilitation effect from the picture–picture task supports the claim of Dell that activation spreads continuously from concepts to lemmas and from lemmas to forms. However, the evidence from word reading in Experiment 3 suggests that the amount of activation from pictures arriving at the word forms is limited and task dependent (<xref ref-type="bibr" rid="R29" id="285" class="deo:Reference">Roelofs, 2003</xref>). Whereas <xref ref-type="bibr" rid="R24" id="286" class="deo:Reference">Levelt et al. (1999)</xref> assumed that the transition of activation from lemmas to word forms occurs in a discrete step, the present findings suggest that the activation is weakly cascading. That is, activation cascades from lemmas to forms, but the amount of activation is limited and task dependent. To conclude, the results from the present picture–picture and picture–word interference experiments support the cascade view and demand a change of discrete models like WEAVER . At the same time, the absence of an effect of distractor pictures on word reading suggests that the amount of activation that spreads continuously from concepts to phonological forms is limited. Computer simulations using a weakly cascading version of WEAVER showed that the model accounts for the phonological effect in the picture–picture task, on the one hand, and for the picture–word asymmetry, on the other. Moreover, the simulations showed that the differences between experiments in the direction of the phonological effects may be explained as differences in the trade-off between interference and facilitation in word-form encoding, depending on the task situation.</region>
        <outsider class="DoCO:TextBox" type="header" id="278" page="14" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="279" page="14" column="1">366</outsider>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="288" confidence="possible" page="14" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="290" page="14" column="1">Allport, D. A., Tipper, S. P., &amp; Chmiel, N. R. J. (1985). Perceptual integration and postcategorical filtering. In M. I. Posner &amp; O. S. M. Marin (Eds.), Attention and performance XI (pp. 107–132). London: Erlbaum. <marker type="column" number="2"/><marker type="block"/> Altmann, E. M., &amp; Davidson, D. J. (2001). An integrative approach to Stroop: Combining a language model and a unified cognitive theory. Proceedings of the 23rd meeting of the Cognitive Science Society (pp. 21–26). Hillsdale, NJ: Erlbaum.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="291" confidence="possible" page="14" column="2">Bloem, I., &amp; La Heij, W. (2003). Semantic facilitation and semantic interference in word translation: Implications for models of lexical access in language production. Journal of Memory and Language, 48, 468 – 488.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="292" confidence="possible" page="14" column="2">Bloem, I., Van den Boogaard, S., &amp; La Heij, W. (2004). Semantic facilitation and semantic interference in language production: Further evidence for the conceptual selection model of lexical access. Journal of Memory and Language, 51, 307–323.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="293" confidence="possible" page="14" column="2">Bundesen, C. (1990). A theory of visual attention. Psychological Review, 97, 523–547.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="294" confidence="possible" page="14" column="2">Cutting, J. C., &amp; Ferreira, V. S. (1999). Semantic and phonological information flow in the production lexicon. Journal of Experimental Psychology: Learning, Memory, and Cognition, 25, 318 –344.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="295" confidence="possible" page="14" column="2">Damian, M. F., &amp; Bowers, J. S. (2003). Locus of semantic interference in picture-word interference tasks. Psychonomic Bulletin and Review, 10, 111–117.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="296" confidence="possible" page="14" column="2">Damian, M. F., &amp; Martin, R. C. (1999). Semantic and phonological codes interact in single word production. Journal of Experimental Psychology: Learning, Memory, and Cognition, 25, 345–361.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="297" confidence="possible" page="14" column="2">De Jong, R., Liang, C.-C., &amp; Lauber, E. (1994). Conditional and uncon- ditional automaticity: A dual-process model of effects of spatial stimulus-response correspondence. Journal of Experimental Psychology: Human Perception and Performance, 20, 731–750.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="298" confidence="possible" page="14" column="2">Dell, G. S. (1986). A spreading-activation theory of retrieval in sentence production. Psychological Review, 93, 283–321.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="299" confidence="possible" page="14" column="2">Dell, G. S., &amp; O’Seaghdha, P. G. (1991). Mediated and convergent lexical priming in language production: A comment on Levelt et al. Psychological Review, 98, 604 – 614.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="300" confidence="possible" page="14" column="2">Freedman, M. L., Martin, R. C., &amp; Biegler, K. (2004). Semantic relatedness effects in conjoined noun phrase production: Implications for the role of short-term memory. Cognitive Neuropsychology, 21, 245–265.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="301" confidence="possible" page="14" column="2">Glaser, M. O., &amp; Glaser, W. R. (1982). Time course analysis of the Stroop phenomenon. Journal of Experimental Psychology: Human Perception and Performance, 8, 875– 894.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="302" confidence="possible" page="14" column="2">Glaser, W. R., &amp; D  ̈ngelhoff, F.-J. (1984). The time course of picture-word interference. Journal of Experimental Psychology: Human Perception and Performance, 10, 640 – 654.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="303" confidence="possible" page="14" column="2">Glaser, W. R., &amp; Glaser, M. O. (1989). Context effects in Stroop-like word and picture processing. Journal of Experimental Psychology: General, 118, 13– 42.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="304" confidence="possible" page="14" column="2">Griffin, Z. M. (2001). Gaze durations during speech reflect word selection and phonological encoding. Cognition, 82, B1–B14.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="305" confidence="possible" page="14" column="2">Griffin, Z. M., &amp; Bock, K. (1998). Constraint, word frequency, and levels of processing in spoken word production. Journal of Memory and Language, 38, 313–338.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="306" confidence="possible" page="14" column="2">Jescheniak, J. D., Hahne, A., &amp; Schriefers, H. (2003). Information flow in the mental lexicon during speech planning: Evidence from event-related brain potentials. Cognitive Brain Research, 15, 261–276.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="307" confidence="possible" page="14" column="2">Jescheniak, J. D., &amp; Levelt, W. J. M. (1994). Word frequency effects in speech production: Retrieval of syntactic information and phonological form. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 824 – 843.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="308" confidence="possible" page="14" column="2">Korvorst, M., Roelofs, A., &amp; Levelt, W. J. M. (2006). Incrementality in naming and reading complex numerals: Evidence from eyetracking. Quarterly Journal of Experimental Psychology, 59, 296 –311.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="309" confidence="possible" page="14" column="2">LaBerge, D. (1995). Attentional processing: The brain’s art of mindful- ness. Cambridge, MA: Harvard University Press.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="310" confidence="possible" page="14" column="2">La Heij, W., Heikoop, K. W., Akerboom, S., &amp; Bloem, I. (2003). Picture naming in picture context: Semantic interference or semantic facilitation? Psychology Science, 45, 49 – 62.</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="313" page="15" column="1">Levelt, W. J. M., &amp; Meyer, A. S. (2000). Word for word: Multiple lexical access in speech production. European Journal of Cognitive Psychology, 12, 433– 452.</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="314" confidence="possible" page="15" column="1">Levelt, W. J. M., Roelofs, A., &amp; Meyer, A. S. (1999). A theory of lexical access in speech production. Behavioral and Brain Sciences, 22, 1–38.</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="315" confidence="possible" page="15" column="1">Levelt, W. J. M., Schriefers, H., Vorberg, D., Meyer, A. S., Pechmann, T., &amp; Havinga, J. (1991). The time course of lexical access in speech production: A study of picture naming. Psychological Review, 98, 122– 142.</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="316" confidence="possible" page="15" column="1">MacLeod, C. M. (1991). Half a century of research on the Stroop effect: An integrative review. Psychological Bulletin, 109, 163–203.</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="317" confidence="possible" page="15" column="1">MacLeod, C. M. (1998). Training on integrated versus separated Stroop tasks: The progression of interference and facilitation. Memory &amp; Cognition, 26, 201–211.</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="318" confidence="possible" page="15" column="1">Meyer, A. S., &amp; Damian, M. F. (2007). Activation of distractor names in the picture-picture interference paradigm. Memory &amp; Cognition, 35, 494 –503.</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="319" confidence="possible" page="15" column="1">Meyer, A. S., Roelofs, A., &amp; Levelt, W. J. M. (2003). Word length effects in object naming: The role of a response criterion. Journal of Memory and Language, 48, 131–147.</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="320" confidence="possible" page="15" column="1">Meyer, A. S., Sleiderink, A. M., &amp; Levelt, W. J. M. (1998). Viewing and naming objects. Cognition, 66, B25–B33.</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="321" confidence="possible" page="15" column="1">Meyer, A. S., &amp; Van der Meulen, F. F. (2000). Phonological priming of picture viewing and picture naming. Psychonomic Bulletin and Review, 7, 314 –319.</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="322" confidence="possible" page="15" column="1">Meyer, D. E., Osman, A. M., Irwin, D. E., &amp; Yantis, S. (1988). Modern mental chronometry. Biological Psychology, 26, 3– 67.</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="323" confidence="possible" page="15" column="1">Morsella, E., &amp; Miozzo, M. (2002). Evidence for a cascade model of lexical access in speech production. Journal of Experimental Psychology: Learning, Memory, and Cognition, 28, 555–563.</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="324" confidence="possible" page="15" column="1">Navarrete, E., &amp; Costa, A. (2005). Phonological activation of ignored pictures: Further evidence for a cascade model of lexical access. Journal of Memory and Language, 53, 359 –377.</ref>
          <ref rid="R35" class="deo:BibliographicReference" id="325" confidence="possible" page="15" column="1">Peterson, R. R., &amp; Savoy, P. (1998). Lexical selection and phonological encoding during language production: Evidence for cascaded processing. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24, 539 –557.</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="326" confidence="possible" page="15" column="1">Posner, M. I., &amp; Dehaene, S. (1994). Attentional networks. Trends in Neurosciences, 17, 75–79.</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="327" confidence="possible" page="15" column="1">Ratcliff, R. (1979). Group reaction time distributions and an analysis of distribution statistics. Psychological Bulletin, 86, 446 – 461.</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="328" confidence="possible" page="15" column="1">Ridderinkhof, K. R. (2002). Activation and suppression in conflict tasks: Empirical clarification through distributional analyses. In W. Prinz &amp; B. Hommel (Eds.), Attention and Performance XIX: Common mechanisms in perception and action (pp. 494 –519). Oxford: Oxford University Press.</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="330" page="15" column="2">Roelofs, A. (1992). A spreading-activation theory of lemma retrieval in speaking. Cognition, 42, 107–142.</ref>
          <ref rid="R40" class="deo:BibliographicReference" id="331" confidence="possible" page="15" column="2">Roelofs, A. (1997). The WEAVER model of word-form encoding in speech production. Cognition, 64, 249 –284.</ref>
          <ref rid="R41" class="deo:BibliographicReference" id="332" confidence="possible" page="15" column="2">Roelofs, A. (1998). Rightward incrementality in encoding simple phrasal forms in speech production: Verb-particle combinations. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24, 904 – 921.</ref>
          <ref rid="R42" class="deo:BibliographicReference" id="333" confidence="possible" page="15" column="2">Roelofs, A. (2003). Goal-referenced selection of verbal action: Modeling attentional control in the Stroop task. Psychological Review, 110, 88 – 125.</ref>
          <ref rid="R43" class="deo:BibliographicReference" id="334" confidence="possible" page="15" column="2">Roelofs, A. (2005). The visual-auditory color-word Stroop asymmetry and its time course. Memory &amp; Cognition, 33, 1325–1336.</ref>
          <ref rid="R44" class="deo:BibliographicReference" id="335" confidence="possible" page="15" column="2">Roelofs, A. (2006a). Context effects of pictures and words in naming objects, reading words, and generating simple phrases. Quarterly Journal of Experimental Psychology, 59, 1764 –1784.</ref>
          <ref rid="R45" class="deo:BibliographicReference" id="336" confidence="possible" page="15" column="2">Roelofs, A. (2006b). Functional architecture of naming dice, digits, and number words. Language and Cognitive Processes, 21, 78 –111.</ref>
          <ref rid="R46" class="deo:BibliographicReference" id="337" confidence="possible" page="15" column="2">Roelofs, A. (2007). Attention and gaze control in picture naming, word reading, and word categorizing. Journal of Memory and Language, 57, 232–251.</ref>
          <ref rid="R47" class="deo:BibliographicReference" id="338" confidence="possible" page="15" column="2">Roelofs A., O  ̈ zdemir, R., &amp; Levelt, W. J. M. (2007). Influences of spoken word planning on speech recognition. Journal of Experimental Psychology: Learning, Memory, and Cognition, 33, 900 –913.</ref>
          <ref rid="R48" class="deo:BibliographicReference" id="339" confidence="possible" page="15" column="2">Schriefers, H., Meyer, A., &amp; Levelt, W. J. M. (1990). Exploring the time-course of lexical access in language production: Picture-word interference studies. Journal of Memory and Language, 29, 86 –102.</ref>
          <ref rid="R49" class="deo:BibliographicReference" id="340" confidence="possible" page="15" column="2">Smith, M. C., &amp; Magee, L. E. (1980). Tracing the time course of picture- word processing. Journal of Experimental Psychology: General, 109, 373–392.</ref>
          <ref rid="R50" class="deo:BibliographicReference" id="341" confidence="possible" page="15" column="2">Stroop, J. R. (1935). Studies of interference in serial verbal reactions. Journal of Experimental Psychology, 18, 643– 662.</ref>
          <ref rid="R51" class="deo:BibliographicReference" id="342" confidence="possible" page="15" column="2">Thomas, E. A. C., &amp; Ross, B. H. (1980). On appropriate procedures for combining probability distributions within the same family. Journal of Mathematical Psychology, 21, 136 –152.</ref>
          <ref rid="R52" class="deo:BibliographicReference" id="343" confidence="possible" page="15" column="2">Waszak, F., Hommel, B., &amp; Allport, A. (2003). Task-switching and long- term binding: Role of episodic stimulus-task bindings in task-shift costs. Cognitive Psychology, 46, 361– 413.</ref>
          <ref rid="R53" class="deo:BibliographicReference" id="344" confidence="possible" page="15" column="2">Wilk, M. B., &amp; Gnanadesikan, R. (1968). Probability plotting methods for the analysis of data. Biometrika, 55, 1–17.</ref>
          <ref rid="R54" class="deo:BibliographicReference" id="345" confidence="possible" page="15" column="2">Zhang, J., &amp; Kornblum, S. (1997). Distributional analysis and De Jong, Liang, and Lauber’s (1994) dual-process model of the Simon effect. Journal of Experimental Psychology: Human Perception and Performance, 23, 1543–1551.</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="header" id="311" page="15" column="1">ACTIVATION FLOW IN SPOKEN WORD PLANNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="312" page="15" column="1">367</outsider>
        <region class="unknown" id="329" page="15" column="1">(Appendix follows)</region>
        <outsider class="DoCO:TextBox" type="header" id="346" page="16" column="1">ROELOFS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="347" page="16" column="1">368</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="348" confidence="possible" page="16" column="1">Appendix</h1>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="349" confidence="possible" page="16" column="1">Materials of the Experiments</h1>
        <region class="unknown" id="350" page="16" column="1">Target Semantically related schildpad (tortoise) konijn konijn (rabbit) schildpad vliegtuig (aircraft) auto auto (car) vliegtuig molen (mill) fabriek fabriek (factory) molen kanon (cannon) pistool pistool (pistol) kanon bureau (desk) zetel zetel (seat) bureau beitel (chisel) hamer hamer (hammer) beitel sandaal (sandal) zwemvlies zwemvlies (flipper) sandaal appel (apple) banaan banaan (banana) appel trompet (trumpet) cello cello (cello) trompet vulpen (fountain pen) potlood potlood (pencil) vulpen Phonologically related bezem (broom) beker beker (cup) bezem wapen (weapon) waaier waaier (fan) wapen lepel (spoon) lelie lelie (lily) lepel kabel (cable) kano kano (canoe) kabel koning (king) kogel kogel (bullet) koning rugby (rugby) rugzak rugzak (backpack) rugby tafel (table) taco taco (taco) tafel zebra (zebra) zegel zegel (seal) zebra toren (tower) token totem (totem) toren circus (circus) cirkel cirkel (circle) circus</region>
        <region class="unknown" id="351" page="16" column="1">Note. English translations of the Dutch targets and distractors are given in parentheses.</region>
        <region class="DoCO:TextChunk" id="352" confidence="possible" page="16" column="2">Distractor Semantically unrelated vliegtuig auto schildpad konijn pistool kanon fabriek molen beitel hamer bureau zetel appel banaan sandaal zwemvlies vulpen potlood trompet cello Phonologically unrelated wapen waaier bezem beker kano kabel lelie lepel rugby rugzak koning kogel zebra zegel tafel taco circus cirkel toren totem Received June 30, 2006 Revision received October 3, 2007 Accepted October 29, 2007</region>
      </section>
    </body>
  </article>
</pdfx>
