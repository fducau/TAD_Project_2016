<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>c85f65d5093a2fdd3afe139e95ea55b376d075c2a8718cf0e5ef31cebb4f96e7</job>
    <base_name>5u</base_name>
    <doi confidence="possible">10.1080/13506280802211334</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <title-group>
        <article-title class="DoCO:Title" id="1">Feature binding in attentive tracking of distinct objects</article-title>
      </title-group>
      <outsider class="DoCO:TextBox" type="outsider" id="2">NIH Public Access Author Manuscript</outsider>
      <region class="DoCO:FigureBox" id="Fx3">
        <image class="DoCO:Figure" src="5u.page_001.image_01.png" thmb="5u.page_001.image_01-thumb.png"/>
      </region>
      <outsider class="DoCO:TextBox" type="sidenote" id="4">Vis cogn. Published in Vis cogn.</outsider>
      <region class="unknown" id="5">Author manuscript; available in PMC 2009 June 1. final edited form as: 2009 ; 17(1-2): 180–194. doi:10.1080/13506280802211334.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="6">Feature</outsider>
      <region class="unknown" id="7">binding in attentive tracking of distinct objects</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="8">Tal 1Department 2Center for</outsider>
      <region class="unknown" id="9">Makovski 1 and Yuhong V. Jiang 1,2 of Psychology, University of Minnesota Cognitive Sciences, University of Minnesota</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="10">Abstract To what the among a found that or both, in a</outsider>
      <abstract class="DoCO:Abstract" id="11" confidence="possible">degree can attentive tracking of objects’ motion benefit from increased distinctiveness in objects’ surface features? To address this question, we asked observers to track 4 moving digits total of 8 moving digits. By varying the distinctiveness of the digits’ color and identity, we tracking performance improved when the 8 objects were all distinct in color, digit identity, compared to when the 8 objects were identical. However, when the 8 objects were distinct combination of color and digit but targets and nontargets shared color or digit identity, performance enhancement was not observed. Four follow-up experiments extended the range of the dimensions generating the effect and ruled out alternative strategic accounts. We conclude surface features can be used to enhance tracking performance. This enhancement is feature- revealing a limited degree of feature binding in attentive tracking.</abstract>
      <outsider class="DoCO:TextBox" type="sidenote" id="12">feature that based,</outsider>
      <outsider class="DoCO:TextBox" type="sidenote" id="13">Keywords</outsider>
      <region class="DoCO:TextChunk" id="14" confidence="possible">Multiple-object tracking; attentive tracking; feature and location binding</region>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="deo:Introduction">
        <h1 class="DoCO:SectionTitle" id="15" page="1" column="1">Introduction</h1>
      </section>
      <region class="DoCO:TextChunk" id="35" page="1" column="1">The dynamics of the visual environment pose a significant challenge to human vision. How do we maintain a sense of temporal continuity in a constantly changing environment? One solution to this computational problem is to track objects as they move. Motion tracking is easily achieved when a single object must be tracked, or when the tracked objects differ from the other objects in a salient visual feature. Tracking becomes increasingly difficult when multiple objects are to be tracked among visually similar nontargets ( <xref ref-type="bibr" rid="R11" id="16" class="deo:Reference">Pylyshyn &amp; Storm, 1988</xref>). In this study we investigate the degree to which attentive tracking can benefit from distinctiveness in object features. We asked observers to track a subset of moving chromatic digits and measured their performance as a function of the objects’ distinctiveness in color, digit identity, and the combination of color and digit identity. The results are informative of feature binding in attentive tracking. In the following introduction, we review the current state of knowledge on this topic and identify a critical gap.<marker type="block"/> Standard multiple-object tracking tasks have deprived participants of the opportunity to use identity information. In Pylyshyn and Storm’s (1988) original paradigm, observers are shown a field of identical objects. A subset of these objects are designated as tracking targets during a cue period, after which the targets and nontargets are identical in shape and surface features. Tracking is accomplished by processing where the targets are and by updating each target’s location as it moves. Object identity plays no role in this paradigm.<marker type="page" number="2"/><marker type="block"/> Although it seems that the standard multiple-object tracking task is unrepresentative of everyday visual activity where moving objects are usually distinct, there are several reasons why identity information has rarely been incorporated (with the exception of a few studies reviewed below). First, spatiotemporal properties are used predominantly when visual continuity must be established. Infants rely primarily on spatiotemporal continuity, rather than shape or color constancy, to track objects after brief occlusions. At the age of ten-month old, infants were not surprised when a toy truck moved behind an occluder and reemerged as a toy duck (<xref ref-type="bibr" rid="R18" id="23" class="deo:Reference">Xu &amp; Carey, 1996</xref>). Infants also did not treat two objects that differ in surface properties as separate objects until the objects started to move independently (Spelke, Gutheil, &amp; <xref ref-type="bibr" rid="R16" id="24" class="deo:Reference">Van de Walle, 1995</xref>). The heavy reliance on spatiotemporal properties was also observed in visually deprived individuals who recovered vision as adults. These individuals also initially relied heavily on motion continuity to segregate a visual scene and only later incorporated surface properties such as color or shape discontinuity (<xref ref-type="bibr" rid="R15" id="25" class="deo:Reference">Sinha, 2007</xref>).<marker type="block"/> Normal human adults also appear to prefer spatiotemporal information to identity information in updating visual objects. For example, in the object reviewing paradigm (Kahneman, Treisman, &amp; <xref ref-type="bibr" rid="R5" id="27" class="deo:Reference">Gibbs, 1992</xref>), two letters (e.g., A and B) were presented inside two squares positioned at the 3 and 9 o’clock locations. The letters then disappeared while the squares moved clockwise to the 6 and 12 o’clock locations. After the motion, a probe letter was displayed for participants to name as quickly as possible. Participants were faster to name a formerly presented letter if it appeared in its original square rather than in the other square. <xref ref-type="bibr" rid="R5" id="28" class="deo:Reference">Kahneman et al. (1992)</xref> proposed that spatiotemporal continuity served to maintain the integrity of “object files”, allowing participants to update object information after motion. Interestingly, object updating appears to rely primarily on spatiotemporal continuity. In a similar paradigm, if the two letters initially appeared against blue and green background and later the background switched colors, performance in reporting the previewed letters was unaffected (<xref ref-type="bibr" rid="R7" id="29" class="deo:Reference">Mitroff &amp; Alvarez, 2007</xref>).<marker type="block"/> Another reason why researchers have focused primarily on tracking “where” rather than “what” is because the use of identity information in multiple-object tracking is highly limited. When objects with different shapes were used and tracking was occasionally interrupted by a question about the characteristics of a target, observers accurately reported the target’s direction and speed, but had difficulty reporting its shape (Scholl, Pylyshyn, &amp; <xref ref-type="bibr" rid="R14" id="31" class="deo:Reference">Franconeri, 1999</xref>). Further evidence that “what” is poorly bound to “where” comes from a study by Pylyshyn, who presented different digits, one in each circle in the cue period for participants to remember (<xref ref-type="bibr" rid="R10" id="32" class="deo:Reference">Pylyshyn, 2004</xref>). The digits were taken away before the circles began to move. At the end of the motion period, participants were asked to select the target circles and to report the digit originally presented in each circle. This paradigm bears some similarity to Kahneman et al.’s object updating task, except that there were more objects (8 versus 2 moving objects), more identities (4 vs. 2), more complex motion, and an explicit instruction to bind what with where. Although participants in Kahneman et al.’s paradigm were able to update the identity of two objects after a brief rotation of the placeholders, those in Pylyshyn’s more complex task were unable to do so. Even when they successfully tracked the target circles, memory for the associated digit identities was poor. Similar failures of “what-to-where” binding have been observed when participants tracked objects with apparent, rather than continuous, motion (<xref ref-type="bibr" rid="R12" id="33" class="deo:Reference">Saiki, 2003</xref>).<marker type="block"/> Although the binding of what to where is difficult in attentive tracking, some degree of binding has been demonstrated when distinct objects are used for tracking, and when participants are explicitly required to bind what to where. The multiple-identity tracking task usually presents observers with a small number of objects and designate either a subset or the entire set for tracking. Unlike Pylyshyn’s (2004) task where the distinct identities are presented only during the cue period, in the multiple-identity tracking task objects are always distinct in shape or</region>
      <outsider class="DoCO:TextBox" type="footer" id="20" page="1" column="1">Correspondence should be sent to Tal Makovski, N218 Elliott Hall, 75 East River Road, Minneapolis, MN 55455. Email: E-mail: <email id="19">tal.makovski@gmail.com</email>..</outsider>
      <outsider class="DoCO:TextBox" type="header" id="21" page="2" column="1">Makovski and Jiang</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="22" page="2" column="1">Page 2</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="36" page="2" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
      <outsider class="DoCO:TextBox" type="header" id="37" page="3" column="1">Makovski and Jiang</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="38" page="3" column="1">Page 3</outsider>
      <region class="DoCO:TextChunk" id="40" confidence="possible" page="3" column="1">color for the entire tracking period. At the end of the motion period, all objects are masked. One of the locations is then probed for observers to retrieve the associated object identity (<xref ref-type="bibr" rid="R8" id="39" class="deo:Reference">Oksama &amp; Hyönä, 2004</xref>, in press). Observers’ limited ability to bind identities to locations was dependent upon the speed and number of targets.</region>
      <region class="DoCO:TextChunk" id="58" page="3" column="1">Horowitz and colleagues employed a further modification of the multiple-identity tracking task, investigating whether distinctive identities are addressable during tracking ( <xref ref-type="bibr" rid="R4" id="41" class="deo:Reference">Horowitz et al., 2007</xref>). Participants were asked to track cartoon animals (e.g., a tiger, a leopard) that moved in straight lines. The unique identities of the animals remained on the screen during tracking. At the end of the tracking period the animals hid behind cactuses. Observers were asked to report either the location of all the targets (standard question) or the location of a specific animal (specific question). Horowitz et al. found that the estimated capacity was higher when answering the standard question than when answering the specific question, with a capacity estimate of about one object in the specific question. From these data Horowitz et al. concluded that “what” information is accessible during tracking, but only to a limited degree. Consistent with this idea, tracking performance was higher when the moving animals were distinct rather than identical to one another (Experiment 5, <xref ref-type="bibr" rid="R4" id="42" class="deo:Reference">Horowitz et al., 2007</xref>).<marker type="block"/> The main goal of the present study is to investigate the extent to which attentive tracking can be enhanced by distinctiveness in object identities. Horowitz et al. showed that tracking performance is higher when distinct, rather than homogeneous, objects must be tracked. However, their use of cartoon animals makes it difficult to dissociate the role of visual distinctiveness from semantic or name distinctiveness. In addition, it is difficult to isolate the visual features that contribute to tracking of distinct objects observed by <xref ref-type="bibr" rid="R4" id="44" class="deo:Reference">Horowitz et al. (2007)</xref>. To understand how object features are integrated with their location during tracking, it is necessary to test tracking of visual objects made of identifiable features.<marker type="block"/> We conducted a series of five experiments using colored digits (or colored shape/orientation) to study how distinctiveness in features or conjunction of features affects attentive tracking. In this article, we report one of the experiments in full and briefly describe the other experiments that provide converging support for the main findings. In the main experiment, we used an array of colored digits and asked participants to track a subset of those objects. Unlike the multiple-identity tracking task, participants of the present study were not required to remember object identities. Tracking can be achieved entirely by updating the motion trajectories of objects without remembering their identities. Importantly, we manipulated the objects’ distinctiveness. The objects could be distinct in one or two features (e.g., all have different colors) or in a combination of features (e.g., the conjunction of color and shape made all objects unique). We also tested whether all objects or only the target subset needs to be distinct to facilitate tracking.<marker type="block"/> Consider two conditions shown in <xref ref-type="table" rid="T1" id="47" class="deo:Reference">Table 1</xref>: the homogeneous condition and the color- distinct condition, where participants tracked 4 out of 8 objects that were either homogeneous or distinct in color. Motion trajectory tracking is sufficient for both conditions. If spatiotemporal continuity is the only source of information for attentive tracking, then performance should be comparable between the homogeneous and color-distinct conditions. In contrast, if distinctiveness in color is also used to separate targets from nontargets, then performance may be superior in the color-distinct condition. Similar predictions can be made when comparing the homogeneous condition with the digit-distinct condition. Furthermore, the distinctiveness in both color and digit may convey an added advantage in the both- distinct condition. Thus, the comparison of the homogeneous condition with the color-distinct, digit-distinct, and both-distinct conditions informs us whether featural information is helpful for tracking when the task does not require identity memory. An advantage in the feature distinct conditions may imply that participants can bind a feature with a moving location.<marker type="page" number="4"/><marker type="block"/> Now consider the conjunction-distinct condition, where the 8 objects were made distinctive because they were distinct in the combination of color and digit shape. For instance, a target object, such as a blue 3, is the only object that is blue in color and is “3” in shape. In terms of features, it shares with a distractor (e.g., a blue 4) in color and with another distractor (e.g., a green 3) in digit identity. If the advantage conveyed by tracking distinct objects over tracking homogeneous objects operates upon a color-digit integrated object, then it should also enhance performance in the conjunction-distinct condition. In contrast, if the advantage for tracking distinct objects emerges primarily from distinguishing features that are not fully integrated together, then the conjunction-distinct condition may not yield superior performance to the homogeneous condition.<marker type="block"/> Whether distinctiveness in the conjunction of two features helps attentive tracking is an interesting question not addressed previously. When objects are static, binding of separate features to form an integrated object is easily achieved. Indeed, extensive research has shown that visual attention and visual working memory operate on the basis of integrated objects (<xref ref-type="bibr" rid="R2" id="53" class="deo:Reference">Duncan, 1984</xref>; <xref ref-type="bibr" rid="R13" id="54" class="deo:Reference">Scholl, 2001</xref>). For example, participants can remember all four colors and all four orientations as well as remembering only four colors or only four orientations, as long as the colors and orientations conjoin to form four colored oriented lines (<xref ref-type="bibr" rid="R6" id="55" class="deo:Reference">Luck &amp; Vogel, 1997</xref>). Feature binding may become much more difficult in attentive tracking, however, where objects are moving and where a subset of objects is not actively attended (Pylyshyn, 1989; but see Cavanagh &amp; Alvarez, 2005). In turn, the conjunction-distinct condition may produce performance similar to one of the paired conditions, where targets and distractors share featural information (see <xref ref-type="table" rid="T1" id="56" class="deo:Reference">Table 1</xref>, color-paired, digit-paired, and conjunction-paired). Sample trials can be viewed online at <ext-link ext-link-type="uri" href="http://jianglab.psych.umn.edu/MOTdigits/MOTdigits.htm." id="57">http://jianglab.psych.umn.edu/MOTdigits/MOTdigits.htm.</ext-link></region>
      <outsider class="DoCO:TextBox" type="footer" id="49" page="3" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
      <outsider class="DoCO:TextBox" type="header" id="50" page="4" column="1">Makovski and Jiang</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="51" page="4" column="1">Page 4</outsider>
      <region class="DoCO:TextChunk" id="59" confidence="possible" page="4" column="1">In short, by comparing performance in the different identity-distinct conditions with the homogeneous condition, this study informs us how feature binding operates in attentive tracking.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="60" page="4" column="1">Method Participants</outsider>
      <region class="DoCO:TextChunk" id="61" confidence="possible" page="4" column="1">All participants were volunteers from the University of Minnesota between 18 and 33 years old. They all had normal color vision and normal or corrected-to-normal visual acuity. 20 participants took part in the main experiment.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="62" page="4" column="1">Equipment</outsider>
      <region class="DoCO:TextChunk" id="65" confidence="possible" page="4" column="1">Participants were tested individually in a room with normal interior lighting. They sat approximately 57cm away from a 19” computer monitor. The experiment was programmed with psychophysical toolbox (<xref ref-type="bibr" rid="R1" id="63" class="deo:Reference">Brainard, 1997</xref>; <xref ref-type="bibr" rid="R9" id="64" class="deo:Reference">Pelli, 1997</xref>) implemented in MATLAB (www.mathworks.com).</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="66" page="4" column="1">Stimuli</outsider>
      <region class="DoCO:TextChunk" id="73" page="4" column="1">The moving objects were colored digits (each fit within a 1.5°×1.5° imaginary square) presented against a black background. There were eight possible colors (red, green, blue, yellow, orange, azure, white, and pink) and eight possible digits (1 to 8). The colors and digits were randomly sampled according to a trial’s condition. <marker type="block"/> Participants were tested in 8 conditions with 15 trials each, presented in a randomly intermixed order. All conditions used similar trial sequences. Participants pressed the spacebar to initiate each trial. Eight colored digits were presented at randomly selected locations within an<marker type="page" number="5"/><marker type="block"/> imaginary presentation window of 21°×21°. Four of the objects were surrounded by white frames (1.9°×1.9°), which identified their status as tracking targets. After 1330msec, the frames disappeared and the objects started moving randomly within the presentation window. The objects moved at a constant speed of 21.9°/s, bounced off the “wall” of the presentation window, and repelled one another when a minimal center-to-center distance of 2.1° was reached. Participants were asked to track the cued targets and were encouraged to maintain central fixation during tracking. After the objects moved for 7 seconds and stopped, they all turned to white disks (1.5° in diameter). Participants were asked to click on the four targets. The correctly selected targets turned green while the missed targets turned red to provide feedback for 1 second.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="68" page="4" column="1">Procedure</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="70" page="4" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
      <outsider class="DoCO:TextBox" type="header" id="71" page="5" column="1">Makovski and Jiang</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="72" page="5" column="1">Page 5</outsider>
      <outsider class="DoCO:TextBox" type="sidenote" id="74" page="5" column="1">Design</outsider>
      <region class="DoCO:TextChunk" id="76" confidence="possible" page="5" column="1">The eight conditions differed in the distinctness of identity (<xref ref-type="table" rid="T1" id="75" class="deo:Reference">Table 1</xref>). All eight objects were identical in the homogenous condition (e.g., they were all red 2s); the exact color and digit identity was randomly selected on each trial of that condition.</region>
      <region class="DoCO:TextChunk" id="78" page="5" column="1">There were four “distinct” conditions. The eight objects were uniform in digit identity but distinct in color in the color-distinct condition (e.g., they were all 4s, but in 8 different colors). The objects were the same in color but distinct in digit identity in the digit-distinct condition (e.g., they were all red, but in 8 different digit identities). Or the objects were distinct in both color and digit identity in the both-distinct condition (e.g., all 8 digits and all 8 colors were used in random combination). The conjunction-distinct condition involved distinct objects produced by the conjunction of four colors and four digits. In this condition, no two objects were the same in the combination of color and digit, but a given target (e.g., a blue 3) always shared color with one of the distractors (e.g., a blue 4) and digit identity with another distractor (e.g., a green 3). <marker type="block"/> Finally, there were three “paired” conditions in which all four targets were distinct and all four distractors were distinct, but each of the targets was the same as one of the distractors. In the color-paired condition, for instance, all objects were the same in digit identity, but the four targets were distinct in color, and the four distractors were distinct in color, and a target always shared a distractor’s color. Similarly, in the digit-paired condition, the targets and distractors were paired in digit identity but each subset was distinct. In the conjunction-paired condition, the targets and distractors were paired in both digit identity and color, but each subset was distinct. Note that the conjunction-paired condition included 4 digits and 4 colors which were paired to make one target identical to one distractor. The conjunction-distinct condition also included 4 digits and 4 colors, however the features were combined such that all 8 objects were distinct in color-digit combination.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="79" page="5" column="1">Results</outsider>
      <region class="DoCO:TextChunk" id="81" confidence="possible" page="5" column="1"> <xref ref-type="fig" rid="F1" id="80" class="deo:Reference">Figure 1</xref> depicts mean tracking accuracy as a function of stimulus condition in the main experiment.</region>
      <outsider class="DoCO:TextBox" type="sidenote" id="82" page="5" column="1">(1)</outsider>
      <region class="DoCO:TextChunk" id="93" page="5" column="1">Homogeneous versus distinct identities Does distinctiveness in feature identities enhance tracking? We addressed this question by comparing performance in the homogeneous, color-distinct, digit-distinct, and both-distinct conditions using a repeated-measures ANOVA. Distinctiveness in color enhanced performance, F(1, 19) = 14.60, p &lt; .01, as did distinctiveness in digit identity, F(1, 19) = 6.70, p &lt; .05. The interaction between color distinctiveness and digit distinctiveness was marginally significant, F(1, 19) = 3.20, p = .09, as the two factors were slightly under-additive. Pairwise t-tests showed that each of the three feature-distinct conditions was significantly higher in <marker type="page" number="6"/><marker type="block"/> accuracy than the homogeneous condition, all ps &lt; .001. These results clearly showed that attentive tracking was influenced by objects’ distinctive identities, even when participants were not required to remember what the objects were (see also <xref ref-type="bibr" rid="R4" id="87" class="deo:Reference">Horowitz et al., 2007</xref>).<marker type="block"/> Did the enhancement from distinct identities extend to a condition where the objects were distinct in terms of a combination of color and digit, but not in color or digit alone? Our results clearly showed that it did not. To the contrary, the conjunction-distinct condition had significantly lower accuracy than the homogeneous condition, t(19) = 3.30, p &lt; .004. The accuracy of the conjunction-distinct condition was also significantly lower than any of the three feature-distinct conditions, all ps &lt; .001.<marker type="block"/> Homogeneous versus paired identities The three paired conditions were designed such that objects had distinct features within each subset, but one target was always identical to one distractor. In these cases, tracking on the basis of distinct identity (e.g., a red 7) can only help distinguish between different targets, or between each specific target and three of the distractors. It does not help distinguish a target and its paired distractor. Our results showed that accuracy in the paired condition was lower than the accuracy in the homogeneous condition. The impairment was significant in the digit- paired condition, t(19) = 4.10, p &lt; .001, and the conjunction-paired condition, t(19) = 5.40, p &lt; .001, but was insignificant in the color-paired condition, t(19) = 1.60, p &gt; .10. These results suggest that the advantage afforded by distinguishing the target from other targets or from three of the distractors was outweighed by the disadvantage of confusing the target with an identical distractor.<marker type="block"/> Conjunction-distinct vs. conjunction-paired Both the conjunction-distinct and the conjunction-paired conditions were produced by conjoining four colors with four digits to form eight objects. The only difference was that the combination of digits and colors produced eight distinct objects in the former but four pairs of target-distractor in the latter. Does distinctiveness in feature conjunction produce any advantage in the former? No, the conjunction-distinct condition was not significantly better than the conjunction-paired condition, t(19) = 1.30, p &gt; .20.</region>
      <outsider class="DoCO:TextBox" type="footer" id="84" page="5" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
      <outsider class="DoCO:TextBox" type="header" id="85" page="6" column="1">Makovski and Jiang</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="86" page="6" column="1">Page 6</outsider>
      <outsider class="DoCO:TextBox" type="sidenote" id="90" page="6" column="1">(2)</outsider>
      <outsider class="DoCO:TextBox" type="sidenote" id="92" page="6" column="1">(3)</outsider>
      <outsider class="DoCO:TextBox" type="sidenote" id="94" page="6" column="1">Follow-up</outsider>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="95" page="6" column="1">Experiments</h1>
        <region class="DoCO:TextChunk" id="100" page="6" column="1">In addition to the main experiment, we conducted four control experiments to verify the generality of the results. The control experiments were similar in procedure to the main experiment, so we included a brief description of the methods and results. Descriptive statistics and p-values for these experiments are provided in <xref ref-type="table" rid="T2" id="96" class="deo:Reference">Table 2</xref>. Our main focus was to show that objects distinct in feature conjunction (but not in single features) are not tracked better than homogeneous objects.<marker type="block"/> Experiment 1: variable trial duration The unpredictable trial duration was used to discourage participants from using a strategy of not tracking until the final moments of a trial [footnote 1] 1 . Seven participants were tested in this experiment which was a replication of the main experiment, except that the duration of tracking was unpredictable. Each trial ended after 3.0, 3.8, 4.9, 6.3, or 8.0s of motion. Similar to the main experiment, each distinctiveness condition contained 15 trials, divided randomly and evenly into the 5 possible trial durations. The basic pattern of results (<xref ref-type="table" rid="T2" id="99" class="deo:Reference">Table 2</xref>) was the same as the main experiment: distinctness in features enhanced performance but distinctness in a combination of features did not. Compared with the homogeneous condition, accuracy was</region>
        <outsider class="DoCO:TextBox" type="sidenote" id="98" page="6" column="1">Control</outsider>
        <outsider class="DoCO:TextBox" type="sidenote" id="101" page="6" column="1">1We thank Todd</outsider>
        <region class="unknown" id="102" page="6" column="1">Horowitz for suggesting this possibility.</region>
        <outsider class="DoCO:TextBox" type="footer" id="103" page="6" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="104" page="7" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="105" page="7" column="1">Page 7</outsider>
        <region class="DoCO:TextChunk" id="106" confidence="possible" page="7" column="1">enhanced in the color-distinct and digit-distinct conditions, ps &lt; .03, but impaired in the conjunction-distinct condition, p &lt; .02.</region>
        <outsider class="DoCO:TextBox" type="sidenote" id="107" page="7" column="1">Control</outsider>
        <region class="DoCO:TextChunk" id="112" page="7" column="1">Experiment 2: Blocked design This experiment was designed to investigate whether effects of feature and conjunction distinctiveness held with a blocked (rather than mixed) design. Eleven participants were tested using colored digits as in the main experiment. They completed five conditions presented in separate blocks of trials; the order of blocks was randomized. The conditions were homogeneous, color-distinct, digit-distinct, both-distinct, and conjunction-distinct. There were 15 trials in each condition. Blocking the distinctive conditions did not produce an advantage in the conjunction-distinct condition compared with the homogeneous condition (p &gt; .40), which was significantly lower in accuracy than the feature-distinct conditions (ps &lt; .05). <marker type="block"/> Experiment 3: color and novel shapes Thirteen participants were tested in this experiment where digits were replaced by novel shapes that were difficult to name. Otherwise the experiment was identical to the main experiment. Again, the results were qualitatively similar to those of the main experiment. Distinctiveness in a combination of features failed to facilitate performance compared with the homogeneous condition, p &gt; .55.<marker type="block"/> Experiment 4: color and line orientations Line orientation is a simple visual feature that may be better integrated with color than digits or novel shapes [footnote 2] 2 . Ten participants were tested in this experiment where 8 oriented lines (20°-160° in units of 20°) replaced the digits. Still, the use of two simple features (color and line orientation) did not change the results. The conjunction-distinct condition again did not yield higher accuracy than the homogeneous condition, p &gt; .43.</region>
        <outsider class="DoCO:TextBox" type="sidenote" id="109" page="7" column="1">Control</outsider>
        <outsider class="DoCO:TextBox" type="sidenote" id="111" page="7" column="1">Control</outsider>
      </section>
      <section class="deo:Discussion">
        <h1 class="DoCO:SectionTitle" id="113" page="7" column="1">Discussion</h1>
        <region class="DoCO:TextChunk" id="132" page="7" column="1">Everyday visual experience suggests that we track moving objects not only on the basis of their motion trajectories but also on the basis of their surface features. Our study confirms this intuition. Attentive tracking of a subset of moving objects was more accurate when all objects were distinct in color or digit identity than if they were identical in color and digit identity. The enhancement by distinctive features was confined to conditions where at least a single feature differentiated all objects, as when all objects had different colors, but not when a combination of features differentiated all objects. In addition, even when the targets were distinct from one another, tracking was not enhanced if the distractors shared the targets’ colors or digit identities. Four follow-up experiments demonstrated the robustness of these effects by ruling out strategic biases (Control experiments 1-2) and by extending the range of the dimensions generating the effect (Control experiments 3-4). Together these findings have significant implications for feature binding in attentive tracking. <marker type="block"/> First, the finding that distinctiveness in features enhances tracking apparently contradicts previous results, where participants were found to have poor memory for surface properties in a multiple-object tracking task (<xref ref-type="bibr" rid="R14" id="115" class="deo:Reference">Scholl et al., 1999</xref>). Indeed, trying to remember object identities may actively interfere with the ability to track (<xref ref-type="bibr" rid="R3" id="116" class="deo:Reference">Fougnie &amp; Marois, 2006</xref>). The discrepancy can be accounted for by an important difference between our study and the previous studies. Namely, we did not require participants to remember object identities. If we had stopped our participants occasionally to probe their memory of object identities, we might also have<marker type="page" number="8"/><marker type="block"/> observed poor performance. Nonetheless, distinctiveness in features may help segregate targets from nontargets, a critical component of attentive tracking (<xref ref-type="bibr" rid="R19" id="123" class="deo:Reference">Yantis, 1992</xref>).<marker type="block"/> We also found that performance was impaired in the paired-identity conditions compared with the homogeneous condition, a finding that was observed in one but not another of Horowitz et al.’s (2007) experiments. The effect was not always statistically reliable (<xref ref-type="table" rid="T2" id="125" class="deo:Reference">Table 2</xref>), but it had been observed several times (see also Makovski &amp; Jiang, submitted). The impairment was somewhat surprising because the paired-identity conditions were more distinctive than the homogeneous condition, as each object was distinctive in feature from all but one other object. One might expect that distinctiveness would enhance, rather than impair, performance in the paired-identity condition. In a subsequent study, we found that the impairment for paired conditions was observed only when the paired condition was randomly intermixed in presentation with the distinct and homogeneous conditions (Makovski &amp; Jiang, submitted). Testing these conditions in separate blocks of trials removed impairment in the paired condition. Our current conclusion is that the use of identity information in multiple-object tracking is not obligatory, but is under strategic control. A tendency to rely on identity was also applied to the paired condition when trials were randomly intermixed, because identity information helped performance on distinct trials,. This strategy sets up a competition between two types of perceptual grouping: Grouping on the basis of attentional set (tracking targets versus nontargets), and grouping on the basis of surface features (red objects vs. green objects and so on). The competition from feature grouping impaired the effectiveness of attentional grouping. Competition for the two kinds of grouping cannot explain the lack of a benefit in the conjunction-distinct condition, however, as blocking conditions did not facilitate its performance compared with the homogeneous condition.<marker type="block"/> The results of the current study clearly demonstrate that feature rather than conjunction distinctiveness enhances tracking performance. Does this benefit reflect improved tracking abilities, or that distinctiveness provides additional information for recovering lost targets (<xref ref-type="bibr" rid="R4" id="127" class="deo:Reference">Horowitz et al., 2007</xref>)? On the one hand, tracking ability may be directly improved because observers can tolerate closer distance between a target and a distractor when they have distinct identities. On the other hand, identity information may be held in a separate system, such as visual working memory, which allows participants to recover a lost target. To disassociate these possibilities, in a recent study we asked participants to track distinct objects whose color changed once every 260msec (Makovski &amp; Jiang, submitted). The objects were always distinct from one another at any given moment, but the continuity of identity information over time was destroyed. In this setup, participants could no longer track the distinct condition better than the homogeneous condition. These data are more consistent with the second hypothesis, which asserts that identity information is kept in a system (e.g., visual working memory) that operates in parallel to motion tracking.<marker type="block"/> Even though features held in visual working memory are typically considered to be bound together to form coherent objects (<xref ref-type="bibr" rid="R6" id="129" class="deo:Reference">Luck &amp; Vogel, 1997</xref>), our results suggest that they are not properly conjoined during attentive tracking. Distinctiveness in feature-conjunction would have produced as much advantage as distinctiveness in features had they have been properly conjoined. Apparently, motion made such feature binding more difficult to retain, probably because the basis for binding - shared location (<xref ref-type="bibr" rid="R17" id="130" class="deo:Reference">Treisman, 1988</xref>) - is no longer a perceptually stable property.<marker type="block"/> In summary, we have shown that multiple-object tracking is sensitive to the distinctness in object identities, even in a task where identity memory is never probed. The enhancement is largely feature-based, revealing a limited degree of feature binding in attentive tracking.</region>
        <outsider class="DoCO:TextBox" type="sidenote" id="118" page="7" column="1">2We thank Todd were more</outsider>
        <region class="unknown" id="119" page="7" column="1">Horowitz for this suggestion. Digits, rather than orientations, were used in the main experiment because the 8 digits distinctive than the 8 orientations.</region>
        <outsider class="DoCO:TextBox" type="footer" id="120" page="7" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="121" page="8" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="122" page="8" column="1">Page 8</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="133" page="8" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="134" page="9" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="135" page="9" column="1">Page 9</outsider>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="136" page="9" column="1">Acknowledgements</h1>
        <region class="unknown" id="137" page="9" column="1">This research was supported in part by NSF 0733764 and NIH 071788. We thank Leah Watson, Khena Swallow, Carrick Williams, Todd Horowitz and James Brockmole for comments and suggestions.</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="138" page="9" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="139" page="9" column="1">Brainard DH. The psychophysics toolbox. Spatial Vision 1997;10(4):433–436. [PubMed: 9176952]</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="140" confidence="possible" page="9" column="1">Duncan J. Selective Attention and the Organization of Visual Information. Journal of Experimental Psychology-General 1984;113(4):501–517. [PubMed: 6240521]</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="141" confidence="possible" page="9" column="1">Fougnie D, Marois R. Distinct capacity limits for attention and working memory - Evidence from attentive tracking and visual working memory paradigms. Psychological Science 2006;17(6):526–534. [PubMed: 16771804]</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="142" confidence="possible" page="9" column="1">Horowitz TS, Klieger SB, Fencsik DE, Yang KK, Alvarez GA, Wolfe JM. Tracking unique objects. Perception &amp; Psychophysics 2007;69(2):172–184. [PubMed: 17557588]</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="143" confidence="possible" page="9" column="1">Kahneman D, Treisman A, Gibbs BJ. The Reviewing of Object Files - Object-Specific Integration of Information. Cognitive Psychology 1992;24(2):175–219. [PubMed: 1582172]</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="144" confidence="possible" page="9" column="1">Luck SJ, Vogel EK. The capacity of visual working memory for features and conjunctions. Nature 1997;390(6657):279–281. [PubMed: 9384378]</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="145" confidence="possible" page="9" column="1">Makovski T, Jiang YV. The role of visual working memory in attentive tracking of unique objects. submitted Mitroff SR, Alvarez GA. Space and time, not surface features, guide object persistence. Psychonomic Bulletin &amp; Review 2007;14(6):1199–1204. [PubMed: 18229497]</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="146" confidence="possible" page="9" column="1">Oksama L, Hyönä J. Is multiple object tracking carried out automatically by an early vision mechanism independent of higher-order cognition? An individual difference approach. Visual Cognition 2004;11:631–671.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="147" confidence="possible" page="9" column="1">Oksama L, Hyönä J. Dynamic binding of identity and location information: A serial model of multiple- identity tracking. Cognitive Psychology. in press Pelli DG. The VideoToolbox software for visual psychophysics: Transforming numbers into movies. Spatial Vision 1997;10(4):437–442. [PubMed: 9176953]</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="148" confidence="possible" page="9" column="1">Pylyshyn ZW. Some puzzling findings in multiple object tracking: I. Tracking without keeping track of object identities. Visual Cognition 2004;11(7):801–822.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="149" confidence="possible" page="9" column="1">Pylyshyn ZW, Storm RW. Tracking multiple independent targets: Evidence for a parallel tracking mechanism. Spatial Vision 1988;3:179–197. [PubMed: 3153671]</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="150" confidence="possible" page="9" column="1">Saiki J. Feature binding in object-file representations of multiple moving items. Journal of Vision 2003;3 (1):6–21. [PubMed: 12678621]</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="151" confidence="possible" page="9" column="1">Scholl BJ. Objects and attention: the state of the art. Cognition 2001;80(12):1–46. [PubMed: 11245838]</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="152" confidence="possible" page="9" column="1">Scholl BJ, Pylyshyn ZW, Franconeri SL. When are featural and spatiotemporal properties encoded as a result of attentional allocation? Investigative Ophthalmology &amp; Visual Science 1999;40(4):S797– S797.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="153" confidence="possible" page="9" column="1">Sinha, P. From fragments to objects: Mechanisms of visual integration; Paper presented at the 2007 Summer Institute on the Visual Perception &amp; Cognition Conference; Minneapolis, MN. 2007;</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="154" confidence="possible" page="9" column="1">Spelke, E.; Gutheil, G.; Van de Walle, G. The development of object perception. In: Osherson, D., editor. Invitation to Cognitive Science, 2nd Ed., Vol 2: Visual Cognition. MIT Press; Cambridge, MA: 1995.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="155" confidence="possible" page="9" column="1">Treisman A. Features and Objects - the 14th Bartlett Memorial Lecture. Quarterly Journal of Experimental Psychology Section a-Human Experimental Psychology 1988;40(2):201–237.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="156" confidence="possible" page="9" column="1">Xu F, Carey S. Infants’ metaphysics: The case of numerical identity. Cognitive Psychology 1996;30(2): 111–153. [PubMed: 8635312]</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="157" confidence="possible" page="9" column="1">Yantis S. Multielement visual tracking: Attention and perceptual organization. Cognitive Psychology 1992;24:295–340. [PubMed: 1516359]</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="footer" id="158" page="9" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="159" page="10" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="160" page="10" column="1">Page 10</outsider>
        <region class="DoCO:FigureBox" id="F1">
          <image class="DoCO:Figure" src="5u.page_010.image_02.png" thmb="5u.page_010.image_02-thumb.png"/>
          <caption class="deo:Caption" id="162" confidence="possible" page="10" column="1">Figure 1.</caption>
        </region>
        <region class="DoCO:TextChunk" id="163" page="10" column="1">Tracking accuracy as a function of stimulus conditions (Error bars show ±1 standard error of the mean). The dashed line represents performance in the homogenous condition.</region>
        <outsider class="DoCO:TextBox" type="footer" id="164" page="10" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="165" page="11" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="166" page="11" column="1">Page 11</outsider>
        <region class="DoCO:TableBox" id="T1">
          <caption class="deo:Caption" id="167" page="11" column="1">Table 1</caption>
        </region>
        <outsider class="DoCO:TextBox" type="sidenote" id="168" page="11" column="1">A schematic</outsider>
        <region class="unknown" id="169" page="11" column="1">illustration of tracking objects used in Experiment 1 Targets</region>
        <region class="DoCO:FigureBox" id="Fx170">
          <image class="DoCO:Figure" src="5u.page_011.image_03.png" thmb="5u.page_011.image_03-thumb.png"/>
          <image class="DoCO:Figure" src="5u.page_011.image_04.png" thmb="5u.page_011.image_04-thumb.png"/>
          <image class="DoCO:Figure" src="5u.page_011.image_05.png" thmb="5u.page_011.image_05-thumb.png"/>
          <image class="DoCO:Figure" src="5u.page_011.image_06.png" thmb="5u.page_011.image_06-thumb.png"/>
        </region>
        <outsider class="DoCO:TextBox" type="footer" id="171" page="11" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="172" page="12" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="173" page="12" column="1">Page 12</outsider>
        <region class="unknown" id="174" page="12" column="1">Targets</region>
        <region class="DoCO:FigureBox" id="Fx175">
          <image class="DoCO:Figure" src="5u.page_012.image_08.png" thmb="5u.page_012.image_08-thumb.png"/>
          <image class="DoCO:Figure" src="5u.page_012.image_07.png" thmb="5u.page_012.image_07-thumb.png"/>
        </region>
        <outsider class="DoCO:TextBox" type="footer" id="176" page="12" column="1">Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="177" page="13" column="1">Makovski and Jiang</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="178" page="13" column="1">Page 13</outsider>
        <outsider class="DoCO:TextBox" type="sidenote" id="179" page="13" column="1">N/A</outsider>
        <outsider class="DoCO:TextBox" type="sidenote" id="180" page="13" column="1">trial design Variable duration Blocked 1: 2:</outsider>
        <region class="unknown" id="181" page="13" column="1">shapes orientations Novel</region>
        <outsider class="DoCO:TextBox" type="footer" id="182" page="13" column="1">Line 3: 4: Vis cogn. Author manuscript; available in PMC 2009 June 1.</outsider>
      </section>
    </body>
  </article>
</pdfx>
