<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>9aa7268950db63b1b9beac4221eabbdc9a9609522162741df11656be58cd653a</job>
    <base_name>x</base_name>
    <doi>10.1037/0278-7393.34.2.399</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="1">Journal of Experimental Psychology: Learning, Memory, and Cognition 2008, Vol. 34, No. 2, 399 – 407</outsider>
      <outsider class="DoCO:TextBox" type="header" id="2">Copyright 2008 by the American Psychological Association 0278-7393/08/$12.00 DOI: 10.1037/0278-7393.34.2.399</outsider>
      <title-group>
        <article-title class="DoCO:Title" id="3">Multidimensional Visual Statistical Learning</article-title>
      </title-group>
      <region class="DoCO:TextChunk" id="4" confidence="possible">Nicholas B. Turk-Browne, Phillip J. Isola, Brian J. Scholl, and Teresa A. Treat Yale University</region>
      <abstract class="DoCO:Abstract" id="5" confidence="possible">Recent studies of visual statistical learning (VSL) have demonstrated that statistical regularities in sequences of visual stimuli can be automatically extracted, even without intent or awareness. Despite much work on this topic, however, several fundamental questions remain about the nature of VSL. In particular, previous experiments have not explored the underlying units over which VSL operates. In a sequence of colored shapes, for example, does VSL operate over each feature dimension independently, or over multidimensional objects in which color and shape are bound together? The studies reported here demonstrate that VSL can be both object-based and feature-based, in systematic ways based on how different feature dimensions covary. For example, when each shape covaried perfectly with a particular color, VSL was object-based: Observers expressed robust VSL for colored-shape sub-sequences at test but failed when the test items consisted of monochromatic shapes or color patches. When shape and color pairs were partially decoupled during learning, however, VSL operated over features: Observers expressed robust VSL when the feature dimensions were tested separately. These results suggest that VSL is object-based, but that sensitivity to feature correlations in multidimensional sequences (possibly another form of VSL) may in turn help define what counts as an object. Keywords: statistical learning, feature binding, objects, feature dimensions</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <region class="DoCO:TextChunk" id="6" page="1" column="1">Visual perception is remarkable in at least two ways. First, it serves to make us aware of a highly coherent and structured world, despite noisy fragmented input. Second, it provides such experiences without any hint of the underlying computational complexity involved in their construction. In fact, recent work has demonstrated that perception is supported by surprisingly subtle types of visual associative learning. One type of learning—visual statistical learning—may be particularly important in this context, since it can occur automatically and without any intent or even awareness.</region>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="7" confidence="possible" page="1" column="1">Visual Statistical Learning</h1>
      </section>
      <region class="DoCO:TextChunk" id="12" page="1" column="1">The study of implicit learning has a long history in psychology (see <xref ref-type="bibr" rid="R37" id="8" class="deo:Reference">Stadler &amp; Frensch, 1998</xref>), going back to early studies of learning in natural languages (e.g., <xref ref-type="bibr" rid="R14" id="9" class="deo:Reference">Harris, 1955</xref>), artificial grammars (e.g., <xref ref-type="bibr" rid="R32" id="10" class="deo:Reference">Reber, 1967</xref>), and manual sequences of responses (e.g., <xref ref-type="bibr" rid="R24" id="11" class="deo:Reference">Nissen &amp; Bullemer, 1987</xref>). In its modern incarnation, the study of statistical learning began with the demonstration that young infants are able to find “word” boundaries in acoustically unsegmented syllable sequences by using only the differential transitional prob-</region>
      <region class="DoCO:TextChunk" id="15" confidence="possible" page="1" column="1">Nicholas B. Turk-Browne, Phillip J. Isola, Brian J. Scholl, and Teresa A. Treat, Department of Psychology, Yale University. Nicholas B. Turk-Browne was supported by a foreign Natural Sciences and Engineering Research Council of Canada postgraduate scholarship, and Brian J. Scholl was supported by National Science Foundation Grant BCS-0132444. For helpful conversation and comments on drafts of the article, we thank Tim Brady, Marvin Chun, Rochel Gelman, Justin Jung  ́, Stephan Lewandowsky, Christian Luhmann, and Pierre Perruchet. We thank Dick Aslin for providing the shape stimuli. Correspondence concerning this article should be addressed to Nicholas B. Turk-Browne or Brian J. Scholl, Department of Psychology, Yale University, Box 208205, New Haven, CT 06520-8205. E-mail: <email id="13">nicholas.turk-browne@yale.edu</email> or <email id="14">brian.scholl@yale.edu</email></region>
      <region class="DoCO:TextChunk" id="46" page="1" column="2">abilities between syllables (Saffran, Aslin, &amp; <xref ref-type="bibr" rid="R34" id="16" class="deo:Reference">Newport, 1996</xref>). The precise relationship between such forms of statistical learning and the implicit learning literature more generally is under active consideration (<xref ref-type="bibr" rid="R31" id="17" class="deo:Reference">Perruchet &amp; Pacton, 2006</xref>). The auditory statistical learning design was later adapted for use with visual stimuli in studies with adult observers by Fiser and Aslin (2002a; see also <xref ref-type="bibr" rid="R26" id="18" class="deo:Reference">Olson &amp; Chun, 2001</xref>). Observers viewed an animation in which a single object moved horizontally across the screen, continuously cycling back and forth behind a central occluder and changing its shape each time it passed behind the occluder (see <xref ref-type="fig" rid="F1a" id="19" class="deo:Reference">Figure 1a</xref>). Observers watched this animation for only a few minutes, with no specific task. The sequence of shapes, though apparently random, actually consisted of temporal “triplets” in which the same three shapes always appeared in the same order (e.g., A-B-C-G-H-I-D-E-F-A-B-C . . .). Critically, only this statistical regularity demarcated the triplets, since the intershape delay was always the same. After this passive exposure, observers completed a surprise two-interval-forced-choice familiarity task that pitted triplets (e.g., ABC) against foil sequences of three shapes with a joint probability of zero (e.g., AEI). Observers correctly identified the triplets as more familiar than the foil sequences 95% of the time, indicating robust statistical learning of visual temporal sequences. While the use of deterministic triplets and familiarity judgments may support explicit recognition of the regularities in some cases, visual statistical learning (VSL) can also occur during an orthog- onal task (such as repetition detection), without any reported awareness of the statistical structure (Turk-Browne, Jung  ́, &amp; <xref ref-type="bibr" rid="R2" id="20" class="deo:Reference">Scholl, 2005</xref>), and can facilitate online performance (<xref ref-type="bibr" rid="R15" id="21" class="deo:Reference">Hunt &amp; Aslin, 2001</xref>; <xref ref-type="bibr" rid="R26" id="22" class="deo:Reference">Olson &amp; Chun, 2001</xref>; Turk-<xref ref-type="bibr" rid="R17" id="23" class="deo:Reference">Browne et al., 2005</xref>; Turk-<xref ref-type="bibr" rid="R42" id="24" class="deo:Reference">Browne &amp; Scholl, 2006</xref>). Other recent work with VSL has demonstrated that such learning operates over spatial as well as temporal regularities (e.g.,<marker type="page" number="2"/><marker type="column" number="1"/><marker type="block"/> Baker, Olson, &amp; <xref ref-type="bibr" rid="R3" id="33" class="deo:Reference">Behrmann, 2004</xref>; <xref ref-type="bibr" rid="R5" id="34" class="deo:Reference">Chun &amp; Jiang, 1998</xref>; <xref ref-type="bibr" rid="R8" id="35" class="deo:Reference">Fiser &amp; Aslin, 2001</xref>); at multiple spatial scales (<xref ref-type="bibr" rid="R11" id="36" class="deo:Reference">Fiser &amp; Aslin, 2005</xref>); across multiple modalities (<xref ref-type="bibr" rid="R7" id="37" class="deo:Reference">Conway &amp; Christiansen, 2005</xref>) and despite interleaved noise (Jung  ́, Turk-Browne, &amp; <xref ref-type="bibr" rid="R2" id="38" class="deo:Reference">Scholl, 2005</xref>; Turk-<xref ref-type="bibr" rid="R17" id="39" class="deo:Reference">Browne et al., 2005</xref>); and in young infants in addition to adults (<xref ref-type="bibr" rid="R10" id="40" class="deo:Reference">Fiser &amp; Aslin, 2002b</xref>; Kirkham, Slemmer, &amp; <xref ref-type="bibr" rid="R18" id="41" class="deo:Reference">Johnson, 2002</xref>). Moreover, other recent studies of temporal VSL have begun to elucidate some of the underlying processes that help make VSL possible, involving selective attention (Turk-<xref ref-type="bibr" rid="R17" id="42" class="deo:Reference">Browne et al., 2005</xref>), association (Turk-<xref ref-type="bibr" rid="R42" id="43" class="deo:Reference">Browne &amp; Scholl, 2006</xref>), computations of persisting object representations (Fiser, Scholl, &amp; <xref ref-type="bibr" rid="R12" id="44" class="deo:Reference">Aslin, 2007</xref>), and anticipation (Turk-Browne, Johnson, Chun, &amp; <xref ref-type="bibr" rid="R12" id="45" class="deo:Reference">Scholl, 2007</xref>).</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="26" page="1" column="2">399</outsider>
      <outsider class="DoCO:TextBox" type="header" id="27" page="2" column="1">TURK-BROWNE, ISOLA, SCHOLL, AND TREAT</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="28" page="2" column="1">400</outsider>
      <region class="DoCO:FigureBox" id="F1">
        <image class="DoCO:Figure" src="x.page_002.image_01.png" thmb="x.page_002.image_01-thumb.png"/>
        <caption class="deo:Caption" id="32" page="2" column="1">Figure 1. Stimuli and trial sequence. (a) Depiction of the display used in the present experiments (and in <xref ref-type="bibr" rid="R9" id="30" class="deo:Reference">Fiser &amp; Aslin, 2002a</xref>). A single object oscillates back and forth across the display, changing into a new object each time it passes behind the stationary central occluder. (b) The 12 nonsense shapes used in our study, from <xref ref-type="bibr" rid="R8" id="31" class="deo:Reference">Fiser and Aslin (2001)</xref>. (c) The 12 nonblack colors used in our study (depicted here with different patterns and gray levels).</caption>
      </region>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="47" confidence="possible" page="2" column="1">The Units of VSL: Features or Objects?</h1>
        <region class="DoCO:TextChunk" id="53" page="2" column="1">Despite this considerable body of work on VSL, several fundamental questions remain about its nature. In particular, previous experiments have not determined the underlying units over which VSL operates. In a sequence of colored shapes, for example, does VSL operate over each feature dimension independently, or over multidimensional objects in which color and shape are intrinsically bound together? Our study modifies two aspects of previous designs, which rendered them unable to answer this question. First, most previous studies used either monochromatic shapes (so that there was no statistical information about color; e.g., <xref ref-type="bibr" rid="R9" id="48" class="deo:Reference">Fiser &amp; Aslin, 2002a</xref>) or sequences in which each shape had a single unique color (so that the statistics of color were also perfectly correlated with those of shape; e.g., <xref ref-type="bibr" rid="R10" id="49" class="deo:Reference">Fiser &amp; Aslin, 2002b</xref>; <xref ref-type="bibr" rid="R18" id="50" class="deo:Reference">Kirkham et al., 2002</xref>). Second, in all but one previous VSL experiment, the surface features present during familiarization were always present during test. 1 Exploring the nature of the underlying units of VSL seems important for several reasons: First, the existence of multiple feature dimensions is an inescapable facet of real-world visual experience, and thus these studies may help to reveal how VSL operates in a more ecologically valid situation. Second, exploring the necessity of certain features during familiarization and test may<marker type="column" number="2"/><marker type="block"/> have important implications for how readily learning in one situation will transfer to another (see also Turk-<xref ref-type="bibr" rid="R42" id="52" class="deo:Reference">Browne &amp; Scholl, 2006</xref>). Finally, and most generally, one of the most critical steps in understanding any cognitive or perceptual process is to determine the underlying currency over which that process operates. In the following experiments, we explore how VSL operates over individual features and bound objects.</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="54" confidence="possible" page="2" column="2">General Method</h1>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="55" page="2" column="2">Observers</h1>
        <region class="DoCO:TextChunk" id="56" page="2" column="2">Seventy-two na  ̈ve subjects (16 in Experiments 1, 2, 3, and 4a; 8 in Experiment 4b), all with normal or corrected-to-normal acuity and color vision, participated for course credit or monetary com- pensation.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="57" page="2" column="2">Apparatus and Stimuli</h1>
        <region class="DoCO:TextChunk" id="62" page="2" column="2">Stimuli were presented with custom software written with the VisionShell graphics libraries (<xref ref-type="bibr" rid="R6" id="58" class="deo:Reference">Comtois, 2004</xref>) on Apple desktop computers. Observers sat approximately 46 cm from the monitor without head restraint. Displays were constructed from a set of 12 nonsense shapes used previously in studies of VSL (<xref ref-type="fig" rid="F1b" id="59" class="deo:Reference">Figure 1b</xref>; e.g., <xref ref-type="bibr" rid="R8" id="60" class="deo:Reference">Fiser &amp; Aslin, 2001</xref>). Each shape appeared in one or more of 13 colors (including black; see <xref ref-type="fig" rid="F1c" id="61" class="deo:Reference">Figure 1c</xref>), and subtended roughly 3.3°. Each sequence began with the object located in the center of</region>
        <region class="DoCO:TextChunk" id="65" confidence="possible" page="2" column="2">1 The one exception is the study of Turk-<xref ref-type="bibr" rid="R17" id="63" class="deo:Reference">Browne et al. (2005)</xref>, who observed expression of learning at test for monochromatic shapes that had been colored during familiarization. However, the color information during familiarization in this study was used only to manipulate attention, and was not diagnostic; in fact, each shape throughout the study appeared in one of only two colors, and only one color was attended. In addition, one auditory statistical learning study has employed stimuli that varied between familiarization and test: <xref ref-type="bibr" rid="R39" id="64" class="deo:Reference">Thiessen and Saffran (2003)</xref> changed the prosody of spoken syllables after familiarization and still observed auditory temporal statistical learning in 9-month-old infants.</region>
        <outsider class="DoCO:TextBox" type="header" id="66" page="3" column="1">MULTIDIMENSIONAL VISUAL STATISTICAL LEARNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="67" page="3" column="1">401</outsider>
        <region class="DoCO:TextChunk" id="69" page="3" column="1">the display, where it immediately began moving to either the left or right at 11.48°/s. When the center of the object was 12.76° from the display border, the object immediately reversed direction and moved toward the same point on the opposite side of the screen. The object then continued back toward the center of the display, at which time the entire movement could be repeated. A stationary gray occluder, subtending 9.51° 5.68°, was always present in the center of the display. The object was (at least partially) visible for 1 s between each moment of complete occlusion (see <xref ref-type="fig" rid="F1a" id="68" class="deo:Reference">Figure 1a</xref>).</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="70" page="3" column="1">Procedure</h1>
        <region class="DoCO:TextChunk" id="71" page="3" column="1">Familiarization phase. Observers watched a 5-minute sequence of 288 colored shapes, presented as described above. Although the sequence of colors varied across experiments, the sequence of shapes was always identically structured. Each shape was assigned to a unique position in one of four triplets— sequences of three shapes that always appeared in the same order (e.g., ABC, GHI, etc.). Each third of the full shape sequence was generated by randomly interleaving 8 repetitions of each triplet with two constraints (for a total of 24 repetitions/triplet): (a) no triplet could be repeated sequentially (e.g., ABCABC), and (b) no pair of triplets could be immediately repeated (e.g., ABCGHIAB- CGHI). As a result, the joint probability of a triplet (e.g., ABC) was 0.083, while the joint probability of a sequence of three shapes spanning triplets (e.g., CGH) was 0.027. 2 Test phase. After the familiarization phase, observers completed 32 two-interval forced-choice test trials, judging the relative familiarity of (a) triplets versus (b) foil sequences of three familiar shapes that had never appeared sequentially during familiarization. 3 The triplet and foil sequences were presented on each trial in the same disoccluding– occluding manner as during familiarization, separated by a 1-second pause, and were randomly chosen with equal likelihood; the presentation order of the alternatives was randomized. Observers pressed a key if the first sequence seemed more familiar and a different key if the second sequence seemed more familiar. 4</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="72" confidence="possible" page="3" column="1">Experiment 1: Testing Bound Objects</h1>
        <region class="DoCO:TextChunk" id="73" page="3" column="1">While most previous studies have employed monochromatic shapes, this preliminary experiment verified that our method could give rise to VSL even when each shape had its own unique color during both familiarization and test, as a critical baseline for our later experiments.</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="74" page="3" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="76" page="3" column="1">Each shape was assigned a single unique nonblack color, in which it always appeared throughout the experiment (<xref ref-type="fig" rid="F2a" id="75" class="deo:Reference">Figure 2a</xref>).</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="77" page="3" column="1">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="79" page="3" column="1">In this and all future experiments, our measure of VSL was the percentage of test trials in which the triplet was chosen over the foil (where chance 50%). Observers showed robust statistical learning (80%; <xref ref-type="fig" rid="F3a" id="78" class="deo:Reference">Figure 3a</xref>) that differed significantly from chance, t(15) 5.730, p .001, d 1.432. This effect serves as a baseline for later experiments.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="80" confidence="possible" page="3" column="2">Experiment 2: Testing Separated Features</h1>
        <region class="DoCO:TextChunk" id="81" page="3" column="2">Did VSL in Experiment 1 operate over bound object representations? If so, then the presence of both features should be necessary for learning to be expressed at test, such that testing either monochromatic shapes or colored circles would break the binding (i.e., the associations between dimensions) and should attenuate the expression of VSL.</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="82" page="3" column="2">Method</h1>
        <region class="DoCO:TextChunk" id="85" page="3" column="2">The familiarization phase of this experiment was identical to that of Experiment 1. The test phase consisted of two separate blocks: a shape test and a color test (with order counterbalanced across observers). The shape test was identical to the test in Experiment 1, except that all shapes were presented in black (such that only shape information was preserved; see <xref ref-type="fig" rid="F2b" id="83" class="deo:Reference">Figure 2b</xref>). Conversely, the color test was identical to the test in Experiment 1, except that all colors were presented as circles (such that only color information was preserved; see <xref ref-type="fig" rid="F2b" id="84" class="deo:Reference">Figure 2b</xref>).</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="86" page="3" column="2">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="88" page="3" column="2">As depicted in <xref ref-type="fig" rid="F3b" id="87" class="deo:Reference">Figure 3b</xref>, observers expressed weak VSL in the shape test (57%), t(15) 2.159, p .047, d 0.540, and these results were significantly weaker than those in Experiment 1, t(30) 3.699, p .001, d 1.308. Observers expressed no significant VSL in the color test (55%), t(15) 1.412, p .178, d 0.353, and these results were again significantly weaker than those in Experiment 1, t(30) 4.033, p .001, d 1.426. There was no difference between the performance for shape and color (t 1). Critically, the familiarization phase in this experiment was identical to that in Experiment 1, suggesting that the weaker results here reflect only the expression of learning rather than the learning itself. These results suggest that performance in Experiment 1 was not driven by learning of sequences of features in either the shape or color dimension alone. Given that both features were necessary for VSL to be expressed, learning must have operated over bound shape– color pairs. An alternative explanation could be that individual observers only ever attended to either shape or color during learning. Thus,</region>
        <region class="DoCO:TextChunk" id="90" confidence="possible" page="3" column="2">2 For derivations of these probabilities, see Turk-<xref ref-type="bibr" rid="R17" id="89" class="deo:Reference">Browne et al., 2005</xref>. 3 The foils (e.g., AEI) contained three shapes that were equally familiar as the shapes in the triplets, but they had never been presented in succes- sion during familiarization. Thus, the two test sequences in each trial could be discriminated only based on statistical learning of the joint probabilities between shapes during familiarization: Observers could respond accurately only by noting relationships between individual shapes, in particular by encoding their nonzero joint probabilities. Note that while this is perhaps the most direct test of statistical learning, other studies have also tested for the learning of even subtler statistics, such as relative joint probability and conditional probability. 4 Following the test phase, observers were carefully debriefed to assess their explicit awareness of the triplet structure from familiarization. Note that such awareness would not necessarily indicate explicit or strategic learning per se; observers may instead become aware of the structure after implicit processes have run their course. Regardless, only 2 of 72 observers reported becoming fully aware of the triplet structure during familiarization. The majority of subjects fell into one of two groups, either reporting no awareness of any regular sequences or reporting that they noticed one or more pairs of objects that consistently appeared together.</region>
        <outsider class="DoCO:TextBox" type="header" id="91" page="4" column="1">TURK-BROWNE, ISOLA, SCHOLL, AND TREAT</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="92" page="4" column="1">402</outsider>
        <region class="DoCO:FigureBox" id="F2">
          <image class="DoCO:Figure" src="x.page_004.image_02.png" thmb="x.page_004.image_02-thumb.png"/>
          <caption class="deo:Caption" id="94" page="4" column="1">Figure 2. The familiarization and test structure for both shape and color across experiments. See text for details. Color is depicted here in terms of different patterns and gray levels.</caption>
        </region>
        <region class="DoCO:TextChunk" id="95" page="4" column="1">performance in Experiment 1 would be high (given that both dimensions were present at test), while average performance across individuals would be low in the feature tests in Experiment 2 (since half of the time observers would have attended to a feature dimension during learning that was not present at test). To explore this possibility, we correlated each observer’s shape performance in Experiment 2 with their color performance in Experiment 2, expecting a negative correlation if observers had attended to only one dimension. In contrast, we obtained a positive correlation (r .616, df 14; p .011), which is consistent only with learning of multidimensional objects.</region>
        <region class="DoCO:FigureBox" id="F3">
          <image class="DoCO:Figure" src="x.page_004.image_03.png" thmb="x.page_004.image_03-thumb.png"/>
          <caption class="deo:Caption" id="97" page="4" column="1">Figure 3. The degree of VSL measured as the percentage of triplets chosen over foil sequences for the bound objects of Experiment 1, the individual feature triplets of Experiment 2, the re-paired feature triplets of Experiment 3, the monochromatic shape triplets of Experiment 4a (as a function of color covariance during familiarization), and the color triplets of Experiment 4b. Error bars depict standard errors. Chance performance is 50%.</caption>
        </region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="98" confidence="possible" page="4" column="2">Experiment 3: Binding Versus Quantity of Statistical Information</h1>
        <region class="DoCO:TextChunk" id="102" page="4" column="2">The attenuated performance in Experiment 2 relative to Experiment 1 suggests that VSL is object-based, but it remains possible that observers performed better in Experiment 1 because the triplets presented during the test phase itself contained twice as much statistical information (i.e., accumulating over both shape and color dimensions potentially independently), and not because of feature binding between particular shapes and colors. To rule out this explanation, we equated the amount of statistical feature <marker type="page" number="5"/><marker type="column" number="1"/><marker type="block"/> information at test in this experiment (such that each test triplet contained both a shape and color triplet) but disrupted the feature binding (such that shape triplets were assigned different color triplets than during familiarization). If performance is still attenuated relative to Experiment 1, we can conclude that VSL operated over bound shape– color pairs and that such differences cannot be explained in terms of the brute amount of statistical information present in the input.</region>
        <outsider class="DoCO:TextBox" type="header" id="100" page="5" column="1">MULTIDIMENSIONAL VISUAL STATISTICAL LEARNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="101" page="5" column="1">403</outsider>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="103" page="5" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="105" page="5" column="1">The familiarization phase of this experiment was identical to that of Experiment 1. The test phase, however, pitted “re-paired triplets” against “re-paired foils.” Each re-paired triplet consisted of the shape sequence from one familiarization triplet appearing in the color sequence from a different familiarization triplet. In this way, each shape was assigned to a different color at test than during familiarization (see <xref ref-type="fig" rid="F2c" id="104" class="deo:Reference">Figure 2c</xref>). These reassignments were kept constant throughout the test and were also used to construct the re-paired foils (which contained unstructured sequences of shape and color). In other words, neither feature of the triplets violated the training sequence, whereas both features of the foils did so.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="106" page="5" column="1">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="108" page="5" column="1">As depicted in <xref ref-type="fig" rid="F3c" id="107" class="deo:Reference">Figure 3c</xref>, observers reliably preferred the re- paired triplets over the re-paired foils (64%), t(15) 3.168, p .006, d 0.792. Critically, expression of learning was significantly weaker when feature triplets were recombined at test in this experiment versus when presented in the same manner as during familiarization in Experiment 1, t(30) 2.327, p .027, d 0.823. Thus, performance in Experiment 1 cannot solely be attrib- uted to the fact that test triplets contained both shape and color triplets, further supporting the notion that VSL operates over bound shape– color pairs. Performance was not significantly better in Experiment 3 than in Experiment 2: shape test, t(30) 1.253, p .220, d 0.443; color test, t(30) 1.652, p .109, d 0.584. While our conclusions from this experiment are being driven by statistics rather than by numerical differences, note that our primary conclusion would not be altered even if these differences had reached significance. In other words, the purpose of this experiment was to rule out alternative explanations of Experiment 1 based on the presence of more feature information during test, or on increased surface similarity between familiarization and test phases. Our claim in this respect relies on a comparison only between Experiments 1 and 3. Indeed, the comparison of Experiments 2 and 3 would speak to a different question about whether the amount of feature information at test matters at all. This question seems independent; for example, the number of feature dimensions present at test may modulate performance, while presenting features with the same binding as during familiarization may provide an additional benefit.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="109" confidence="possible" page="5" column="1">Experiment 4a: Feature-Based Learning of Shapes</h1>
        <region class="DoCO:TextChunk" id="112" page="5" column="1">The first three experiments collectively demonstrate that VSL operates over bound objects, but how general is this conclusion? In <marker type="column" number="2"/><marker type="block"/> the real world, color and shape do covary for some objects (e.g., bananas) but not others (e.g., t-shirts). Is VSL sensitive to this type of distinction? The previous experiments employed multidimensional objects during familiarization, implemented in a particular way: Both color and shape varied during familiarization and did so in a correlated fashion. However, would VSL still be object-based even if the two feature dimensions did not perfectly covary? Here, we explored this possibility by testing with monochromatic shapes (as in Experiment 2), but we manipulated the covariance of shape and color during familiarization (<xref ref-type="fig" rid="F2d" id="111" class="deo:Reference">Figure 2d</xref>): Shapes in two of the triplets (matched-color triplets) were assigned unique colors as in the previous experiments, but the shapes in the remaining two triplets (random-color triplets) were assigned different randomly chosen colors on each presentation. If VSL is always object-based, then the results of this experiment should parallel those of Experiment 2: The shift to monochromatic shapes should frustrate the expression of learning. However, if VSL is sensitive to the covariance between feature values for individual objects (at the same time that the triplets themselves are being learned), then we might observe object-based learning for the matched-color triplets (i.e., attenuated performance due to the removal of color at test) but feature-based learning for the random-color triplets (i.e., strong performance despite the removal of color at test). A third possibility is that this type of diagnosticity is assessed for entire feature dimensions rather than individual feature values: The presence of at least some shape– color covariance (i.e., in the matched-color triplets) could yield object-based learning for all triplets, or the presence of deviation from such covariance (i.e., in the random-color triplets) could yield feature- based learning for all triplets.</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="113" page="5" column="2">Method</h1>
        <region class="DoCO:TextChunk" id="114" page="5" column="2">The familiarization phase of this experiment was identical to that of Experiment 2 except as noted here. The two matched-color triplets were sub-sequences of three shapes that were each paired with a unique color throughout the familiarization phase. The two random-color triplets were sub-sequences of three shapes that were paired with three colors drawn randomly on each presentation (from the remaining six colors), with the constraint that no color could appear twice in a row. In other words, shapes in the random triplets could appear in one of six colors at different points during familiarization. In this way, colors in random triplets were nondiagnostic of shape identity, while colors in the matched condition were perfectly diagnostic of shape identity. At test, all shapes were presented monochromatically.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="115" page="5" column="2">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="120" page="5" column="2">As depicted in <xref ref-type="fig" rid="F3d" id="116" class="deo:Reference">Figure 3d</xref>, observers expressed robust VSL despite the removal of color at test for both the matched-color triplets (74%), t(15) 3.973, p .001, d 0.993; and the random-color triplets (71%), t(15) 3.091, p .007, d 0.773, which did not differ (t 1). Three key implications follow from these results. First, the lack of any difference between the matched-color and random-color triplets indicates that the diagnosticities of individual color values do not affect the likelihood that shape triplets can be recognized without color. Second, performance for both the matched-color<marker type="page" number="6"/><marker type="column" number="1"/><marker type="block"/> and random-color triplets was significantly greater than chance— and not reliably different than in the colored-shape test of Experiment 1: matched-color, t 1; random-color, t(30) 1.143, p .262, d 0.404. This suggests that when the covariance between shape and color feature dimensions is disrupted even partially, VSL operates over shapes alone, in a feature-based manner. Third, performance for the (always-color-matched) triplets in Experiment 2 was worse than for the matched-color triplets, t(30) 2.403, p .023, d 0.849; and marginally worse than for the random-color triplets, t(30) 1.800, p .082, d 0.636. This provides further evidence that observers were sensitive to the diagnosticity between shape and color dimensions as a whole, such that color information was discarded— even for the matched triplets—when some colors were nondiagnostic.</region>
        <outsider class="DoCO:TextBox" type="header" id="118" page="6" column="1">TURK-BROWNE, ISOLA, SCHOLL, AND TREAT</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="119" page="6" column="1">404</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="121" confidence="possible" page="6" column="1">Experiment 4b: Feature-Based Learning of Colors</h1>
        <region class="DoCO:TextChunk" id="123" page="6" column="1">Would this switch to feature-based rather than object-based processing in the face of reduced covariance between feature dimensions also extend to other dimensions, or might it be peculiar to shape processing? Here, we addressed this question by repeating the familiarization phase of Experiment 4a, but now testing the two color triplets without their matched shapes (<xref ref-type="fig" rid="F2d" id="122" class="deo:Reference">Figure 2d</xref>).</region>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="124" page="6" column="1">Method</h1>
        <region class="DoCO:TextChunk" id="125" page="6" column="1">The familiarization phase of this experiment was identical to that of Experiment 4a, with six of the colors (e.g., A, B, C, D, E, F) uniquely paired with one of the shapes from two of the shape triplets, and six of the colors (e.g., G, H, I, J, K, L) randomly presented on each presentation of shapes from the other two shape triplets. The test phase was similar to the color test of Experiment 2, except that there were only two color triplets from familiarization (e.g., ABC, DEF). However, a test of only these two triplets would be underpowered since the two triplets could only be tested against two foils (resulting in eight trials: 2 triplets 2 foils 2 repetitions). We could not simply use four foils as before because the triplets would then appear twice as often as the foils during test (confounding the familiarity measure): The likelihood of a particular triplet appearing in a test trial would be 50%, while the likelihood of a particular foil appearing would be 25%. To avoid this issue while increas- ing the number of test trials, we also defined two pseudo-triplets from the six random colors (e.g., HLG, IKJ). The items within the pseudo-triplets were always presented in the same order, similar to the real triplets. The triplets and pseudo-triplets were then used to construct four foil sequences as in the other experiments (e.g., AEL, DLJ, HKA, IBF). Each of the “triplets” was tested against each of the foils twice, resulting in 16 trials containing a real triplet and 16 trials containing a pseudo- triplet. While data from the pseudo-triplet trials were meaning- less (since observers had no basis for selecting which pattern was more familiar, as confirmed by chance performance on these trials, t 1), their presence allowed us to equate the frequency of the real triplets with the frequency of all foils during the test phase. Data analysis was then restricted to the test trials containing real triplets.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="126" page="6" column="2">Results and Discussion</h1>
        <region class="DoCO:TextChunk" id="128" page="6" column="2">As depicted in <xref ref-type="fig" rid="F3d" id="127" class="deo:Reference">Figure 3d</xref>, observers expressed robust VSL for the two color triplets despite the removal of shape at test (72%), t(7) 2.892, p .023, d 1.023, thus providing further evidence that VSL can operate in a feature-based manner if the covariance between feature dimensions is disrupted. This conclusion is further supported by the fact that performance was significantly greater than in the color test of Experiment 2, t(22) 2.362, p .027, d 0.943. Moreover, this experiment also provides what we believe is the first demonstration of VSL for colors (or indeed for any feature dimension beyond shape). This rules out the possibility that observers simply discarded color information completely in Experiment 4a in order to learn shape sequences. Instead, low covariance between feature dimensions allowed VSL to operate in parallel in each of these dimensions.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="129" confidence="possible" page="6" column="2">General Discussion</h1>
        <region class="DoCO:TextChunk" id="130" page="6" column="2">The five experiments reported here constitute the first explora- tion, to our knowledge, of whether VSL operates over bound objects or lower level visual features. Our results suggest one straightforward implication (that VSL can be object-based), and one surprising possibility (that VSL can perhaps help to determine what counts as an object in the first place). We elaborate on each of these conclusions below.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="131" page="6" column="2">The Units of VSL</h1>
        <region class="DoCO:TextChunk" id="148" page="6" column="2">It is perhaps worth noting that we began these studies with no strong prediction about the results. On one hand, many researchers have stressed that VSL can be an automatic low-level process, which operates early in perceptual analysis to provide the initial segmentation on which other later processes depend. As such, we might predict that VSL would operate on those representations which are most common very early in perceptual processing, namely independent visual features. On the other hand, a wealth of data has indicated that discrete bound objects are the currency of many other types of visual processing, including attention ( <xref ref-type="bibr" rid="R35" id="132" class="deo:Reference">Scholl, 2001</xref>), tracking (<xref ref-type="bibr" rid="R2" id="133" class="deo:Reference">Alvarez &amp; Scholl, 2005</xref>), masking (<xref ref-type="bibr" rid="R22" id="134" class="deo:Reference">Moore &amp; Lleras, 2005</xref>), and short-term memory (<xref ref-type="bibr" rid="R1" id="135" class="deo:Reference">Alvarez &amp; Cavanagh, 2004</xref>; <xref ref-type="bibr" rid="R19" id="136" class="deo:Reference">Luck &amp; Vogel, 1997</xref>; <xref ref-type="bibr" rid="R46" id="137" class="deo:Reference">Xu &amp; Chun, 2006</xref>)—among many others. As such, we might predict that VSL would also be funda- mentally object-based, operating over representations in which features are already bound together. This possibility would also be consistent with another recent study in which VSL was more robust for sequences that were bound into the same persisting object representation as a result of spatiotemporal continuity (<xref ref-type="bibr" rid="R12" id="138" class="deo:Reference">Fiser et al., 2007</xref>). Here we operationalized the question of whether VSL is feature- based by asking whether the expression of VSL would survive the elision of some features at test, while the remaining features still possessed the same statistical structure that they had during familiarization. Our initial results demonstrated that VSL can be object- based: When colors and shapes perfectly covaried (i.e., when each shape had its own unique color) during familiarization, the expression of learning required the presence of both shapes and colors at<marker type="page" number="7"/><marker type="column" number="1"/><marker type="block"/> test (as in Experiment 1). Of course, there were still robust statistical correlations between the shapes themselves during familiarization, but the expression of learning of these shape sequences was considerably weaker when they were presented in isolation at test (with no reliable expression of learning for colors presented in isolation at test) in Experiment 2. Experiment 3 further demonstrated that the difference in performance between these two experiments was a function of feature binding per se, rather than the mere presence of more feature correlations (due to the added dimensions) present during the test phase of Experiment 1. The fact that the observers in Experiment 2 largely failed to recognize feature triplets at test is reminiscent of a result from the category learning literature (e.g., <xref ref-type="bibr" rid="R33" id="142" class="deo:Reference">Roberts &amp; MacLeod, 1995</xref>) showing that categorization cannot be expressed for constituent elements of a rule—analogous to our individual features—when learning is nonstrategic (like VSL, which has been considered a form of incidental learning; see Turk-<xref ref-type="bibr" rid="R17" id="143" class="deo:Reference">Browne et al., 2005</xref>). Our results also parallel a feature of associative models of Pavlovian conditioning and causal learning (see <xref ref-type="bibr" rid="R44" id="144" class="deo:Reference">Williams &amp; Braker, 1999</xref>), in which experience with compound cues—analogous to our multidimensional objects—results in associations involving those compounds, but not their constituent elements (e.g., <xref ref-type="bibr" rid="R30" id="145" class="deo:Reference">Pearce, 1987</xref>; see also Shanks, Charles, Darby, &amp; <xref ref-type="bibr" rid="R36" id="146" class="deo:Reference">Azmi, 1998</xref>; Williams, Sagness, &amp; <xref ref-type="bibr" rid="R45" id="147" class="deo:Reference">McPhee, 1994</xref>).</region>
        <outsider class="DoCO:TextBox" type="header" id="140" page="7" column="1">MULTIDIMENSIONAL VISUAL STATISTICAL LEARNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="141" page="7" column="1">405</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="149" page="7" column="1">Could VSL Define Objects in the First Place?</h1>
        <region class="DoCO:TextChunk" id="167" page="7" column="1">The two final experiments (Experiments 4a and 4b) complicated our initial “object-based” conclusion in a particularly interesting way, suggesting that VSL may be object-based only when feature binding is useful—that is, when the values across different dimensions reliably covary. When only half of the shape triplets during familiarization had randomly assigned colors, this effectively disrupted the feature binding seen in the previous experiments (despite the fact that other triplets had perfectly covarying shapes and colors), yielding feature-based VSL—that is, a robust expression of learning when each feature dimension was presented in isolation at test. We could, however, instead characterize VSL as always object-based but interpret our results as indicating that multiple feature values are only combined into single object representations when their covariance is high. Intuitively, we recognize that some properties are intrinsic to an object, while others are not. We typically think of color as intrinsic: For example, bananas are usually yellow. We do not typically think of luminance as intrinsic to an object, however: A banana may be brighter in the sun and darker in the shade. Why do we treat these two properties differently? On reflection, it seems that the critical difference between these cases is not some special essence of the properties themselves but rather the fact that they are differentially variable with respect to their occurrence in the presence of an object: For example, bananas typically appear in many different lighting situations, but they are usually yellow. We suggest that covariance between surface features in the visual environment serves as an important cue about which object properties are diagnostic (and nondiagnostic). (This point has been made before in the memory literature; see <xref ref-type="bibr" rid="R4" id="150" class="deo:Reference">Chalfonte &amp; Johnson, 1996</xref>.)<marker type="column" number="2"/><marker type="block"/> This view can readily accommodate our results. When color and shape are highly correlated (i.e., when all bananas are yellow), then the colors become inextricably bound into the representations that result from VSL, such that removing the colors later on disrupts the expression of VSL (as in Experiment 2a). This dis- ruption may be analogous to ways in which we are slower to recognize purple “bananas” or achromatic fire engines (Naor-Raz, Tarr, &amp; <xref ref-type="bibr" rid="R23" id="152" class="deo:Reference">Kersten, 2003</xref>; <xref ref-type="bibr" rid="R38" id="153" class="deo:Reference">Tanaka &amp; Presnell, 1999</xref>). This object- based model could also be applied to the results of Experiments 4a and 4b, where the lack of correlations between features during familiarization may have resulted in separate “object” representations for shapes and colors. In this framework, VSL is always object-based and operates over the largest available set of highly correlated features. This interpretation can be contrasted with the notion discussed in the previous section that VSL becomes feature- based under conditions of reduced feature correlations. Irrespec- tive of the interpretation, however, the sensitivity to correlations between features within objects demonstrated in our experiments may constitute another type of VSL. Interestingly, the monochromatic shape sequences in Experiment 4a were recognized equally well no matter whether they had been familiarized with perfectly correlated colors or with random colors. Moreover, the only difference between the perfectly correlated shape– color pairs in Experiments 4a and 4b (from matched-color triplets) versus Experiment 2 is that they occurred in the context of other shapes paired with random colors. This demonstrates that observers were sensitive to the correlations between feature dimensions (or possibly the average correlation over all shapes), rather than maintaining separate statistical representations of correlations for individual objects. This effect may be atypical in the broader context of real-world objects, though, where color diagnosticity differs from object to object (e.g., con- sider a fire engine vs. a lamp; <xref ref-type="bibr" rid="R38" id="154" class="deo:Reference">Tanaka &amp; Presnell, 1999</xref>) and may be moderated by the degree to which feature dimensions are processed in a separable or integral manner (e.g., <xref ref-type="bibr" rid="R25" id="155" class="deo:Reference">Nosofsky &amp; Palmeri, 1996</xref>; see also <xref ref-type="bibr" rid="R13" id="156" class="deo:Reference">Garner, 1974</xref>). Also, children seem to be reluctant at some ages to categorize objects by color (despite intact color perception), but they will do so robustly for some items that have reliable colors, such as foods (<xref ref-type="bibr" rid="R20" id="157" class="deo:Reference">Macario, 1991</xref>). Sensitivity to feature correlations may in fact hold more generally, explaining why other types of statistical regularities are or are not learned. A study of spatial VSL, for example, demonstrated that small spatial groups of larger spatial arrays were learned only when the smaller groups could vary in their spatial relationships to each other (<xref ref-type="bibr" rid="R11" id="158" class="deo:Reference">Fiser &amp; Aslin, 2005</xref>). When the small “parts” were always arranged into the same global patterns, in contrast, observers were not later sensitive to the intra-part statistical structures when they were tested by themselves. In other words, testing the local parts later in isolation (from the other local parts with which they had been previously associated) was equivalent to testing the shapes in our experiments in isolation from the colors with which they had been previously associated. Thus, statistical structure may serve to define objects in terms of both spatial scale (as argued by <xref ref-type="bibr" rid="R11" id="159" class="deo:Reference">Fiser &amp; Aslin, 2005</xref>) and surface features (as sug- gested here). <xref ref-type="bibr" rid="R11" id="160" class="deo:Reference">Fiser and Aslin (2005)</xref> argued that their results reflect a constraint on “embeddedness” in hierarchical structures, which essentially serve to bind objects into global scenes. Our results, in a complementary fashion, indicate that statistical<marker type="page" number="8"/><marker type="column" number="1"/><marker type="block"/> covariance can also serve to determine which surface features are bound into objects themselves. 5 In fact, the idea that associative variability may serve to define the underlying units of processing has a long history, going back to William James: “What is associated now with one thing and now with another, tends to become dissociated from either, and grow into an object of abstract contemplation by the mind” (<xref ref-type="bibr" rid="R16" id="164" class="deo:Reference">James, 1890</xref>, p. 506). This concept has also been important in the long- term memory literature. According to the encoding variability hypothesis (<xref ref-type="bibr" rid="R21" id="165" class="deo:Reference">Martin, 1968</xref>), for example, the more often a stimulus is encountered within a particular context, the more deeply en- trenched task-relevant attributes of the stimulus become. Relative to an item that has been encountered an equal number of times in multiple contexts, memory for the fixed-context item will be impaired in a novel context (both because it is associated with fewer retrieval cues and because the associations to these retrieval cues are stronger). In Experiment 2, triplets of black (novel color context) shapes may have been unrecognizable because of the fixed color context in which they were encountered during familiarization. Conversely, in Experiment 4a where some shapes were encountered in multiple color contexts, recognition of black shape triplets was spared. Where this account differs from the sensitivity to covariance demonstrated here is in terms of automaticity: Con- ventional demonstrations of encoding variability have defined context as the task in which subjects were engaged (e.g., categorization vs. recognition; Wagner, Maril, &amp; <xref ref-type="bibr" rid="R43" id="166" class="deo:Reference">Schacter, 2000</xref>), while context in the current study was based on surface features themselves.</region>
        <outsider class="DoCO:TextBox" type="header" id="162" page="8" column="1">TURK-BROWNE, ISOLA, SCHOLL, AND TREAT</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="163" page="8" column="1">406</outsider>
      </section>
      <section class="deo:Conclusion">
        <h1 class="DoCO:SectionTitle" id="168" page="8" column="1">Conclusions</h1>
        <region class="DoCO:TextChunk" id="169" page="8" column="1">We began this project in an attempt to determine the impact of features vs. objects on VSL, and in the process we discovered that in some cases VSL can be object-based. In the end, however, our results and their connections to other studies suggest that statistical learning may also serve to construct objects out of some features but not others. In this sense, statistical learning may reflect not a unitary process but rather a hierarchy of interacting processes, some of which help to determine the input to others. Thus, whereas VSL has often been studied in an isolated way, it may actually be an integral component of many other more familiar types of visual processing.</region>
        <region class="DoCO:TextChunk" id="172" confidence="possible" page="8" column="1">5 In both the present experiments and the studies of <xref ref-type="bibr" rid="R11" id="170" class="deo:Reference">Fiser and Aslin (2005)</xref>, smaller features (shapes or parts) may be learned despite the presence of other statistical structure (in colors or more global hierarchies) when there is high variability. However, we have previously shown that statistical regularities in shape sequences are learned when there is espe- cially low color variability (such that many different shapes can appear in the same color; Turk-<xref ref-type="bibr" rid="R17" id="171" class="deo:Reference">Browne et al., 2005</xref>). Onnis and Christiansen and their colleagues demonstrated a similar effect in a very different context: Nonadjacent dependencies between syllables can be learned when the intervening syllable(s) have extremely high or low variance, but not mid- dling variance (Onnis, Christiansen, Chater, &amp; G  ́mez, 2003; Onnis, Monaghan, Christiansen, &amp; Chater, 2004).</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="173" confidence="possible" page="8" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="175" page="8" column="1">Alvarez, G. A., &amp; Cavanagh, P. (2004). The capacity of visual short-term memory is set both by visual information load and by number of objects. Psychological Science, 15, 106 –111. <marker type="column" number="2"/><marker type="block"/> Alvarez, G. A., &amp; Scholl, B. J. (2005). How does attention select and track spatially extended objects? New effects of attentional concentration and amplification. Journal of Experimental Psychology: General, 134, 461– 476.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="176" confidence="possible" page="8" column="2">Baker, C. I., Olson, C. R., &amp; Behrmann, M. (2004). Role of attention and perceptual grouping in visual statistical learning. Psychological Science, 15, 460 – 466.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="177" confidence="possible" page="8" column="2">Chalfonte, B. L., &amp; Johnson, M. K. (1996). Feature memory and binding in young and older adults. Memory &amp; Cognition, 24, 403– 416.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="178" confidence="possible" page="8" column="2">Chun, M. M., &amp; Jiang, Y. (1998). Contextual cueing: Implicit learning and memory of visual context guides spatial attention. Cognitive Psychology, 36, 28 –71.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="179" confidence="possible" page="8" column="2">Comtois, R. (2004). VisionShell PPC [Software libraries]. Cambridge, MA: Author.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="180" confidence="possible" page="8" column="2">Conway, C. M., &amp; Christiansen, M. H. (2005). Modality-constrained statistical learning of tactile, visual, and auditory sequences. Journal of Experimental Psychology: Learning, Memory, and Cognition, 31, 24 – 39.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="181" confidence="possible" page="8" column="2">Fiser, J., &amp; Aslin, R. N. (2001). Unsupervised statistical learning of higher-order spatial structures from visual scenes. Psychological Science, 12, 499 –504.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="182" confidence="possible" page="8" column="2">Fiser, J., &amp; Aslin, R. N. (2002a). Statistical learning of higher-order temporal structure from visual shape sequences. Journal of Experimental Psychology: Learning, Memory, and Cognition, 28, 458 – 467.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="183" confidence="possible" page="8" column="2">Fiser, J., &amp; Aslin, R. N. (2002b). Statistical learning of new visual feature combinations by infants. Proceedings of the National Academy of Sciences of the United States of America, 99, 15822–15826.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="184" confidence="possible" page="8" column="2">Fiser, J., &amp; Aslin, R. N. (2005). Encoding multielement scenes: Statistical learning of visual feature hierarchies. Journal of Experimental Psychology: General, 134, 521–537.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="185" confidence="possible" page="8" column="2">Fiser, J., Scholl, B. J., &amp; Aslin, R. N. (2007). Perceived object trajectories during occlusion constrain visual statistical learning. Psychonomic Bulletin &amp; Review, 14, 173–178.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="186" confidence="possible" page="8" column="2">Garner, W. R. (1974). The processing of information and structure. Hillsdale, NJ: Erlbaum.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="187" confidence="possible" page="8" column="2">Harris, Z. (1955). From phoneme to morpheme. Language: Journal of the Linguistic Society of America, 31, 190 –222.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="188" confidence="possible" page="8" column="2">Hunt, R. H., &amp; Aslin, R. N. (2001). Statistical learning in a serial reaction time task: Access to separable statistical cues by individual learners. Journal of Experimental Psychology: General, 130, 658 – 680.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="189" confidence="possible" page="8" column="2">James, W. (1890). The principles of psychology. London: Macmillan.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="190" confidence="possible" page="8" column="2">Jung  ́, J., Turk-Browne, N. B., &amp; Scholl, B. J. (2005). Visual statistical learning through intervening noise [Abstract]. Journal of Vision, 5, 421a.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="191" confidence="possible" page="8" column="2">Kirkham, N. Z., Slemmer, J. A., &amp; Johnson, S. P. (2002). Visual statistical learning in infancy: Evidence for a domain general learning mechanism. Cognition, 83, B35–B42.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="192" confidence="possible" page="8" column="2">Luck, S. J., &amp; Vogel, E. K. (1997, November 20). The capacity of visual working memory for features and conjunctions. Nature, 390, 279 –281.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="193" confidence="possible" page="8" column="2">Macario, J. F. (1991). Young children’s use of color in classification: Foods and canonically colored objects. Cognitive Development, 6, 17– 46.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="194" confidence="possible" page="8" column="2">Martin, E. (1968). Stimulus meaningfulness and paired-associate transfer: An encoding variability hypothesis. Psychological Review, 75, 421– 441.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="195" confidence="possible" page="8" column="2">Moore, C. M., &amp; Lleras, A. (2005). On the role of object representations in substitution masking. Journal of Experimental Psychology: Human Perception and Performance, 31, 1171–1180.</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="196" confidence="possible" page="8" column="2">Naor-Raz, G., Tarr, M. J., &amp; Kersten, D. (2003). Is color an intrinsic property of object representation? Perception, 32, 667– 680.</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="197" confidence="possible" page="8" column="2">Nissen, M. J., &amp; Bullemer, P. (1987). Attentional requirements of learning: Evidence from performance measures. Cognitive Psychology, 19, 1–32.</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="198" confidence="possible" page="8" column="2">Nosofsky, R. M., &amp; Palmeri, T. J. (1996). Learning to classify integral- dimension stimuli. Psychonomic Bulletin &amp; Review, 3, 222–226.</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="199" confidence="possible" page="8" column="2">Olson, I. R., &amp; Chun, M. M. (2001). Temporal contextual cuing of visual</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="202" page="9" column="1">attention. Journal of Experimental Psychology: Learning, Memory, and Cognition, 27, 1299 –1313.</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="203" confidence="possible" page="9" column="1">Onnis, L. Christiansen, M.H., Chater, N. &amp; G  ́mez, R. (2003). Reduction of uncertainty in human sequential learning: Evidence from artificial grammar learning. In Proceedings of the 25th Annual Conference of the Cognitive Science Society (pp. 886 – 891). Mahwah, NJ: Erlbaum.</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="204" confidence="possible" page="9" column="1">Onnis, L. Monaghan, P., Christiansen, M.H., &amp; Chater, N. (2004). Vari- ability is the spice of learning, and a crucial ingredient for detecting and generalizing in nonadjacent dependencies. In Proceedings of the 26th Annual Conference of the Cognitive Science Society (pp. 1047–1052). Mahwah, NJ: Erlbaum.</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="205" confidence="possible" page="9" column="1">Pearce, J. M. (1987). A model for stimulus generalization in Pavlovian conditioning. Psychological Review, 94, 61–73.</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="206" confidence="possible" page="9" column="1">Perruchet, P., &amp; Pacton, S. (2006). Implicit learning and statistical learning: One phenomenon, two approaches. Trends in Cognitive Sciences, 10, 233–238.</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="207" confidence="possible" page="9" column="1">Reber, A. S. (1967). Implicit learning of artificial grammars. Journal of Verbal Learning and Verbal Behavior, 6, 855– 863.</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="208" confidence="possible" page="9" column="1">Roberts, P. L., &amp; MacLeod, C. (1995). Representational consequences of two modes of learning. The Quarterly Journal of Experimental Psychology, 48A, 296 –319.</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="209" confidence="possible" page="9" column="1">Saffran, J. R., Aslin, R. N., &amp; Newport, E. L. (1996, December 13). Statistical learning by 8-month-old infants. Science, 274, 1926 –1928.</ref>
          <ref rid="R35" class="deo:BibliographicReference" id="210" confidence="possible" page="9" column="1">Scholl, B. J. (2001). Objects and attention: The state of the art. Cognition, 80, 1– 46.</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="211" confidence="possible" page="9" column="1">Shanks, D. R., Charles, D., Darby, R. J., &amp; Azmi, A. (1998). Configural processes in human associative learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24, 1353–1378.</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="212" confidence="possible" page="9" column="1">Stadler, M. A., &amp; Frensch, P. A. (1998). Handbook of implicit learning. Thousand Oaks, CA: Sage.</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="213" page="9" column="2">Tanaka, J. W., &amp; Presnell, L. M. (1999). Color diagnosticity in object recognition. Perception &amp; Psychophysics, 61, 1140 –1153.</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="214" confidence="possible" page="9" column="2">Thiessen, E., &amp; Saffran, J. (2003). When cues collide: Use of stress and statistical cues to word boundaries by 7- to 9-month-old infants. Devel- opmental Psychology, 39, 706 –716.</ref>
          <ref rid="R40" class="deo:BibliographicReference" id="215" confidence="possible" page="9" column="2">Turk-Browne, N. B., Johnson, M. K., Chun, M. M., &amp; Scholl, B. J. (2007). Neural evidence of statistical learning: Efficient detection and anticipation of regularities without awareness. Manuscript submitted for publi- cation.</ref>
          <ref rid="R41" class="deo:BibliographicReference" id="216" confidence="possible" page="9" column="2">Turk-Browne, N. B., Jung  ́, J., &amp; Scholl, B. J. (2005). The automaticity of visual statistical learning. Journal of Experimental Psychology: General, 134, 552–564.</ref>
          <ref rid="R42" class="deo:BibliographicReference" id="217" confidence="possible" page="9" column="2">Turk-Browne, N. B., &amp; Scholl, B. J. (2006). The space–time continuum: Spatial visual statistical learning produces temporal processing advan- tages [Abstract]. Journal of Vision, 6, 676a.</ref>
          <ref rid="R43" class="deo:BibliographicReference" id="218" confidence="possible" page="9" column="2">Wagner, A. D., Maril, A., &amp; Schacter, D. L. (2000). Interactions between forms of memory: When priming hinders new episodic learning. Journal of Cognitive Neuroscience, 12, 52– 60.</ref>
          <ref rid="R44" class="deo:BibliographicReference" id="219" confidence="possible" page="9" column="2">Williams, D. A., &amp; Braker, D. S. (1999). Influence of past experience on the coding of compound stimuli. Journal of Experimental Psychology: Animal Behavior Processes, 25, 461– 474.</ref>
          <ref rid="R45" class="deo:BibliographicReference" id="220" confidence="possible" page="9" column="2">Williams, D. A., Sagness, K. E., &amp; McPhee, J. E. (1994). Configural and elemental strategies in predictive learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 694 –709.</ref>
          <ref rid="R46" class="deo:BibliographicReference" id="221" confidence="possible" page="9" column="2">Xu, Y., &amp; Chun, M. M. (2006, March 2). Dissociable neural mechanisms supporting visual short-term memory for objects. Nature, 440, 91–95. Received April 18, 2006 Revision received November 5, 2007 Accepted November 7, 2007</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="header" id="200" page="9" column="1">MULTIDIMENSIONAL VISUAL STATISTICAL LEARNING</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="201" page="9" column="1">407</outsider>
      </section>
    </body>
  </article>
</pdfx>
