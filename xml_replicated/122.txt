 As people go about their daily lives, they seem to effortlessly manage the extremely rich and detailed stream of information entering their eyes. For the most part, people successfully navigate through busy intersections; find items of interest, such as food or friends; and understand complex social situations— all just by the simple act of looking. However, despite these many successes, there are also countless demonstrations that people fail to notice potentially important visual events, particularly when their attention is focused elsewhere. For example, traffic accidents often involve drivers ‘‘not seeing’’ clearly visible obstacles (e.g., McLay, Anderson, Sidaway, & Wilder, 1997). Such occurrences are typically interpreted as attentional Address correspondence to George Alvarez, Department of Brain and Cognitive Sciences, 46-4078, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, MA 02139, e-mail: alvarez@ mit.edu. lapses: It seems that people have a severely limited ability to perceive, understand, and act upon information that falls outside the current focus of attention. Even when attention is focused intensely on a particular object, however, people do not experience ‘‘blindness’’ for all other visual information. The purpose of the current study was to probe what type of representation can be maintained outside the focus of attention. In so doing, we emphasized the distinction between local visual features and statistical summary features. Local visual features are properties that describe an individual item, independently of other items. For example, the size and the location of an individual object are local visual features. In contrast, there are a variety of statistical summary features that represent information at a more abstract level, collapsing across local details ( Ariely, 2001; Chong & Treisman, 2003, 2005b). For the present study, we focused on relatively simple summary features, such as the center of mass of a collection of objects (henceforth, the ‘‘centroid’’), which is essentially the mean position of the group. Specifically, we tested the hypothesis that withdrawing attention impairs perception of local features more than it impairs the perception of summary features. Object location was used as a test case for investigating whether summary features can be represented more robustly than local visual features outside the focus of attention. We used a multiple-object-tracking task (Pylyshyn & Storm, 1988) in which eight objects moved around the display. The primary task was to attentively track a subset of four target objects while ignoring four distractor objects. This attentionally demanding tracking task drew focal attention toward the targets and away from the distractors (Intriligator & Cavanagh, 2001; Sears & Pylyshyn, 2000). At a random time during each trial, all items disappeared briefly (200 ms), and then all but one or four randomly chosen targets or distractors reappeared. Participants had to localize either the single missing item (individual test) or the centroid of the missing group of items (centroid test). Because distractors receive less attention than targets, we predicted that localizing missing distractors would be more difficult than localizing missing targets. However, of principal interest was whether the distractor centroid would be represented more robustly than the individual distractor positions, indicating a relative sparing of summary features outside the attentional focus. Across three experiments, we varied the extent to which subjects could selectively attend to targets. In Experiment 1, targets and distractors were physically identical and moved among each other, making selective target processing most difficult. In Experiment 2, targets were white and distractors were black, and this separation of targets from distractors in feature space facilitated target selection. In Experiment 3, targets and distractors were again identical, but target selection was facilitated by spatially separating targets from distractors, such that the focus of attention was far removed from the distractors. We found that selective processing of the targets improved in Experiments 2 and 3 relative to Experiment 1, to the extent that in Experiments 2 and 3, participants performed at chance level when asked to localize a single missing distractor. In contrast, we found in all experiments that participants could accurately localize the distractor centroid, even when individual distractors were localized at chance levels. This finding suggests that the cost of withdrawing attention from distractors can be compen- sated for by pooling together noisy local signals and computing summary statistics. Each experiment had a separate group of 8 participants who were between the ages of 18 and 35, gave informed consent, and were paid $10/hr for their participation. The experiments were run using the Psychophysics Toolbox (Brainard, 1997; Pelli, 1997). The display was 351 Â 281, viewed from 57 cm. The stimuli were eight circles (radius 5 0.351) that moved at a constant rate of 41/s within a central region of the screen, marked by a black, square outline (24.51 Â 24.51, line thickness 5 0.11; see Fig. 1). Two diagonal red lines connected the corners of the square (line thickness 5 0.11), and the background was gray. The circles’ direction of motion was constrained such that items appeared to avoid one another, while otherwise moving randomly about the display. Test Phase Participants performed a multiple-object-tracking task followed by a missing-item localization task (see Fig. 1). At the start of each trial, eight circles appeared, and four of these items were identified as tracking targets by flashing off and on for 2 s. Next, all items moved for a random duration between 6 and 10 s. The primary task was to attentively track the targets, counting the number of times a target item touched or crossed one of the red lines. Participants kept one running count collapsed across all targets. This task was attentionally demanding and ensured that participants were continuously focusing their attention on the target items. At the end of each trial, all the circles disappeared for 200 ms, and then some reappeared. In the individual-test condition, either a single target or a single distractor was missing from the final display. In the centroid-test condition, either all four targets or all four distractors were missing. A cue that appeared at the center of the screen informed participants of how many items were missing (‘‘1’’ for individual tests, ‘‘4’’ for centroid tests). Participants used the mouse to move a crosshair and clicked either on the location of the single missing item or on the location corresponding to the centroid of the four missing items. After clicking on the selected position, participants typed in the number of times targets had touched the red lines during the trial. Although participants entered this number second, they were instructed that the counting task was their primary task, and that they should not sacrifice accuracy on the counting task to perform the localization task. There were 80 trials, with conditions randomly intermixed. Guessing Phase After the test phase, participants completed a guessing phase, in which they were not required to track any targets. They were simply shown test displays with either one or four items missing, and were asked to guess where they thought the missing item or items were located. These displays were generated in the same way as in the test phase, but participants were shown only the final frame. The data from this phase provided an estimate of how well participants could guess where the missing items were located on the basis of the configuration of the items present in the test display, providing an empirical estimate of chance performance. Experiment 1 tested how well participants could judge the location of individual items or the centroid of a group outside the focus of attention. We hypothesized that the tracking task would draw attention away from distractors, resulting in better localization accuracy for targets than distractors, but that ability to localize distractors would be better on centroid tests than on individual tests. In Experiment 1, the targets and distractors were all black, so that target selection was difficult. Overall participants accurately performed the primary counting task, typically missing one or two touches. Counting errors did not vary systematically with the type of localization test (individual vs. centroid), F(1, 7) 5 2.06, p 5 .194, Z p 2 1⁄4 :23, or with the type of item that was missing (target vs. distractor), F < 1. Error in the guessing phase, which provides an empirical estimate of chance performance, averaged 10.01 (SEM 5 0.51) for individual tests and 5.41 (SEM 5 0.11) for centroid tests (see the dashed lines in Fig. 2). Localization accuracy revealed an important difference between individual tests and centroid tests. As Figure 2a illustrates, error in reporting the location of a single missing item was significantly lower for targets than for distractors, t(7) 5 3.69, p 5 .008, r 2 5 .66, and performance was better than chance for both targets, t(7) 5 4.04, p 5 .005, r 2 5 .70, and distractors, t(7) 5 3.20, p 5 .015, r 2 5 .59. Although performance was better for targets than for distractors, which suggests that attention was more focused on the targets, the ability to identify distractor locations better than chance suggests that target selection was imperfect, and that some attention may have been paid to distractors. However, the amount of attention was not enough to localize individual distractors as accurately as individual targets. In contrast, there was no significant difference in localization error for targets and distractors in the centroid-test condition, t(7) 5 1.07, p 5 .321, r 2 5 .14 (see Fig. 2b). Thus, despite noisy individual representations of distractor locations—as evidenced by error on the individual tests—participants could determine the location of the distractor centroid as well as the location of the target centroid. Performance was again better than chance for both targets, t(7) 5 4.08, p 5 .005, r 2 5 .70, and distractors, t(7) 5 5.48, p 5 .001, r 2 5 .81. Could this remarkable level of accuracy in localizing distractor centroids be achieved by sampling just one or two distractors and making an informed guess about where the centroid would be located? To assess this possibility, we ran Monte Carlo simulations to determine how well participants could judge the location of the distractor centroid by pooling one, two, three, or four noisy individual samples. We assumed that estimates of individual item positions are noisy and estimated the amount of noise from performance on the individual tests. The distribution of errors was approximately normal, and so the model assumed that each individual item position was represented with independent, normally distributed noise with a standard deviation estimated separately for each observer. For example, if each distractor’s position could be estimated within 41 Æ 1.51 on average for a given observer, we could simulate how accurately the centroid of all four distractors could be determined if one, two, three, or four estimates were averaged. The results of this simulation suggested that, given how noisy the individual estimates appeared to be, participants would have had to pool signals from all the distractors to achieve the level of accuracy we observed. Guessing any four random positions on the screen and pooling those estimates would not yield this level of performance; only if these very noisy individual estimates were centered on the actual distractor positions would pooling them enable participants to localize the centroids as accurately as they did. 1 It appears that observers can make accurate judgments about distractors as a group by pooling information from all the individual distractors, even when the individual details of the distractors are not represented accurately. This suggests that observers maintain some awareness of the summary features of items appearing outside the focus of attention, even when local 1 A supplementary appendix providing the details of all simulations reported in this article can be obtained directly from the first author or downloaded on- line at http://cvcl.mit.edu/george/Publications.htm. information is represented inaccurately. However, because the targets and distractors were physically identical in Experiment 1, it is possible that participants could not completely filter out the distractor items, or that distractors were occasionally con- fused for targets, and therefore that distractors received enough attention to improve localization of the distractor centroid. In- deed, participants could localize distractors at better than chance levels, which suggests that some attention ‘‘spilled over’’ to the distractors. Experiments 2 and 3 tested how improving selective processing of targets affects the localization of individuals and their centroid. Previous work has demonstrated that what people see depends on how they tune their attention—their attentional set—such that irrelevant information is more likely to be noticed or pro- cessed if it matches the physical properties of attended items (Most, Scholl, Clifford, & Simons, 2005; Most et al., 2001). However, there appears to be little to no perception of information that falls outside the attentional set. For instance, the appearance of an irrelevant black item will go undetected when participants attend to white items, especially if the distractors are black (Most et al., 2001). In Experiment 2, we increased the degree to which targets could be selectively attended by making the targets white and the distractors black. Continuous tracking of the targets was still required, because the primary task was to count the number of times a target touched a red line in the display. Of principal interest was whether participants would still be capable of accurately judging the location of the distractor centroid, even when the distractors fall outside the attentional set. All aspects of the stimuli and procedure were the same as in Experiment 1, except that the targets were white instead of black. Counting errors did not vary with the type of localization test (individual vs. centroid), F < 1, or with the type of item that was missing (target vs. distractor), F < 1. Error in the guessing phase averaged 9.41 (SEM 5 0.11) for individual tests and 5.31 (SEM 5 0.11) for centroid tests (see the dashed lines in Fig. 3). As in Experiment 1, localization accuracy showed different patterns in the individual-test and centroid-test conditions. As Figure 3a illustrates, error in reporting the location of a single missing item was significantly lower for targets than for distractors, t(7) 5 4.44, p 5 .003, r 2 5 .74. Error was below the empirical chance estimate for targets, t(7) 5 5.18, p 5 .001, r 2 5 .79, but, as expected, was not better than chance for distractors, t(7) 5 1.00, p 5 .350, r 2 5 .13. This indicates that the salient feature difference was effective in enhancing selective target processing. As Figure 3b illustrates, in the centroid condition, there was a significant difference in localization error for targets and distractors, t(7) 5 3.37, p 5 .012, r 2 5 .62, but most important, performance was better than chance for both targets, t(7) 5 8.32, p < .001, r 2 5 .91, and distractors, t(7) 5 7.47, p < .001, r 2 5 .89. Thus, even though the individual position of any single distractor was so poorly represented that performance was at chance for individual judgments, participants could determine the location of the distractor centroid well above chance level. Simulation results again suggested that participants would have had to pool signals from all the distractors to achieve the level of accuracy we observed. Thus, it appears that an accurate representation of the distractor centroid can be attained by pooling noisy local signals, even when target selection is facilitated by a salient feature difference between targets and distractors. Previous work suggests that attention is focally allocated to targets in a multiple-object-tracking task and does not spread over the space between targets (Intriligator & Cavanagh, 2001; Sears & Pylyshyn, 2000), as if there were multiple, independent foci of attention (Cavanagh & Alvarez, 2005). Nevertheless, the targets in Experiments 1 and 2 were often distributed across the display such that the ‘‘virtual polygon,’’ or convex hull, formed by the targets encompassed several of the distractors. It is possible that distractors frequently received diffuse attention in these displays, and that this attention was insufficient for the local computations necessary to accurately judge the individual distractor locations, but sufficient for accurate judgments about the centroid of the distractors (Chong & Treisman, 2005a). In Experiment 3, we investigated this possibility. In Experiment 3, we attempted to withdraw participants’ attention from the region of space containing distractors by con-  straining the targets and distractors to move in opposite halves of the display. Targets were randomly constrained to move within the top, bottom, left, or right half of the screen, and distractors were constrained to move within the opposite half of the screen. As in the previous experiments, continuous tracking of the targets was required, because the primary task was to count the number of times targets touched a red line in the display. However, the spatial separation between the targets and distractors ensured that distractors never fell within the convex hull formed by the targets. Of principal interest was whether this manipulation would eliminate participants’ ability to make accurate judgments about the distractor centroid. All aspects of the stimuli and procedure were the same as in Experiment 1, except that targets remained spatially separate from the distractors for the entirety of each trial. Counting errors did not vary systematically with the type of localization test (individual vs. centroid), F(1, 7) 5 2.53, p 5 .156, Z p 2 1⁄4 :27, or with the type of item that was missing (target vs. distractor), F < 1. Error in the guessing phase was on average 7.91 (SEM 5 0.51) for individual tests and 4.51 (SEM 5 0.31) for centroid tests (see the dashed lines in Fig. 4). As Figure 4a illustrates, error in reporting the location of a single missing item was significantly lower for targets than for distractors, t(7) 5 3.28, p 5 .013, r 2 5 .61. Error was below the empirical chance estimate for targets, t(7) 5 4.26, p 5 .004, r 2 5 .72, but not for distractors, t < 1. As Figure 4b illustrates, localization error in the centroid condition was significantly lower for targets than for distractors, t(7) 5 3.17, p 5 .016, r 2 5 .59, but centroid localization was better than chance for both targets, t(7) 5 8.32, p < .001, r 2 5 .88, and distractors, t(7) 5 2.76, p 5 .028, r 2 5 .52. Thus, as in Experiment 2, the individual position of any single distractor was so poorly represented that performance was at chance for individual judgments, yet participants could localize the distractor centroid well above chance level. Spatially separating the targets from the distractors ensured that distractors never fell within the convex hull formed by the targets, and therefore prevented distractors from receiving continuous diffuse attention. Nevertheless, the results again showed that participants could accurately judge the location of the centroid of distractors with high accuracy, with performance again well better than chance. Simulations suggested that this level of accuracy could have been attained only if (a) noisy individual estimates from all the distractors were pooled together, and (b) the noisy individual estimates were centered around the actual positions of the distractors, and were not truly random guesses. Thus, the distractor centroid can be represented accurately even when targets and distractors are spatially separated, such that target selection is facilitated and distractors are kept far from the focus of attention. Visual information can be represented at multiple levels of abstraction, from local details to abstract features that summa- rize the local details. We used object location as a test case to explore the representation of local versus summary visual features outside the focus of attention. The location of an individual object is a local detail, whereas the centroid of a collection of objects is a simple summary feature that represents the objects as a group. In an adapted multiple-object-tracking task, participants were required to attentively track a set of moving targets while ignoring a set of moving distractors. During the tracking task, all of the items disappeared briefly (200 ms), and then all but one or four randomly chosen items reappeared; the second- ary task was to localize the missing items. The results suggested that although participants knew very little about the local details of individual distractors, they could accurately report the centroid of the distractors. These findings are related to previous findings concerning inattentional blindness and change blindness. Inattentional- blindness studies have shown that without attention, there is little or no consciously accessible representation of a scene ( Mack & Rock, 1998; Neisser & Becklen, 1975). These studies typically aim for participants to completely withdraw attention from the tested items, and sometimes even actively inhibit information outside of the attentional set (Most et al., 2001). In contrast, observers in our task were attempting to monitor all information, but the primary task required them to focus attention on a particular subset of that information. Thus, we assume that our observers were aware of, and paying some attention to, all information in the display. For this reason, our study is more related to change-blindness studies, in which displays consist of two alternating scenes that differ in one aspect (e.g., a single item changes color). In such studies, ob- servers often fail to notice substantial differences between the scenes, and this finding has been interpreted as reflecting a failure to represent information outside the focus of attention (Rensink, O’Regan, & Clark, 1997). However, these studies have typically manipulated local features, such as the color or orientation of an individual object. Less is known about how well summary visual features are represented outside the focus of attention in the change-detection paradigm. The current results suggest that changes to local feature information outside the focus of attention are unlikely to be noticed, unless the changes alter the summary statistics of the scene. Previous work suggests that processing of summary statistics is improved when observers spread their attention diffusely (Chong & Treisman, 2005a), and Treisman (2006) has argued that summary statistics are computed automatically when attention is spread diffusely. The current results suggest that even when attention is focally allocated to a subset of items, summary features can be computed outside the focus of attention. Most important, the representation of these summary features is more robust to the withdrawal of attention than is the representation of local visual features. Surprisingly, our experiments show that even when local features are so poorly represented that they are identified at chance levels, it is possible to pool estimates of those local details and attain an accurate representation of the group outside the focus of attention. However, whether the centroid position of distractors is computed only when required by the task demands, or whether it is computed automatically, remains an open question to be addressed by future research. Although object location was particularly well suited for an initial investigation into the representation of summary features outside the focus of attention, it is important to recognize that there are many other types of summary features. In general, other researchers have referred to these features as global features (Navon, 1977; Oliva & Torralba, 2001), holistic features (Kimchi, 1992), or sets (Ariely, 2001; Chong & Treisman, 2003, 2005b). We refer to these types of features under the umbrella term ensemble visual features. We use the term ensemble because other terms carry certain connotations that do not accurately represent our view of what counts as a summary statistic. Specifically, the terms global and holistic are often used inter- changeably with low spatial frequency, and the term set is often used to refer to collections of discrete objects. But ensemble refers to any summary statistic that collapses across individual image details, whether or not those details are contained within a specific spatial-frequency band, and whether those details are attached to discrete objects, parts, or a location in space. More- over, an ensemble can include relatively simple features, such as the mean size or the centroid of a collection of objects, or more complex features, such as particular combinations of local orientation and spatial-frequency information (Parkes, Lund, Angelucci, Solomon, & Morgan, 2001; Torralba, Oliva, Castelhano, & Henderson, 2006). This study shows that information outside the focus of attention remains consciously accessible in the form of an ensemble representation that lacks local detail, but nevertheless carries a precise statistical summary of the visual scene. Future work will be necessary to determine which classes of ensemble features are represented robustly outside the focus of attention. Of particular interest are ensemble features that capture the statistics of the natural world and are likely to play a vital role in everyday perception.  Acknowledgments—For helpful conversation and comments on earlier drafts, we thank Tim Brady, Talia Konkle, Ruth Rosen- holtz, Antonio Torralba, and two anonymous reviewers. G.A.A. was supported by the National Institutes of Health, National Eye Institute (Fellowship F32EY016982). A.O. was supported by the National Science Foundation (CAREER Award 0546262).
