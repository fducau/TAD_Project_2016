<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>2c654bebf264f2caf699a21f92bc97bb019525a452d39a2f48b9b594dbd730ef</job>
    <base_name>1m</base_name>
    <doi>10.1016/j.cognition.2009.09.010</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="1">ARTICLE IN PRESS</outsider>
      <outsider class="DoCO:TextBox" type="header" id="2">Cognition xxx (2009) xxx–xxx</outsider>
      <region class="unknown" id="3">Contents lists available at ScienceDirect Cognition</region>
      <region class="DoCO:FigureBox" id="Fx4">
        <image class="DoCO:Figure" src="1m.page_001.image_01.png" thmb="1m.page_001.image_01-thumb.png"/>
      </region>
      <region class="unknown" id="5">journal homepage: www.elsevier.com/locate/COGNIT</region>
      <region class="unknown" id="6">Brief article</region>
      <title-group>
        <article-title class="DoCO:Title" id="7">A motion aftereffect from visual imagery of motion</article-title>
      </title-group>
      <region class="unknown" id="8">Jonathan Winawer a, * , Alexander C. Huk b , Lera Boroditsky a a Department of Psychology, Stanford University, 450 Serra Mall, Stanford, CA 94305, United States b Neurobiology and Center for Perceptual Systems, The University of Texas at Austin, Austin TX 78712, United States a r t i c l e i n f o a b s t r a c t</region>
      <region class="unknown" id="9">Article history: Received 30 March 2008 Revised 23 August 2009 Accepted 20 September 2009 Available online xxxx Keywords: Imagery Perception Motion</region>
      <abstract class="DoCO:Abstract" id="10" confidence="possible">Mental imagery is thought to share properties with perception. To what extent does the process of imagining a scene share neural circuits and computational mechanisms with actually perceiving the same scene? Here, we investigated whether mental imagery of motion in a particular direction recruits neural circuits tuned to the same direction of perceptual motion. To address this question we made use of a visual illusion, the motion aftereffect. We found that following prolonged imagery of motion in one direction, people are more likely to perceive real motion test probes as moving in the direction opposite to the direction of motion imagery. The transfer of adaptation from imagined to perceived motion provides evidence that motion imagery and motion perception recruit shared direction- selective neural circuitry. Even in the absence of any visual stimuli, people can selectively recruit specific low-level sensory neurons through mental imagery. Ó 2009 Elsevier B.V. All rights reserved.</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="deo:Introduction">
        <h1 class="DoCO:SectionTitle" id="11" page="1" column="1">1. Introduction</h1>
      </section>
      <region class="DoCO:TextChunk" id="22" page="1" column="1">The mechanisms underlying mental imagery have been investigated for over a century. One important question has been whether imagery uses the same mechanisms nor- mally employed for perception (<xref ref-type="bibr" rid="R15" id="12" class="deo:Reference">Ishai &amp; Sagi, 1995</xref>; Kosslyn, Thompson, &amp; <xref ref-type="bibr" rid="R19" id="13" class="deo:Reference">Alpert, 1997</xref>; <xref ref-type="bibr" rid="R26" id="14" class="deo:Reference">Perky, 1910</xref>; <xref ref-type="bibr" rid="R28" id="15" class="deo:Reference">Pylyshyn, 2002</xref>). A number of brain areas important for perception can also be engaged by imagery, including retinotopically mapped regions in visual cortex (<xref ref-type="bibr" rid="R18" id="16" class="deo:Reference">Kosslyn et al., 1999</xref>; Kosslyn, Thompson, Kim, &amp; <xref ref-type="bibr" rid="R20" id="17" class="deo:Reference">Alpert, 1995</xref>; Slotnick, Thompson, &amp; <xref ref-type="bibr" rid="R30" id="18" class="deo:Reference">Kosslyn, 2005</xref>) and cortical areas that respond preferen- tially to specific classes of stimuli (e.g., faces, buildings) (<xref ref-type="bibr" rid="R24" id="19" class="deo:Reference">O’Craven and Kanwisher, 2000</xref>) or visual motion (Goebel, Khorram-Sefat, Muckli, Hacker, &amp; <xref ref-type="bibr" rid="R11" id="20" class="deo:Reference">Singer, 1998</xref>; <xref ref-type="bibr" rid="R12" id="21" class="deo:Reference">Grossman &amp; Blake, 2001</xref>). However, standard neuroimaging methods have not answered whether the same subpopulations of neurons are engaged by both perception and imagery. Observations that a particular brain area is active during either viewing or imagery of a particular feature does not</region>
      <region class="DoCO:TextChunk" id="24" confidence="possible" page="1" column="1">* Corresponding author. Tel.: +1 650 704 9702. E-mail address: <email id="23">winawer@stanford.edu</email> (J. Winawer). 0010-0277/$ - see front matter Ó 2009 Elsevier B.V. All rights reserved. doi:10.1016/j.cognition.2009.09.010</region>
      <region class="DoCO:FigureBox" id="Fx25">
        <image class="DoCO:Figure" src="1m.page_001.image_02.png" thmb="1m.page_001.image_02-thumb.png"/>
      </region>
      <region class="DoCO:TextChunk" id="43" page="1" column="2">necessarily imply that the same individual neurons or fine circuits underlie these activations, nor whether the processing is selective for a particular feature; the activation may be driven by a non-selective mechanism like arousal or attention (Beauchamp, Cox, &amp; <xref ref-type="bibr" rid="R3" id="26" class="deo:Reference">DeYoe, 1997</xref>; Corbetta, Miezin, Dobmeyer, Shulman, &amp; <xref ref-type="bibr" rid="R7" id="27" class="deo:Reference">Petersen, 1991</xref>; Huk, Ress, &amp; <xref ref-type="bibr" rid="R14" id="28" class="deo:Reference">Heeger, 2001</xref>; <xref ref-type="bibr" rid="R25" id="29" class="deo:Reference">O’Craven et al., 1997</xref>; Saenz, Buracas, &amp; <xref ref-type="bibr" rid="R29" id="30" class="deo:Reference">Boynton, 2002</xref>). To infer whether imagery of motion relies on direction- selective motion circuitry that is also used for perception of physical motion, we tested for a motion aftereffect following motion imagery. The motion aftereffect is an illusion in which after prolonged viewing of motion in one direction, a stationary or ambiguous dynamic test stimulus appears to drift in the opposite direction (Mather, Verstraten, &amp; <xref ref-type="bibr" rid="R22" id="31" class="deo:Reference">Anstis, 1998</xref>; <xref ref-type="bibr" rid="R33" id="32" class="deo:Reference">Wohlgemuth, 1911</xref>). Prolonged viewing of directional motion is thought to adapt direction- selective cortical neurons, such that subpopulations tuned to the adapting direction become less responsive after adaptation. Such direction-selective adaptation leads to an imbalance in neural responses that favors the direction opposite that of adaptation (<xref ref-type="bibr" rid="R2" id="33" class="deo:Reference">Barlow &amp; Hill, 1963</xref>). The pres- ence of a motion aftereffect is therefore an indicator of the<marker type="page" number="2"/><marker type="column" number="1"/><marker type="block"/> involvement of direction-selective neural mechanisms (<xref ref-type="bibr" rid="R17" id="39" class="deo:Reference">Kohn &amp; Movshon, 2003</xref>; Petersen, Baker, &amp; <xref ref-type="bibr" rid="R27" id="40" class="deo:Reference">Allman, 1985</xref>; <xref ref-type="bibr" rid="R31" id="41" class="deo:Reference">Van Wezel &amp; Britten, 2002</xref>). We reasoned that if visual imagery of motion relies on direction-selective neurons that are also involved in the perception of physical motion, then prolonged imagery of motion in one direction should adapt direction-selective neurons and produce a motion aftereffect. In previous work we have shown that viewing frozen-motion photographs can produce a motion aftereffect (Winawer, Huk, &amp; <xref ref-type="bibr" rid="R32" id="42" class="deo:Reference">Boroditsky, 2008</xref>). Here we asked whether imagining motion in the absence of visual stimuli can adapt direction-selective neurons and produce a motion aftereffect.</region>
      <outsider class="DoCO:TextBox" type="footer" id="35" page="1" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
      <outsider class="DoCO:TextBox" type="header" id="36" page="2" column="1">ARTICLE IN PRESS</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="37" page="2" column="1">2</outsider>
      <outsider class="DoCO:TextBox" type="header" id="38" page="2" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="44" page="2" column="1">2. Methods</h1>
        <region class="DoCO:TextChunk" id="45" page="2" column="1">Five experiments were conducted. Experiments 1–3 tested for a motion aftereffect resulting from imagined motion. For comparison to the imagery experiments, Experiments 4 and 5 tested for a motion aftereffect resulting from viewing real motion. Each experiment was preceded by a baseline motion sensitivity measurement. In the experimental trials, participants either imagined or viewed motion, and were tested with moving-dot test probes. The test probes were used to assess the degree to which imagining or viewing real motion caused a motion aftereffect.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="46" page="2" column="1">2.1. Participants</h2>
          <region class="DoCO:TextChunk" id="47" page="2" column="1">Naïve volunteers from the MIT (n = 64) and Stanford (n = 68) communities received course credit or were paid for participation. In Experiment 1, 33 participants imagined upward or downward motion. In Experiment 2, 31 participants imagined inward or outward motion. In Experiment 3, 30 participants also imagined inward or outward motion, but with a delay of 1, 4, or 13 s inserted in each trial before the appearance of the test probe to assess the decay of the aftereffect. In Experiments 4 and 5, participants passively viewed moving gratings, either upward or downward (n = 31), or inward or outward (n = 7). In all experiments, participants viewed or imagined the two opposing directions of motion in separate blocks; no participants participated in more than one experiment.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="48" page="2" column="1">2.2. Moving-dot test stimuli</h2>
          <region class="DoCO:TextChunk" id="53" page="2" column="1">We assessed adaptation to motion with a standard direction discrimination task ( <xref ref-type="bibr" rid="R23" id="49" class="deo:Reference">Newsome &amp; Pare, 1988</xref>) used previously to quantify motion aftereffects from adapting to real visual motion (<xref ref-type="bibr" rid="R4" id="50" class="deo:Reference">Blake &amp; Hiris, 1993</xref>; <xref ref-type="bibr" rid="R13" id="51" class="deo:Reference">Hiris &amp; Blake, 1992</xref>). The test stimulus consisted of low-contrast dynamic random dots. The percentage of dots moving coherently in a particular direction (‘‘motion coherence”) varied from trial to trial. The direction of coherent motion was either up/down (Experiments 1 and 4), or inward/outward (Experiments 2, 3, and 5). Participants were instructed to indicate the direction of global motion by forced choice (up vs. down or inward vs. outward, depend- ing on the type of motion in the experiment). The range of motion coherence values was adjusted for each participant<marker type="column" number="2"/><marker type="block"/> according to their performance on the baseline motion discrimination task. Participants who failed to demonstrate sensitivity to motion in the baseline task were excluded from analysis (see Appendix A).</region>
        </section>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="54" page="2" column="2">3. Imagery adaptation</h1>
        <region class="DoCO:TextChunk" id="56" page="2" column="2">Experiments 1 and 2 tested for adaptation from motion imagery (<xref ref-type="fig" rid="F1" id="55" class="deo:Reference">Fig. 1</xref>). After a baseline task, participants were familiarized with the motion stimuli to imagine. The stimuli were either horizontal gratings that moved up or down (Experiment 1), or two vertical gratings that moved hori- zontally inward or outward (Experiment 2). The gratings were square wave luminance gratings with a spatial frequency of 1 cycle per degree, and a speed of 2.7° per sec- ond. To facilitate imagery, participants were presented with a timing guide: a stationary fixation square which cycled in luminance or a tone which cycled in pitch. The timing guide cycled at the same temporal frequency as the moving gratings. Participants viewed two examples of the moving gratings in each direction for 6 s each, to- gether with the fixation square and tone. Participants were told to ‘‘try to attend to the size, color, and speed of the stripes, so that later you can picture them clearly even when the screen is blank.” At the beginning of each of the 8 imagery blocks, participants were re-familiarized with the gratings by again viewing two examples of gratings in each direction in random order (6 s each). Participants were not told which direction of motion they would need to imagine until after the re-familiarization. This prevented them from being able to selectively attend to the example gratings moving in the direction of imagery for the subsequent block. Each trial consisted of a period of imagery adaptation followed by viewing a real moving-dot test stimulus. The imagery adaptation period was 60 s in the first trial of each block and 6 s in each subsequent trial. After viewing the moving-dot test stimulus participants indicated its direction with a keypress. Within each block of trials, the direction of imagery and whether the eyes were open or closed was the same. For each direction of imagery adaptation, there were two eyes-open blocks and two eyes-closed blocks, in random order.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="57" page="2" column="2">4. Decay of imagery adaptation</h1>
        <region class="DoCO:TextChunk" id="59" page="2" column="2">Experiment 3 was conducted to assess whether aftereffects from mental imagery decay over a period of a few seconds, as do aftereffects from visual motion (<xref ref-type="bibr" rid="R16" id="58" class="deo:Reference">Keck &amp; Pentz, 1977</xref>). This experiment was identical to Experiment 2 except there was a variable delay (1, 4, or 13 s) between when participants were cued to open their eyes following imagery and when the test probe appeared; there was no eyes-open condition; there were 8 dot coherence values tested instead of 12; and there were two blocks of trials instead of 8, with each block consisting of 48 instead of 24 trials (2 directions for the test probe Â 8 coherence values Â 3 delay durations).</region>
        <outsider class="DoCO:TextBox" type="footer" id="60" page="2" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
        <outsider class="DoCO:TextBox" type="header" id="61" page="3" column="1">ARTICLE IN PRESS</outsider>
        <outsider class="DoCO:TextBox" type="header" id="62" page="3" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="63" page="3" column="1">3</outsider>
        <region class="DoCO:FigureBox" id="F1">
          <image class="DoCO:Figure" src="1m.page_003.image_03.png" thmb="1m.page_003.image_03-thumb.png"/>
          <caption class="deo:Caption" id="65" page="3" column="1">Fig. 1. Experimental procedure. Prior to each imagery block participants viewed four examples of moving gratings. The direction of imagery (up vs. down or in vs. out) and whether the eyes were open or closed were the same throughout the block. Each trial within a block consisted of motion imagery followed by a test stimulus. An imagery trial began with the appearance of a static grating and a small arrow indicating the direction of motion imagery for that block. The grating and arrow then faded. On eyes-open trials, the participant then imagined motion (60 s for the first trial of a block, 6 s for each subsequent ‘‘top- up” adaptation trial) on a screen that was blank except for the fixation timing guide. During the eyes-closed blocks, participants were instructed to close their eyes each time the static grating faded and imagine motion while listening to the auditory timing guide. At the end of each imagery period, the tone stopped cycling, and was followed by a pause and a beep, cueing participants to open their eyes and attend to the moving-dot test stimulus. The test stimulus appeared 1 s after the beep cueing the end of the imagery period. For Experiment 3, the fixation period between imagined motion and test stimulus varied in duration. For control experiments with real motion, the grating did not fade; participants were instructed to passively view the moving grating while fixating the central square.</caption>
        </region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="66" page="3" column="1">5. Real motion adaptation</h1>
        <region class="DoCO:TextChunk" id="67" page="3" column="1">In Experiments 4 and 5, we tested adaptation to real visual motion. The procedure and stimuli were identical to those in Experiments 1 and 2 (up/down and in/out motion adaptation, respectively) except that rather than being instructed to imagine motion during adaptation, participants were simply instructed to fixate on the actual moving grating; examples of the moving gratings were not shown at the beginning of each block because participants did not need to imagine the grating; there were four blocks of trials instead of eight because there were no eyes-closed blocks; and there was no auditory timing guide.</region>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="68" page="3" column="1">6. Results</h1>
        <region class="DoCO:TextChunk" id="71" page="3" column="1">Imagery of motion produced motion aftereffects. Imag- ining motion upward made participants more likely to see the test dots as moving downward, compared to imagining motion downward. Likewise, imagining motion outward made participants more likely to see the test dots as moving inward. These effects were found from imagery both with eyes closed and with eyes open. Moreover, the effects of imagery adaptation weakened when a delay was intro- duced between adaptation and test, as has been found <marker type="column" number="2"/><marker type="block"/> for perceptual motion adaptation (<xref ref-type="bibr" rid="R16" id="70" class="deo:Reference">Keck &amp; Pentz, 1977</xref>). We infer that visual motion imagery involves some of the same directional-selective motion processing circuits that are used for perception of motion. Below, the motion aftereffects are quantified and compared to aftereffects from perception of real motion.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="72" page="3" column="2">6.1. Analysis</h2>
          <region class="DoCO:TextChunk" id="82" page="3" column="2"> <xref ref-type="fig" rid="F2" id="73" class="deo:Reference">Fig. 2</xref> shows the population motion sensitivity curves following opposite directions of imagery adaptation. In each plot, the vertical separation between the curves indicates how differently the same physical stimulus was judged following imagery in opposite directions. The horizontal separation indicates the amount by which two stimuli that were judged by participants as the same (following adaptation in different directions) were in fact physically different. Had there been no effect of imagery the two curves would overlap. If participants had answered based on an association (e.g., with a bias to respond upwards following upwards imagery) then the difference between the curves would have been in the opposite direction than what we observed. The motion aftereffects were quantified as the separation between the paired functions, estimated by logistic<marker type="page" number="4"/><marker type="column" number="1"/><marker type="block"/> fits to the population data (<xref ref-type="fig" rid="F2" id="81" class="deo:Reference">Fig. 2</xref>; see Appendix A for model fits). The aftereffects were further quantified on individual participants. A logistic regression was fit to each participant’s data. This provided for each participant an estimate of the separation between the two curves (up vs. down or inward vs. outward) for each eye condition (open and closed). We coded this value as positive if the separation between the curves was in the direction predicted by an aftereffect and negative if it was in the opposite direction. We tested this value against a null hypothesis of no-shift by two-tailed, one-sample t-test (Experiments 3–5), or by analysis of variance using eye condition (open or closed) as a repeated measure (Experiments 1 and 2).</region>
          <outsider class="DoCO:TextBox" type="footer" id="75" page="3" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
          <outsider class="DoCO:TextBox" type="header" id="76" page="4" column="1">ARTICLE IN PRESS</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="77" page="4" column="1">4</outsider>
          <outsider class="DoCO:TextBox" type="header" id="78" page="4" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
          <region class="DoCO:FigureBox" id="F2">
            <image class="DoCO:Figure" src="1m.page_004.image_04.png" thmb="1m.page_004.image_04-thumb.png"/>
            <caption class="deo:Caption" id="80" page="4" column="1">Fig. 2. Aftereffects following motion imagery. The separation between population motion sensitivity curves indicates that participants were more likely to perceive motion of the test stimulus in the direction opposite imagery, evidence for a motion aftereffect from motion imagery. Data points represent the mean frequency of responding upward (Experiment 1, upper panels) or inward (Experiment 2, lower panels) either with the eyes closed (left) or eyes open (right). Error bars are one SEM by participant. The x-axis is the motion coherence in normalized units. Positive numbers are arbitrarily assigned to upward or inward motion. The curves are logistic regressions fitted to the population data (see Appendix A). The separation between the fitted functions, in units of normalized coherence, is 0.13, 0.06, 0.14, and 0.08 for up/down imagery with eyes open, up/down imagery with eyes closed, in/out imagery with eyes open, and in/out imagery with eyes closed, respectively. For each of these parameter estimates, the lower bound was above 0: 0.10, 0.05, 0.05, and 0.03, respectively (95% confidence intervals).</caption>
          </region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="83" page="4" column="1">6.2. Imagery adaptation</h2>
          <region class="DoCO:TextChunk" id="87" page="4" column="1">A small but highly significant aftereffect from imagery was observed, evident in the population data fits ( <xref ref-type="fig" rid="F2" id="84" class="deo:Reference">Fig. 2</xref>), and the individual data fits (<xref ref-type="fig" rid="F3" id="85" class="deo:Reference">Fig. 3</xref>). The individual data from up/down imagery (Experiment 1) showed a separation between the motion response functions of<marker type="column" number="2"/><marker type="block"/> 0.15 ± 0.05 (mean ± sem) units of normalized coherence (F(1,28) = 9.3; P = 0.005). There was no significant difference between the size of the effect from imagery with the eyes closed (0.19 ± 0.06) vs. eyes open (0.11 ± 0.05) (F(1,28) = 2.5, P = 0.12). In/out imagery (Experiment 2) also yielded significant motion aftereffects, with a separation between the functions for inward vs. outward imagery of 0.08 ± 0.03 units of normalized coherence (F(1,27) = 6.8; P = 0.015). As with the up/down imagery experiment, the motion aftereffect from imagery with the eyes closed (0.10 ± 0.04) was not significantly different from the effect with the eyes open (0.06 ± 0.03) (F(1,27) = 2.3; P = 0.145). Note that if the data for individual participants are replotted with the actual coherence values of the test stimuli instead of normalized units, then the shape of the curves for each is exactly the same; only the scale of the x-axis changes. Reanalysis with these actual coherence values yields the same pattern of results. The size of the aftereffects in terms of actual coherence was 4.7 ± 1.4% (F(1,28) = 10.9; P = 0.003) for the up/down imagery experiment and 2.9 ± 1.4% (F(1,27) = 4.3; P = 0.049) for the inward/outward imagery experiment.</region>
          <outsider class="DoCO:TextBox" type="footer" id="88" page="4" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
          <outsider class="DoCO:TextBox" type="header" id="89" page="5" column="1">ARTICLE IN PRESS</outsider>
          <outsider class="DoCO:TextBox" type="header" id="90" page="5" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="91" page="5" column="1">5</outsider>
          <region class="DoCO:FigureBox" id="F3">
            <image class="DoCO:Figure" src="1m.page_005.image_05.png" thmb="1m.page_005.image_05-thumb.png"/>
            <caption class="deo:Caption" id="93" page="5" column="1">Fig. 3. Aftereffects summarized by model fits to individual participant data. Upper left: Separation between paired motion sensitivity curves, either with the eyes closed or open during imagery (mean ± sem). Text labels indicate the size of the shift in units of un-normalized motion coherence. Positive values represent a shift consistent with a motion aftereffect (e.g., increased likelihood of responding upward after downward imagery). Up/down and in/out imagery both led to significant motion aftereffects, with numerically larger shifts with the eyes closed than open. Upper right: The effect of delay between the imagery period and the onset of the test probe. A significant aftereffect is found with a 1-s delay, replicating the previous imagery experiment (third bar, upper left). The effect is weaker with longer delays. Lower panel: Scatterplot depicting each participant’s paired null points following imagery. Each data point represents the amount of motion coherence at which the paired motion sensitivity functions cross the 50% point, either for up/down imagery (circles) or in/out imagery (x’s). Points above the identity line correspond to a separation between motion sensitivity curves in the direction predicted by an aftereffect.</caption>
          </region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="94" page="5" column="1">6.3. Decay of adaptation from imagery</h2>
          <region class="DoCO:TextChunk" id="96" page="5" column="1">Experiment 3 showed that a brief delay between imagery and test probe weakened the adaptation effect (<xref ref-type="fig" rid="F3" id="95" class="deo:Reference">Fig. 3</xref>, right). A 1-s delay, identical to that in the first two experiments, produced a reliable motion aftereffect (0.11 ± 0.5 units of normalized coherence), about equal in magnitude to the aftereffect in the corresponding condition in the previous imagery experiment (in-out, eyes closed, 0.10 ± 0.04). The effect declined with longer delays, (4 s, 0.06 ± 0.06; 13 s, 0.01 ± 0.06), with a significant difference between the shortest and longest delay (T(26) = 1.73; P = 0.047, one-tailed, paired t-test).</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="97" page="5" column="1">6.4. Adaptation to real visual motion</h2>
          <region class="DoCO:TextChunk" id="100" page="5" column="1">As expected, viewing real visual motion led to a robust motion aftereffect ( <xref ref-type="fig" rid="F4" id="98" class="deo:Reference">Fig. 4</xref>). For upward and downward motion, the separation between the two functions following<marker type="column" number="2"/><marker type="block"/> opposite directions of adaptation, based on fits to individual participants, was 0.73 ± 0.25 units of normalized coherence (t(23) = 2.92, P = 0.008, two-tailed one-sample t-test), or 21 ± 6.4% in terms of the un-normalized coherence (t(23) = 3.44, P = 0.002). Adaptation to inward or outward motion also led to a large motion aftereffect: a separation between curves of 0.37 ± 0.04 units of normalized coherence (t(6) = 9.02, P = 0.0001). These effects were about 3– 4Â bigger than those found from imagery.</region>
        </section>
      </section>
      <section class="deo:Discussion">
        <h1 class="DoCO:SectionTitle" id="101" page="5" column="2">7. Discussion</h1>
        <region class="DoCO:TextChunk" id="126" page="5" column="2">In these studies participants imagined motion in a particular direction and were then asked to judge the direction of motion of a moving-dots stimulus. We found that imagining motion produced a motion aftereffect. For example, after imagining motion down, participants were more likely to perceive a set of moving dots as moving up (opposite the direction of imagery). These results dem- <marker type="page" number="6"/><marker type="column" number="1"/><marker type="block"/> onstrate for the first time that imagery of motion recruits direction-selective neural mechanisms that are also used for perceiving real motion. The motion aftereffects we observed from imagery were smaller than those from real motion, consistent with reports showing less activation of sensory cortical areas from motion imagery than from perception of the same stimuli (<xref ref-type="bibr" rid="R11" id="109" class="deo:Reference">Goebel et al., 1998</xref>; Grossman &amp; <xref ref-type="bibr" rid="R12" id="110" class="deo:Reference">Blake, 2001</xref>). Our results show that visual imagery of motion can affect the perception of subsequent physical motion stimuli, and that perception and imagery of motion rely on shared direction-selective neural mechanisms. Two important alternative explanations can be ruled out based on the pattern of results. First, the motion aftereffect obtained from in/out imagery discounts the possibil- ity that the effects we report are due to eye movements and not imagery, such as the motion aftereffects caused by pursuit eye movements in the absence of motion perception (<xref ref-type="bibr" rid="R5" id="111" class="deo:Reference">Chaudhuri, 1990</xref>, 1991; Freeman, Sumnall, &amp; <xref ref-type="bibr" rid="R9" id="112" class="deo:Reference">Snowden, 2003</xref>). Second, the motion aftereffect from imagery with the eyes closed argues against visual attention as the source of the effects, such as the motion aftereffects observed from attentional amplification of real motion sig-<marker type="column" number="2"/><marker type="block"/> nals (<xref ref-type="bibr" rid="R1" id="114" class="deo:Reference">Alais &amp; Blake, 1999</xref>) or attentional tracking of moving stimuli (Culham, Verstraten, Ashida, &amp; <xref ref-type="bibr" rid="R8" id="115" class="deo:Reference">Cavanagh, 2000</xref>). Although one might posit that participants attended to an internal stimulus, this explanation still requires that imagery recruits direction-selective motion mechanisms in the absence of sensory input, in accord with our inter- pretation. Attentional mechanisms for a stimulus or feature, by contrast, presumably operate on representations that are delivered by feed-forward inputs. Moreover, two results suggest that the aftereffects were not due to a simple cognitive bias. First, a brief delay after imagery adaptation weakened the effect, as has been found for adaptation to real motion (<xref ref-type="bibr" rid="R16" id="116" class="deo:Reference">Keck &amp; Pentz, 1977</xref>). Because the direction of imagery was always the same within a block of 48 trials, it is unlikely that participants relying on an explicit response bias strategy would simply forget which way to respond after such a brief delay. A knowl- edge-based bias might be expected to be present throughout the block. Secondly, debriefing following Experiment 1 suggests that participants were not significantly influenced by their knowledge of motion aftereffects or expectations of the<marker type="page" number="7"/><marker type="column" number="1"/><marker type="block"/> experiment. The participants were asked two questions at the end of the experiment: Have you ever heard of the ‘Mo- tion Aftereffect’ before, and After viewing upward motion, would you expect a static image to appear to move up or down. The answers to these questions were not predictive of the observed MAEs: participants who reported having heard (n = 7) vs. not having heard (n = 17) of the MAE showed shifts of 0.13 ± 0.03 vs. 0.10 ± 0.01 in the motion response curves following opposite directions of imagery (t(22) = .631; P = 0.53, two-tailed, unpaired t-test), pooling across eyes-open and eyes-closed conditions. The 17 participants who had not heard of the motion aftereffect were evenly divided in their responses as to whether a static image would appear to move in the opposite (n = 8) vs. the same (n = 8) direction of prior viewing of motion; one participant responded that it would not appear to move at all. Our results are consistent with prior psychophysical studies on spatial imagery (<xref ref-type="bibr" rid="R15" id="122" class="deo:Reference">Ishai &amp; Sagi, 1995</xref>) and the imagery and inference of motion. <xref ref-type="bibr" rid="R10" id="123" class="deo:Reference">Gilden and colleagues (1995)</xref> demonstrated that adaptation to real visual motion affected imagery of motion, the converse of our experiments. Importantly, however, the authors attributed their results to an effect of motion adaptation on the imagined location of a stimulus, not an effect of motion adaptation on motion imagery. This explanation would not apply to our experimental paradigm, since the imagined stimuli occupied the same location regardless of the direction of motion. Our results are also consistent with a prior finding that imagining motion can lead to the illusion of roll vec- tion, whereby spatial judgments are altered by imagery of rotation (Mast, Berthoz, &amp; <xref ref-type="bibr" rid="R21" id="124" class="deo:Reference">Kosslyn, 2001</xref>). Previously we observed that passive viewing of photographs that de- pict motion can lead to a motion aftereffect (<xref ref-type="bibr" rid="R32" id="125" class="deo:Reference">Winawer et al., 2008</xref>). Our current studies add to these by showing for the first time that motion imagery, in the absence of motion perception and even in the absence of any visual input, can recruit and adapt directional motion mechanisms. More generally, our results indicate that top-down signals in the brain can selectively exert specific effects on appropriate subpopulations of sensory neurons.</region>
        <outsider class="DoCO:TextBox" type="footer" id="103" page="5" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
        <outsider class="DoCO:TextBox" type="header" id="104" page="6" column="1">ARTICLE IN PRESS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="105" page="6" column="1">6</outsider>
        <outsider class="DoCO:TextBox" type="header" id="106" page="6" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
        <region class="DoCO:FigureBox" id="F4">
          <image class="DoCO:Figure" src="1m.page_006.image_06.png" thmb="1m.page_006.image_06-thumb.png"/>
          <caption class="deo:Caption" id="108" page="6" column="1">Fig. 4. Motion aftereffects following adaptation to real visual motion, either upward or downward (top left) or inward and outward (top right) Positive values on the x-axis indicate upward motion or inward motion. The aftereffect is about 3–4Â larger than that observed following imagery adaptation (bottom). The imagery results in the bars chart are replotted from the eyes-closed condition of Experiment 1 (up/down) and 2 (in/out).</caption>
        </region>
        <outsider class="DoCO:TextBox" type="footer" id="118" page="6" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
        <outsider class="DoCO:TextBox" type="header" id="119" page="7" column="1">ARTICLE IN PRESS</outsider>
        <outsider class="DoCO:TextBox" type="header" id="120" page="7" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="121" page="7" column="1">7</outsider>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="127" page="7" column="1">Acknowledgements</h1>
        <region class="DoCO:TextChunk" id="128" page="7" column="1">We thank Gordon Bower, Nancy Kanwisher, Josh Wall- man, and Nathan Witthoft for reading an earlier version of this manuscript. We thank Jesse Carton and Taraz Lee for assistance in running experiments.</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="129" page="7" column="1">Appendix A. Measurement of motion response functions</h1>
        <region class="unknown" id="130" page="7" column="1">A.1. Display and dots stimulus used</region>
        <region class="DoCO:TextChunk" id="146" page="7" column="1">Participants sat in a quiet, dark room, approximately 40 cm from an iMac CRT monitor (resolution: 1024 Â 768 pixels (26 Â 19.5 cm), refresh rate: 75 Hz). The test stimulus for the up/down imagery and real motion adaptation experiments consisted of 100 dots in a rectangular window whose length and width were 33% of the entire display (approximately 12 by 9 degrees of visual <marker type="column" number="2"/><marker type="block"/> angle). On each frame a subset of the dots were selected to move coherently up or down. All other dots disappeared and randomly reappeared at any location within the test window. A new set of dots was re-selected for coherent movement on each frame. This ‘‘limited lifetime” procedure was used so that the trajectory of single dots could not be followed throughout a trial. Each test trial consisted of 25 frames displayed for 40 ms each (1 s total). Dot dis- placement for coherent motion was $0.11° per frame. For the inward/outward experiments, the test stimulus consisted of 200 dots, 100 on each side of fixation. On a given trial the coherent component of the dots motion was horizontal either inward or outward (towards or away from the vertical midline). The stimulus was otherwise identical to the test stimulus used for the up/down experiments.<marker type="block"/> To determine an appropriate range of motion coherences for each participant, all participants first completed a baseline motion discrimination task. Moving-dot displays were presented in 1-s trials with up to 65% of dots moving coherently preceding up/down experiments and up to 100% preceding in/out experiments. The coherence values producing 99% correct responses in each direction based on logistic fits to the responses were used to determine the maximum test coherence for the adaptation phase of the experiments. As this value depended on the participant’s performance on the baseline task, it differed across participants (36 ± 17% and 35 ± 12%, mean ± SD, for the up/down and in-out imagery experiments, respectively). We defined this value as 1 unit of normalized coherence in order to make comparisons across participants. For the up-down experiments, coherence values of one-half and one-quarter of this value were used as test stimuli, giving 6 test stimuli for each participant (±1, ±0.5, and ± 0.25 ‘‘normalized” coherence.) For the in-out experiments, the normalized coherence values were sampled more finely: ±1, ±0.67, ±0.44, ±0.29, ±0.19, ±0.13, ±0.08, ±0.05, ±0.03, ±0.02, ±0.01, and 0.<marker type="block"/> A.3.1. Population fits The responses to moving-dot test stimuli were modeled as a logistic regression. The model fit to the aggregate data (all participants in the population) for a given pair of opposing adapting conditions used the following equation, fit with a maximum likelihood algorithm, PðxÞ 1⁄4 @=2 þ ð1 À @Þ Ã 1=ð1 þ YÞ; ð1Þ<marker type="block"/> where Y 1⁄4 exp1⁄2Àð a þ b Ã x þ c Ã AÞ In this equation, x is the motion signal in normalized units of coherence (with positive values assigned to either upward or inward motion and negative values assigned to downward or outward motion). P(x) is the probability that the participant indicates upward (or inward) motion. A is the direction of motion imagery or real motion preceding the dot trial (+1 or À1), and a , ß, c , and @ are free parame-<marker type="page" number="8"/><marker type="column" number="1"/><marker type="block"/> ters. The free parameters correspond to (i) o, the deviation from 0% and 100% with which responses asymptoted, (ii), a , an overall bias to respond in a particular direction, (iii) ß, the motion sensitivity or steepness of the function, and (iv) c the effect of adaptation. Dividing À2 Ã c by ß yields the separation between the paired curves in units of coherence. Thus this value indicates how much motion must be added to a stimulus in one adaptation condition to make it perceptually equivalent to the same stimulus in the opposite adaptation condition. The 95% confidence interval for each parameter estimate was determined by bootstrap- ping: 1000 simulated data sets were generated for each pair of adaptation conditions based on the actual population mean responses, each data set was fitted by Eq. (1), the 1000 parameter estimates were rank ordered, and the 975th and 25th values were taken as the confidence intervals.<marker type="block"/> A.3.2. Individual fits The model fits for individual participants used a similar equation, but because there was less data for individual participants than for the whole population, fewer free parameters were used: PðxÞ 1⁄4 1=ð1 þ YÞ; where Y 1⁄4 exp1⁄2Àð a þ b Ã x þ c 1 Ã A 1 þ . . . þ c n Ã A n Þ ð2Þ This model differs from the population model in that there was no parameter @ to model the asymptote and, for the imagery experiments, the effects of adaptation were modeled in a single equation for all conditions. Thus for Experiments 1 and 2, there were two adaptation terms, one for the eyes-closed condition ( c 1 ) and one for the eyes-open condition ( c 2 ). For Experiment 3, there were three adaptation terms for the three delay conditions ( c 1 , c 2 , c 3 ). For the real motion adaptation experiments, only one adaptation parameter was modeled ( c 1 ). In all experiments, the motion sensitivity (ß) and global bias ( a ) were estimated only once per participant, whereas for the group data in the imagery experiments these parameters were fit separately for each pair of adapting conditions (eyes open and eyes closed). As with the population fits, dividing À2 Ã c by ß yields the separation between the paired curves in units of coherence. The mean of this value across participants was taken as the effect of adaptation for each pair of adaptation conditions.<marker type="block"/> Fifteen participants were excluded from analysis for failing to perform well on the motion discrimination task. Nine participants (2 of 33 doing up/down imagery, 2 of 31 doing in/out imagery, 2 of 30 in the imagery-delay experiment, and 3 of 31 viewing up/down real motion) did not show a significant effect of motion coherence. For these participants, the probability of an ‘‘up” or ‘‘in” response did not significantly increase with increased coherence in that direction in the test stimulus. Specifically, the parameter estimated for motion coherence in a logistic regression fit was less than the standard error of the same parameter estimate. Six other participants, (1 of 33 doing<marker type="column" number="2"/><marker type="block"/> up/down imagery, 1 of 31 doing in/out imagery, 1 of 30 in the imagery-delay experiment, and 3 of 31 doing up/ down real motion), performed poorly in the baseline motion discrimination task such that curve fits yielded a unit of normalized coherence as values &gt;100% actual coherence. These participants were excluded from analysis.</region>
        <region class="unknown" id="133" page="7" column="2">A.2. Baseline motion discrimination task</region>
        <region class="unknown" id="135" page="7" column="2">A.3. Logistic regression fits to motion response functions</region>
        <outsider class="DoCO:TextBox" type="footer" id="138" page="7" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
        <outsider class="DoCO:TextBox" type="header" id="139" page="8" column="1">ARTICLE IN PRESS</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="140" page="8" column="1">8</outsider>
        <outsider class="DoCO:TextBox" type="header" id="141" page="8" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
        <region class="unknown" id="144" page="8" column="1">A.4. Participants excluded from analysis</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="147" page="8" column="2">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="148" page="8" column="2">Alais, D., &amp; Blake, R. (1999). Neural strength of visual attention gauged by motion adaptation. Nature Neuroscience, 2(11), 1015–1018.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="149" confidence="possible" page="8" column="2">Barlow, H. B., &amp; Hill, R. M. (1963). Evidence for a physiological explanation of waterfall phenomenon and figural after-effects. Nature, 200(491), 1345–1347.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="150" confidence="possible" page="8" column="2">Beauchamp, M. S., Cox, R. W., &amp; DeYoe, E. A. (1997). Graded effects of spatial and featural attention on human area MT and associated motion processing areas. Journal of Neurophysiology, 78(1), 516–520.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="151" confidence="possible" page="8" column="2">Blake, R., &amp; Hiris, E. (1993). Another means for measuring the motion aftereffect. Vision Research, 33(11), 1589–1592.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="152" confidence="possible" page="8" column="2">Chaudhuri, A. (1990). A motion illusion generated by afternystagmus suppression. Neuroscience Letters, 118(1), 91–95.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="153" confidence="possible" page="8" column="2">Chaudhuri, A. (1991). Eye movements and the motion aftereffect: Alternatives to the induced motion hypothesis. Vision Research, 31(9), 1639–1645.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="154" confidence="possible" page="8" column="2">Corbetta, M., Miezin, F. M., Dobmeyer, S., Shulman, G. L., &amp; Petersen, S. E. (1991). Selective and divided attention during visual discriminations of shape, color, and speed: Functional anatomy by positron emission tomography. Journal of Neuroscience, 11(8), 2383–2402.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="155" confidence="possible" page="8" column="2">Culham, J. C., Verstraten, F. A., Ashida, H., &amp; Cavanagh, P. (2000). Independent aftereffects of attention and motion. Neuron, 28(2), 607–615.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="156" confidence="possible" page="8" column="2">Freeman, T. C. A., Sumnall, J. H., &amp; Snowden, R. J. (2003). The extra-retinal motion aftereffect. Journal of Vision, 3(11), 771–779.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="157" confidence="possible" page="8" column="2">Gilden, D., Blake, R., &amp; Hurst, G. (1995). Neural adaptation of imaginary visual motion. Cognitive Psychology, 28(1), 1–16.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="158" confidence="possible" page="8" column="2">Goebel, R., Khorram-Sefat, D., Muckli, L., Hacker, H., &amp; Singer, W. (1998). The constructive nature of vision: Direct evidence from functional magnetic resonance imaging studies of apparent motion and motion imagery. European Journal of Neuroscience, 10(5), 1563–1573.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="159" confidence="possible" page="8" column="2">Grossman, E. D., &amp; Blake, R. (2001). Brain activity evoked by inverted and imagined biological motion. Vision Research, 41(10–11), 1475–1482.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="160" confidence="possible" page="8" column="2">Hiris, E., &amp; Blake, R. (1992). Another perspective on the visual motion aftereffect. Proceedings of the National Academy of Sciences, 89(19), 9025–9028.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="161" confidence="possible" page="8" column="2">Huk, A. C., Ress, D., &amp; Heeger, D. J. (2001). Neuronal basis of the motion aftereffect reconsidered. Neuron, 32(1), 161–172.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="162" confidence="possible" page="8" column="2">Ishai, A., &amp; Sagi, D. (1995). Common mechanisms of visual imagery and perception. Science, 268(5218), 1772–1774.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="163" confidence="possible" page="8" column="2">Keck, M. J., &amp; Pentz, B. (1977). Recovery from adaptation to moving gratings. Perception, 6(6), 719–725.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="164" confidence="possible" page="8" column="2">Kohn, A., &amp; Movshon, J. A. (2003). Neuronal adaptation to visual motion in area MT of the macaque. Neuron, 39(4), 681–691.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="165" confidence="possible" page="8" column="2">Kosslyn, S. M., Pascual-Leone, A., Felician, O., Camposano, S., Keenan, J. P., Thompson, W. L., et al. (1999). The role of area 17 in visual imagery: Convergent evidence from PET and rTMS. Science, 284(5411), 167–170.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="166" confidence="possible" page="8" column="2">Kosslyn, S. M., Thompson, W. L., &amp; Alpert, N. M. (1997). Neural systems shared by visual imagery and visual perception: A positron emission tomography study. Neuroimage, 6(4), 320–334.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="167" confidence="possible" page="8" column="2">Kosslyn, S. M., Thompson, W. L., Kim, I. J., &amp; Alpert, N. M. (1995). Topographical representations of mental images in primary visual cortex. Nature, 378(6556), 496–498.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="168" confidence="possible" page="8" column="2">Mast, F. W., Berthoz, A., &amp; Kosslyn, S. M. (2001). Mental imagery of visual motion modifies the perception of roll-vection stimulation. Perception, 30(8), 945–957.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="169" confidence="possible" page="8" column="2">Mather, G., Verstraten, F., &amp; Anstis, S. M. (1998). The motion aftereffect: A modern perspective. Cambridge, Mass: MIT Press.</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="170" confidence="possible" page="8" column="2">Newsome, W. T., &amp; Pare, E. B. (1988). A selective impairment of motion perception following lesions of the middle temporal visual area (MT). Journal of Neuroscience, 8(6), 2201–2211.</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="171" confidence="possible" page="8" column="2">O’Craven, K. M., &amp; Kanwisher, N. (2000). Mental imagery of faces and places activates corresponding stiimulus-specific brain regions. Journal of Cognitive Neuroscience, 12(6), 1013–1023.</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="172" confidence="possible" page="8" column="2">O’Craven, K. M., Rosen, B. R., Kwong, K. K., Treisman, A., &amp; Savoy, R. L. (1997). Voluntary attention modulates fMRI activity in human MT- MST. Neuron, 18(4), 591–598.</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="177" page="9" column="1">Perky, C. W. (1910). An experimental study of imagination. American Journal of Psychology, 21, 422–452.</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="178" confidence="possible" page="9" column="1">Petersen, S. E., Baker, J. F., &amp; Allman, J. M. (1985). Direction-specific adaptation in area MT of the owl monkey. Brain Research, 346(1), 146–150.</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="179" confidence="possible" page="9" column="1">Pylyshyn, Z. W. (2002). Mental imagery: In search of a theory. The Behavioral and Brain Sciences, 25(2), 157–182 (discussion 182–237).</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="180" confidence="possible" page="9" column="1">Saenz, M., Buracas, G. T., &amp; Boynton, G. M. (2002). Global effects of feature-based attention in human visual cortex. Nature Neuroscience, 5(7), 631–632.</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="181" page="9" column="2">Slotnick, S. D., Thompson, W. L., &amp; Kosslyn, S. M. (2005). Visual mental imagery induces retinotopically organized activation of early visual areas. Cerebral Cortex.</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="182" confidence="possible" page="9" column="2">Van Wezel, R. J., &amp; Britten, K. H. (2002). Motion adaptation in area MT. Journal of Neurophysiology, 88(6), 3469–3476.</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="183" confidence="possible" page="9" column="2">Winawer, J., Huk, A. C., &amp; Boroditsky, L. (2008). A motion aftereffect from still photographs depicting motion. Psychological Science, 19(3), 276–283.</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="184" confidence="possible" page="9" column="2">Wohlgemuth, A. (1911). On the after-effect of seen movement. Cambridge: University Press.</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="footer" id="173" page="8" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
        <outsider class="DoCO:TextBox" type="header" id="174" page="9" column="1">ARTICLE IN PRESS</outsider>
        <outsider class="DoCO:TextBox" type="header" id="175" page="9" column="1">J. Winawer et al. / Cognition xxx (2009) xxx–xxx</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="176" page="9" column="1">9</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="185" page="9" column="2">Please cite this article in press as: Winawer, J., et al. A motion aftereffect from visual imagery of motion. Cognition (2009), doi:10.1016/ j.cognition.2009.09.010</outsider>
      </section>
    </body>
  </article>
</pdfx>
